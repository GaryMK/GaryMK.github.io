<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>RN环境配置</title>
      <link href="/2023/12/11/RN%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
      <url>/2023/12/11/RN%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<h1 id="RN环境配置"><a href="#RN环境配置" class="headerlink" title="RN环境配置"></a>RN环境配置</h1><h2 id="nvm配置"><a href="#nvm配置" class="headerlink" title="nvm配置"></a>nvm配置</h2><p>nvm下载安装</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.7/install.sh | bash</span><br></pre></td></tr></table></figure><p>nvm配置环境</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 打开～/.zshrc</span></span><br><span class="line">open -e ~/.zshrc</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在zsh配置文件中添加如下代码</span></span><br><span class="line"><span class="built_in">export</span> NVM_DIR=<span class="string">&quot;<span class="subst">$([ -z <span class="string">&quot;<span class="variable">$&#123;XDG_CONFIG_HOME-&#125;</span>&quot;</span> ] &amp;&amp; printf %s <span class="string">&quot;<span class="variable">$&#123;HOME&#125;</span>/.nvm&quot;</span> || printf %s <span class="string">&quot;<span class="variable">$&#123;XDG_CONFIG_HOME&#125;</span>/nvm&quot;</span>)</span>&quot;</span></span><br><span class="line">[ -s <span class="string">&quot;<span class="variable">$NVM_DIR</span>/nvm.sh&quot;</span> ] &amp;&amp; \. <span class="string">&quot;<span class="variable">$NVM_DIR</span>/nvm.sh&quot;</span> <span class="comment"># This loads nvm</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 刷新配置文件</span></span><br><span class="line"><span class="built_in">source</span> ~/.zshrc</span><br></pre></td></tr></table></figure><blockquote><p>nvm常用命令：</p><p>nvm install ：安装指定版本的Node.js</p><p>nvm use ：切换到指定版本的Node.js</p><p>nvm current：显示当前正在使用的Node.js版本</p><p>nvm ls：列出所有已经安装的Node.js版本</p><p>nvm alias：为指定版本创建一个别名，例如nvm alias default 18.16.1</p><p>nvm uninstall ：卸载指定版本的Node.js，例如nvm uninstall 18.16.1</p><p>nvm reinstall-packages ：在切换Node.js版本后，重新安装已安装的全局npm包</p><p>nvm on：打开nvm自动切换</p><p>nvm off：关闭nvm自动切换</p></blockquote><h2 id="安装nodejs"><a href="#安装nodejs" class="headerlink" title="安装nodejs"></a>安装nodejs</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看可安装的版本</span></span><br><span class="line">nvm list-remote</span><br><span class="line"><span class="comment"># 安装指定版本</span></span><br><span class="line">nvm install 20.10.0</span><br></pre></td></tr></table></figure><h2 id="安装依赖"><a href="#安装依赖" class="headerlink" title="安装依赖"></a>安装依赖</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">brew install watchman</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用nrm工具切换淘宝源</span></span><br><span class="line">npx nrm use taobao</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果之后需要切换回官方源可使用</span></span><br><span class="line">npx nrm use npm</span><br><span class="line"></span><br><span class="line"><span class="comment"># Yarn是 Facebook 提供的替代 npm 的工具，可以加速 node 模块的下载</span></span><br><span class="line">npm install -g yarn</span><br></pre></td></tr></table></figure><h2 id="配置Android开发环境"><a href="#配置Android开发环境" class="headerlink" title="配置Android开发环境"></a>配置Android开发环境</h2>]]></content>
      
      
      <categories>
          
          <category> 环境配置 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>zsh安装及配置</title>
      <link href="/2023/12/11/zsh%E5%AE%89%E8%A3%85%E5%8F%8A%E9%85%8D%E7%BD%AE/"/>
      <url>/2023/12/11/zsh%E5%AE%89%E8%A3%85%E5%8F%8A%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<h1 id="zsh安装及配置"><a href="#zsh安装及配置" class="headerlink" title="zsh安装及配置"></a>zsh安装及配置</h1><h3 id="安装Homebrew"><a href="#安装Homebrew" class="headerlink" title="安装Homebrew"></a>安装Homebrew</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/bin/bash -c <span class="string">&quot;<span class="subst">$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)</span>&quot;</span></span><br></pre></td></tr></table></figure><h4 id="配置brew"><a href="#配置brew" class="headerlink" title="配置brew"></a>配置brew</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(<span class="built_in">echo</span>; <span class="built_in">echo</span> <span class="string">&#x27;eval &quot;$(/opt/homebrew/bin/brew shellenv)&quot;&#x27;</span>) &gt;&gt; /Users/mukaikai/.zprofile</span><br><span class="line"><span class="built_in">eval</span> <span class="string">&quot;<span class="subst">$(/opt/homebrew/bin/brew shellenv)</span>&quot;</span></span><br></pre></td></tr></table></figure><h3 id="安装zsh"><a href="#安装zsh" class="headerlink" title="安装zsh"></a>安装zsh</h3><p>macOS 安装 zsh</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">brew install zsh</span><br></pre></td></tr></table></figure><h3 id="zsh设置"><a href="#zsh设置" class="headerlink" title="zsh设置"></a>zsh设置</h3><p>查看系统已有的 shell</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat /etc/shells</span><br></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">/bin/bash</span><br><span class="line">/bin/csh</span><br><span class="line">/bin/dash</span><br><span class="line">/bin/ksh</span><br><span class="line">/bin/sh</span><br><span class="line">/bin/tcsh</span><br><span class="line">/bin/zsh</span><br></pre></td></tr></table></figure><p>以上输出结果可以看到已经有 zsh 了</p><p>更换默认 shell</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">chsh -s /bin/zsh</span><br></pre></td></tr></table></figure><p>重启系统！</p><p>查看当前使用的 shell</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">echo $SHELL</span><br></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">/bin/zsh</span><br></pre></td></tr></table></figure><p>以上输出结果表示默认的shell已经切换至 zsh</p><h3 id="安装Oh-My-Zsh"><a href="#安装Oh-My-Zsh" class="headerlink" title="安装Oh My Zsh"></a>安装Oh My Zsh</h3><ol><li>到 Oh My Zsh 的 Github 页面 <a href="https://github.com/ohmyzsh/ohmyzsh">Oh My Zsh</a></li><li>将文件下载至 ~&#x2F;Downloads 目录。下载好的文件名为 ohmyzsh-master.zip</li><li>到下好的文件所在目录，执行 unzip ohmyzsh-master.zip 将文件解压，解压后得到 ohmyzsh-master 的目录</li><li>执行 cd ohmyzsh-master&#x2F;tools 进入 tools 目录</li><li>tools 目录里 有一个 install.sh 的 shell 脚本文件，这是 Oh My Zsh 的安装脚本。通过 .&#x2F;install.sh 来执行 install.sh 文件，进行 Oh My Zsh 的安装</li><li>恭喜你，如无意外，Oh My Zsh 就已经安装好了</li></ol><h3 id="Oh-My-Zsh配置"><a href="#Oh-My-Zsh配置" class="headerlink" title="Oh My Zsh配置"></a>Oh My Zsh配置</h3><p>修改 zsh 主题</p><ul><li>zsh 主题都在路径<code>~/.oh-my-zsh/themes</code>中，使某一主题生效的文件为<code>~/.zshrc</code>文件，找到<code>ZSH_THEME=&quot;robbyrussell&quot;</code>一行（大概11行左右），把其注释掉，在下面添一行<code>ZSH_THEME=&quot;agnoster&quot;</code>，之后关闭终端，再重启就好了。</li></ul><p>安装powerline-fonts（防止加载某些配色方案后终端的乱码情况）</p><ul><li>从<a href="https://github.com/supermarin/powerline-fonts%E4%B8%8B%E8%BD%BD%E5%AD%97%E4%BD%93%E5%8C%85">https://github.com/supermarin/powerline-fonts下载字体包</a></li><li>在下载好的文件中找到Monaco for Powerline.otf，双击安装字体</li><li>终端 -&gt; 设置 -&gt; 描述文件 -&gt; 字体，进行字体设置</li></ul><p>安装 zsh 高亮插件</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git clone https://gitee.com/hello-luiswu/zsh-syntax-highlighting.git $&#123;ZSH_CUSTOM:-~/.oh-my-zsh/custom&#125;/plugins/zsh-syntax-highlighting</span><br></pre></td></tr></table></figure><p>安装 zsh 历史记录的自动补全插件</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git clone https://gitee.com/hello-luiswu/zsh-autosuggestions $&#123;ZSH_CUSTOM:-~/.oh-my-zsh/custom&#125;/plugins/zsh-autosuggestions</span><br></pre></td></tr></table></figure><p>安装zsh命令拓展补全插件</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/zsh-users/zsh-completions <span class="variable">$&#123;ZSH_CUSTOM:=~/.oh-my-zsh/custom&#125;</span>/plugins/zsh-completions</span><br></pre></td></tr></table></figure><p>启动插件</p><p>修改 zsh 的配置文件</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim ~/.zshrc</span><br></pre></td></tr></table></figure><p>找到以下内容：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">plugins=(git)</span><br></pre></td></tr></table></figure><p>替换成以下内容：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">plugins=(git zsh-autosuggestions zsh-completions zsh-syntax-highlighting)</span><br></pre></td></tr></table></figure><h3 id="Solarized主题"><a href="#Solarized主题" class="headerlink" title="Solarized主题"></a>Solarized主题</h3><p><a href="https://github.com/altercation/solarized">https://github.com/altercation/solarized</a></p>]]></content>
      
      
      <categories>
          
          <category> 环境配置 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> zsh </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mac系统Python报错</title>
      <link href="/2023/08/29/Mac%E7%B3%BB%E7%BB%9FPython%E6%8A%A5%E9%94%99/"/>
      <url>/2023/08/29/Mac%E7%B3%BB%E7%BB%9FPython%E6%8A%A5%E9%94%99/</url>
      
        <content type="html"><![CDATA[<h2 id="Mac系统Python报错"><a href="#Mac系统Python报错" class="headerlink" title="Mac系统Python报错"></a>Mac系统Python报错</h2><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>在Mac系统上执行python文件会报错提示权限不够或者找不到文件</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">1. </span><br><span class="line"><span class="built_in">env</span>: python: No such file or directory</span><br><span class="line"></span><br><span class="line">2.</span><br><span class="line">bash: /usr/bin/python: Permission denied</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h3><p>Mac系统自带的是Python3，直接执行python命令失败</p><h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><ol><li><p>关闭Mac系统的Rootless机制</p><ol><li><p>arm芯片的mac关机长按启动键进入RecoveryOS</p></li><li><p>点击顶部菜单“实用工具”-》“终端”</p></li><li><p>终端输入命令并重启</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">csrutil <span class="built_in">disable</span></span><br></pre></td></tr></table></figure></li></ol></li><li><p>电脑终端查看python3的位置</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">which</span> python3</span><br></pre></td></tr></table></figure></li><li><p>为其创建符号连接</p></li></ol><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">ln</span> -s -f /usr/local/bin/python3 /usr/local/bin/python</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Mac安装软件“已损坏，无法打开.....”问题</title>
      <link href="/2023/08/08/Mac%E5%AE%89%E8%A3%85%E8%BD%AF%E4%BB%B6%E2%80%9C%E5%B7%B2%E6%8D%9F%E5%9D%8F%EF%BC%8C%E6%97%A0%E6%B3%95%E6%89%93%E5%BC%80-%E2%80%9D%E9%97%AE%E9%A2%98/"/>
      <url>/2023/08/08/Mac%E5%AE%89%E8%A3%85%E8%BD%AF%E4%BB%B6%E2%80%9C%E5%B7%B2%E6%8D%9F%E5%9D%8F%EF%BC%8C%E6%97%A0%E6%B3%95%E6%89%93%E5%BC%80-%E2%80%9D%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h1 id="Mac安装软件“已损坏，无法打开…-”问题"><a href="#Mac安装软件“已损坏，无法打开…-”问题" class="headerlink" title="Mac安装软件“已损坏，无法打开…..”问题"></a>Mac安装软件“已损坏，无法打开…..”问题</h1><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>在Mac上安装一些网站软件时候，提示“应用程序”已损坏。您应该将他移到废纸篓。</p><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/image-20230808160609757.png" alt="image-20230808160609757"></p><h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><ol><li><p>允许“任何来源”开启</p><p>打开终端，输入：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo spctl --master-disable</span><br></pre></td></tr></table></figure></li></ol><p>​然后打开【系统设置】-【隐私与安全性】下，可以看到安全性那一栏中任何来源已经开启和选中：</p><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/image-20230808155803780.png" alt="image-20230808155803780"></p><ol start="2"><li>移除应用的安全隔离属性</li></ol><p>打开【终端】，输入</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo xattr -r -d com.apple.quarantine XXX</span><br></pre></td></tr></table></figure><ul><li>XXX 为当前App的路径，如果不知道路径，打开【Finder】-【应用程序】，找到对应的app，拖到终端中该命令后面即可，例如：</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo xattr -r -d com.apple.quarantine /Applications/PicGo.app</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Typora配置PicGo-Core图床</title>
      <link href="/2023/08/08/Typora%E9%85%8D%E7%BD%AEPicGo-Core%E5%9B%BE%E5%BA%8A/"/>
      <url>/2023/08/08/Typora%E9%85%8D%E7%BD%AEPicGo-Core%E5%9B%BE%E5%BA%8A/</url>
      
        <content type="html"><![CDATA[<h1 id="Typora配置PicGo-Core图床"><a href="#Typora配置PicGo-Core图床" class="headerlink" title="Typora配置PicGo-Core图床"></a>Typora配置PicGo-Core图床</h1><h3 id="配置PicGo"><a href="#配置PicGo" class="headerlink" title="配置PicGo"></a>配置PicGo</h3><ol><li>安装PicGo</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">npm install picgo -g</span><br></pre></td></tr></table></figure><ol start="2"><li>设置PicGo</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">picgo set uploader</span><br></pre></td></tr></table></figure><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/image-20230808145701508.png" alt="image-20230808145701508"></p><ul><li>secretId: API密钥的SecretId(腾讯云-访问管理-访问密钥)</li><li>secretKey: API密钥的SecretKey(腾讯云-访问管理-访问密钥)</li><li>appId: API密钥对应的APPID(腾讯云-访问管理-访问密钥)</li><li>bucket: 存储桶名称</li><li>area”: 存储桶所属区域，例如ap-shanghai</li><li>path”: 存储路径</li><li>version: v5</li></ul><h3 id="配置Typora"><a href="#配置Typora" class="headerlink" title="配置Typora"></a>配置Typora</h3><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/image-20230808154633595.png" alt="image-20230808154633595"></p>]]></content>
      
      
      
        <tags>
            
            <tag> Typora </tag>
            
            <tag> PicGo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Git拉取报RPC&amp;Bad Owner</title>
      <link href="/2023/08/08/git%E6%8B%89%E5%8F%96%E6%8A%A5RPC&amp;Band%20Owner/"/>
      <url>/2023/08/08/git%E6%8B%89%E5%8F%96%E6%8A%A5RPC&amp;Band%20Owner/</url>
      
        <content type="html"><![CDATA[<h1 id="Git拉取报RPC-amp-Bad-Owner"><a href="#Git拉取报RPC-amp-Bad-Owner" class="headerlink" title="Git拉取报RPC&amp;Bad Owner"></a>Git拉取报RPC&amp;Bad Owner</h1><h3 id="报错信息"><a href="#报错信息" class="headerlink" title="报错信息"></a>报错信息</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">error: RPC failed; curl 18 transfer closed with outstanding read data remaining</span><br><span class="line">fetch-pack: unexpected disconnect while reading sideband packet</span><br><span class="line">fatal: early EOF</span><br><span class="line">fatal: fetch-pack: invalid index-pack output</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">致命错误：无法访问 &#x27; &#x27; :transfer closed with outstanding read data remaining</span><br></pre></td></tr></table></figure><h3 id="描述"><a href="#描述" class="headerlink" title="描述"></a>描述</h3><p>之前在从git远程库拉取项目的时候，出现了如上错误，因为拉取时间过长才报的错，所以猜测是内存或者项目过大导致的无法拉取，所以搜了搜，网上说是解决方案有三种，一种是增大缓存区；二是浅克隆，也就是说克隆的时候，先少克隆一些，比如只克隆每个文件只取最近一次提交，不是整个历史版本，三是换协议.</p><h3 id="具体解决方案如下："><a href="#具体解决方案如下：" class="headerlink" title="具体解决方案如下："></a>具体解决方案如下：</h3><ol><li>加大缓存区 git config –global http.postBuffer 524288000 这个大约是500M</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git config --global http.postBuffer 1048576000</span><br></pre></td></tr></table></figure><p>1048576000</p><ol><li><p>少clone一些，–depth 1 git clone <a href="https://github.com/[flutter](https://so.csdn.net/so/search?q=flutter&spm=1001.2101.3001.7020)/flutter.git">https://github.com/[flutter](https://so.csdn.net/so/search?q=flutter&amp;spm=1001.2101.3001.7020)/flutter.git</a> –depth 1</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/flutter/flutter.git --depth 1</span><br></pre></td></tr></table></figure><p>–depth 1的含义是复制深度为1，就是每个文件只取最近一次提交，不是整个历史版本。</p></li><li><p>换协议 clone http方式换成SSH的方式，</p><p>即 https:&#x2F;&#x2F; 改为 git:&#x2F;&#x2F;</p><p>例如git clone <a href="https://github.com/test/test.git">https://github.com/test/test.git</a> </p><p>换成git clone git:&#x2F;&#x2F;github.com&#x2F;test&#x2F;test.git</p></li></ol><h3 id="报错信息-1"><a href="#报错信息-1" class="headerlink" title="报错信息"></a>报错信息</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Bad owner or permissions on /Users/mukaikai/.ssh/config</span><br><span class="line">fatal: Could not read from remote repository.</span><br></pre></td></tr></table></figure><h3 id="描述-1"><a href="#描述-1" class="headerlink" title="描述"></a>描述</h3><p>当为本机配一个固定用户名远程登录某主机时，配置了一个config文件，但是在执行ssh免密码登录时报如下的错误：Bad owner or permissions on .ssh&#x2F;config的解决。</p><h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo <span class="built_in">chmod</span> 600 ~/.ssh/config</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Debug </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2023/08/05/hello-world/"/>
      <url>/2023/08/05/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Particles.js库无法正常显示</title>
      <link href="/2023/07/18/Particles-js%E5%BA%93%E6%97%A0%E6%B3%95%E6%AD%A3%E5%B8%B8%E6%98%BE%E7%A4%BA/"/>
      <url>/2023/07/18/Particles-js%E5%BA%93%E6%97%A0%E6%B3%95%E6%AD%A3%E5%B8%B8%E6%98%BE%E7%A4%BA/</url>
      
        <content type="html"><![CDATA[<h1 id="Particles-js库无法正常显示"><a href="#Particles-js库无法正常显示" class="headerlink" title="Particles.js库无法正常显示"></a>Particles.js库无法正常显示</h1><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>在实现网页背景的粒子效果过程中使用了particles.js的库，但提示</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">particles.min.js:9 uncaught typeerror: cannot read properties of null。</span><br></pre></td></tr></table></figure><p>如下图所示：</p><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/image-20230718162721167.png" alt="image-20230718162721167"></p><h3 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h3><p>这个问题的原因在于script在html之前进行了执行，导致找不到相关方法</p><h3 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h3><p>将引入particles.js的<script>标签放在html之后，<body>标签之前</p>]]></content>
      
      
      <categories>
          
          <category> Debug </category>
          
          <category> Web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Javascript </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>开发框架汇总</title>
      <link href="/2023/07/13/%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6%E6%B1%87%E6%80%BB/"/>
      <url>/2023/07/13/%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6%E6%B1%87%E6%80%BB/</url>
      
        <content type="html"><![CDATA[<h1 id="开发框架汇总"><a href="#开发框架汇总" class="headerlink" title="开发框架汇总"></a>开发框架汇总</h1><h3 id="前端"><a href="#前端" class="headerlink" title="前端"></a>前端</h3><h3 id="移动端"><a href="#移动端" class="headerlink" title="移动端"></a>移动端</h3><h3 id="PC端开发"><a href="#PC端开发" class="headerlink" title="PC端开发"></a>PC端开发</h3><h4 id="Electron"><a href="#Electron" class="headerlink" title="Electron"></a>Electron</h4><p>Electron是一个使用 JavaScript、HTML 和 CSS 构建桌面应用程序的框架。该框架兼容Mac、Windows和Linux，可以嵌入 <a href="https://www.chromium.org/">Chromium</a> 和 <a href="https://nodejs.org/">Node.js</a> 到 二进制的 Electron ，进而构建出三个平台的应用程序。</p>]]></content>
      
      
      <categories>
          
          <category> 开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 框架 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Qt开发语法无误依然报错问题汇总</title>
      <link href="/2023/06/23/QT%E5%BC%80%E5%8F%91%E8%AF%AD%E6%B3%95%E6%97%A0%E8%AF%AF%E4%BE%9D%E7%84%B6%E6%8A%A5%E9%94%99%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/"/>
      <url>/2023/06/23/QT%E5%BC%80%E5%8F%91%E8%AF%AD%E6%B3%95%E6%97%A0%E8%AF%AF%E4%BE%9D%E7%84%B6%E6%8A%A5%E9%94%99%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/</url>
      
        <content type="html"><![CDATA[<h1 id="Qt开发语法无误依然报错问题汇总"><a href="#Qt开发语法无误依然报错问题汇总" class="headerlink" title="Qt开发语法无误依然报错问题汇总"></a>Qt开发语法无误依然报错问题汇总</h1><h3 id="报错信息"><a href="#报错信息" class="headerlink" title="报错信息"></a>报错信息</h3><p>目前为止遇到以下类型的报错信息，问题的根源以及解决方式相同。</p><ol><li>编译器报错：”error:C2039:不是“XXX”的成员”</li><li>编译器报错：”error:C2059:语法错误“</li><li>编译器报错：”error:C2065:”XXX”:未声明的标识符“</li><li>编译器报错：”error:C2143:”语法错误”:缺少”XXX””</li></ol><h3 id="错误原因"><a href="#错误原因" class="headerlink" title="错误原因"></a>错误原因</h3><p>代码中有中文注释+“utf-8”编码导致报错</p><h3 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h3><p><strong>方法一：</strong></p><p>直接删除中午注释（不推荐）</p><p><strong>方法二：</strong></p><p>qt环境设置: Tools-Options-Text Editor-Behavior-File Encoding-Default encoding:UTF-8；</p><p>qt环境设置: Tools-Options-Text Editor-Behavior-File Encoding-UTF-8 BOM:Add If Emcoding Is UTF-8;</p><p><strong>方法三：</strong></p><p>点击文件-&gt;高级保存选项-&gt;将编码从 utf8 改为 简体中文(GB18030)即可.</p><p><strong>方法四：</strong></p><p>代码区右键—&gt;最后一项(add utf8-bom on save)点击—&gt;重新编译即可</p>]]></content>
      
      
      <categories>
          
          <category> 开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Qt开发 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2023面经</title>
      <link href="/2023/02/20/2023%E9%9D%A2%E7%BB%8F/"/>
      <url>/2023/02/20/2023%E9%9D%A2%E7%BB%8F/</url>
      
        <content type="html"><![CDATA[<h1 id="2023校招面经"><a href="#2023校招面经" class="headerlink" title="2023校招面经"></a>2023校招面经</h1><h2 id="RecycleView-实现列表"><a href="#RecycleView-实现列表" class="headerlink" title="RecycleView  实现列表"></a>RecycleView  实现列表</h2><p>​首先是在build.gradle里添加RecyclerView的依赖库，然后我们通过继承RecyclerView.Adapter,并在Adapter里定义一个内部类ViewHolder并在其中通过findViewById来获取列表每控件的实例，重写onCreateViewHolder,onBindViewHOlder以及getItemCount方法。onCreateViewHOlder用于创建ViewHolder实例，以及将列表所在布加载进来，监听事件的绑定；onBindViewHolder可以在子项滚动到屏幕内根据postion更新数据；getItemCount获取子项数目。</p><p>​最后通过在Activity内的onCreate中初始化数据，获取RecyclerView实例并设置布局。最后设置适配器。</p><h2 id="RecycleView-实现多条目"><a href="#RecycleView-实现多条目" class="headerlink" title="RecycleView 实现多条目"></a>RecycleView 实现多条目</h2><p>​在ViewHolder定义多个控件。</p><h2 id="HashMap，HashSet-和-HashTable"><a href="#HashMap，HashSet-和-HashTable" class="headerlink" title="HashMap，HashSet 和 HashTable"></a>HashMap，HashSet 和 HashTable</h2><p>实现上：</p><p>​都实现了Map接口，并且都是Key-Value的形式。HashSet是集合形式，且不能重复。</p><p>源码上：</p><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/watermark%2Ctype_ZmFuZ3poZW5naGVpdGk%2Cshadow_10%2Ctext_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p5em4xNDI1MDc3MTE5%2Csize_16%2Ccolor_FFFFFF%2Ct_70.png" alt="img"></p><p>​HashMap是一种散列表,采用(数组 + 链表 + 红黑树)的存储结构;</p><p>​HashTable是数组+链表；链地址法处理冲突。</p><p>​HashSet底层是采用HashMap实现的，每次add添加的元素作为map的key，而Value固定为PRESENT，从而实现不能重复。</p><p><strong>在Jdk8引入树化，当元素个数达到64且链表的长度达到8时进行树化，当链表的长度小于6时反树化。<em>这样可以利用链表对内存的使用率以及红黑树的高效检索,是一种很有效率的数据结构。</em></strong></p><p>安全上：</p><p>HashMap不是线程安全的，HashTable通过synchronized实现线程安全，是同步的。</p><blockquote><p>负载因子（loadFactor）：<br>当我们第一次创建 HashMap 的时候，就会指定其容量（如果未明确指定，默认是 16），随着我们不断的向 HashMap 中 put 元素的时候，就有可能会超过其容量，那么就需要有一个扩容机制。</p><p>所谓扩容，就是扩大 HashMap 的容量,在向 HashMap 中添加元素过程中，如果 元素个数（size）超过临界值（threshold） 的时候，就会进行自动扩容（resize），并且，在扩容之后，还需要对 HashMap 中原有元素进行 rehash，即将原来桶中的元素重新分配到新的桶中。</p><p>在 HashMap 中，临界值（threshold） &#x3D; 负载因子（loadFactor） * 容量（capacity）。</p><p>loadFactor 是装载因子（负载因子），表示 HashMap 满的程度，默认值为 0.75f，也就是说默认情况下，当 HashMap 中元素个数达到了容量的 3&#x2F;4 的时候就会进行自动扩容。</p></blockquote><h2 id="Hash的初始Size"><a href="#Hash的初始Size" class="headerlink" title="Hash的初始Size"></a>Hash的初始Size</h2><p>HashTable中hash数组默认大小是11，增加的方式是 old*2+1。HashMap中hash数组的默认大小是16，而且一定是2的指数。（为什么HashMap要是2的倍数扩容，原因是减小冲突）</p><h2 id="哈希冲突"><a href="#哈希冲突" class="headerlink" title="哈希冲突"></a>哈希冲突</h2><p>开放定址法（发生冲突，继续寻找下一块未被占用的存储地址），再散列函数法，链地址法，而HashMap即是采用了链地址法，也就是数组+链表的方式</p><h1 id="Synchronized实现原理，泄漏"><a href="#Synchronized实现原理，泄漏" class="headerlink" title="Synchronized实现原理，泄漏"></a>Synchronized实现原理，泄漏</h1><p>​synchronized关键字解决的是多个线程之间访问资源的同步性，synchronized 翻译为中文的意思是同步，也称之为<strong>同步锁</strong>。<br>synchronized的作用是保证在同一时刻， 被修饰的代码块或方法只会有一个线程执行，以达到保证并发安全的效果。</p><p>​Synchronized的底层实现是完全依赖JVM虚拟机的,所以谈synchronized的底层实现，就不得不谈数据在JVM内存的存储：Java对象头，以及Monitor对象监视器。</p><blockquote><p>1.Synchronized是由虚拟机实现的一种互斥同步方式，当你查看被Synchronized修饰的程序块编译后的字节码时，会发现程序块被编译前后生成了monitorenter 和 monitorexit 两 个 字 节 码 指 令 ；</p><p>2.在虚拟机运行到monitorenter 时，先获取对象的锁，如果对象没有锁定，或者当前线程已经拥有这个对象的锁，则把锁+1；运行monitorexit时则将计时器-1，当计时器为0时，锁就会被释放；</p><p>3.如果对象获取失败了，那么当前的线程就要阻塞等待，直到对象锁被另一个线程释放为止；</p></blockquote><h2 id="锁泄漏-Lock-Leak）"><a href="#锁泄漏-Lock-Leak）" class="headerlink" title="锁泄漏(Lock Leak）"></a>锁泄漏(Lock Leak）</h2><p>锁泄漏是指一个线程获得某个锁以后，由于程序的错误、缺陷致使该锁一直没法被释放而导致其他线程一直无法获得该锁的现象。</p><p>内部锁synchronized不会造成锁泄漏(Lock Leak)，当临界区发生异常，JVM查找异常表，来保证monitorexit一定能够执行成功，锁一定会被释放。。</p><h2 id="JVM"><a href="#JVM" class="headerlink" title="JVM"></a>JVM</h2><p>​JVM是Java Virtual Machine（Java虚拟机）的缩写，JVM是一种用于计算设备的规范，它是一个虚构出来的计算机，是通过在实际的计算机上仿真模拟各种计算机功能来实现的。引入Java语言虚拟机后，Java语言在不同平台上运行时不需要重新编译。Java语言使用Java虚拟机屏蔽了与具体平台相关的信息，使得Java语言编译程序只需生成在Java虚拟机上运行的目标代码（字节码），就可以在多种平台上不加修改地运行。</p><h4 id="构成"><a href="#构成" class="headerlink" title="构成"></a>构成</h4><ul><li><blockquote><p>类加载系统：负责完成类的加载</p><p>运⾏时数据区：在运⾏Java程序的时候会产⽣的各种数据会保存在运⾏时数据区</p><p>执⾏引擎：执⾏具体的指令（代码）</p></blockquote></li></ul><h4 id="对象成为垃圾的判断依据"><a href="#对象成为垃圾的判断依据" class="headerlink" title="对象成为垃圾的判断依据"></a>对象成为垃圾的判断依据</h4><p>引⽤计数法,可达性分析算法</p><p> 当Java程序创建对象时，JVM会在堆内存中为对象分配内存。 当对象不再被使用时，它们就会成为垃圾。 如果不进行垃圾回收，这些垃圾对象将永远占用内存，并最终导致内存溢出。</p><h4 id="垃圾回收算法"><a href="#垃圾回收算法" class="headerlink" title="垃圾回收算法"></a>垃圾回收算法</h4><p>标记清除算法、复制算法、标记整理算法、分代回收法</p><h2 id="Android计算图片大小"><a href="#Android计算图片大小" class="headerlink" title="Android计算图片大小"></a>Android计算图片大小</h2><p>图片高度 * 图片宽度 * 一个像素占用的字节数</p><h2 id="Java的反射"><a href="#Java的反射" class="headerlink" title="Java的反射"></a>Java的反射</h2><p>​反射的概述JAVA反射机制是在<strong>运行状态</strong>中，对于任意一个类，都能够知道这个类的<strong>所有属性和方法</strong>；对于任意一个对象，都能够<strong>调用</strong>它的任意一个方法和属性；这种动态获取的信息以及动态调用对象的方法的功能称为java语言的反射机制。要想解剖一个类,必须先要获取到该类的</p><h3 id="获取类对应的字节码的对象"><a href="#获取类对应的字节码的对象" class="headerlink" title="获取类对应的字节码的对象"></a>获取类对应的字节码的对象</h3><p><strong>①</strong> 调用某个类的对象的getClass()方法，即：对象.getClass()；</p><p><strong>②</strong> 调用类的class属性类获取该类对应的Class对象，即：类名.class</p><p><strong>③</strong> 使用Class类中的forName()静态方法（最安全，性能最好）即：Class.forName(“类的全路径”)</p><h4 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h4><p>android的sdk中，有一些用hide标记的方法，或者是private方法 属性，这些方法不能直接通过sdk的api调用，如果我们需要用到此功能，只能通过反射的机制来调用它。</p><p>发一些工具类的时候，例如网络数据，数据库数据和类之间的相互转化。使用反射机制可以直接创建对象，方便代码管理。</p><h2 id="手写单例"><a href="#手写单例" class="headerlink" title="手写单例"></a>手写单例</h2><p>​类加载时就初始化实例，避免了多线程同步问题，天然线程安全。实例对象在第一次被调用的时候才真正构建的，而不是程序一启动就会自动构建。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">//懒汉式单例类.在第一次调用的时候实例化自己 </span><br><span class="line">public class Singleton &#123;</span><br><span class="line">    private Singleton() &#123;&#125;</span><br><span class="line">    private static Singleton single=null;</span><br><span class="line">    //静态工厂方法 </span><br><span class="line">    public static Singleton getInstance() &#123;</span><br><span class="line">         if (single == null) &#123;  </span><br><span class="line">             single = new Singleton();</span><br><span class="line">         &#125;  </span><br><span class="line">        return single;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//饿汉式单例类.在类初始化时，已经自行实例化 </span><br><span class="line">public class Singleton1 &#123;</span><br><span class="line">    private Singleton1() &#123;&#125;</span><br><span class="line">    private static final Singleton1 single = new Singleton1();</span><br><span class="line">    //静态工厂方法 </span><br><span class="line">    public static Singleton1 getInstance() &#123;</span><br><span class="line">        return single;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="四大组件是运行在主线程还是子线程"><a href="#四大组件是运行在主线程还是子线程" class="headerlink" title="四大组件是运行在主线程还是子线程"></a>四大组件是运行在主线程还是子线程</h2><p>安卓四大组件：Activity、Service、BroadcastReceiver和ContentProvider</p><p><strong>Activity组件</strong>的主要作用是展示一个界面并和用户交互，它扮演的是一种前台界面的角色、</p><p><strong>Service类</strong>似于其他应用程序的对象，运行在<strong>主线程</strong>中。这就意味着你如果在服务中进行耗时的操作，你需要开启一个子线程去处理这个操作，不然在服务中超过20秒未响应会发生ANR导致程序崩溃。IntentService的出现就是为了解决在服务中操作耗时任务的。</p><p>音乐软件被切换后，仍然能够播放音乐，浏览器软件被切换后，下载依然进行。</p><p><strong>BroadcastReceiver</strong>是允许应用接收来自各处的广播信息，而<strong>ContentProvider</strong>则是主要用于跨应用程序的数据共享，因此数据对象不同。具体应用到场景上，广播接收器主要是应用接收感知系统的信息与变化，如终端的息屏亮屏，有网没网、短信等信息，而内容提供器则是主要和不同应用之间交互共享数据，如调用本地的图片（图库），或者访问其联系人等数据。<br>四个组件正常情况都是在<strong>主线程</strong>运行的，主线程又叫UI线程，顾名思义，用户触摸产生的反馈，绘制的执行都发生在这个线程。</p><h2 id="Service执行耗时操作"><a href="#Service执行耗时操作" class="headerlink" title="Service执行耗时操作"></a>Service执行耗时操作</h2><p>Service也是运行在主线程，Service的onStartCommand() 和 onBind() 方法中不能执行耗时操作，IntentService是继承Service的抽象类，在IntentService中有一个工作线程来处理耗时操作。</p><h2 id="Activity启动模式"><a href="#Activity启动模式" class="headerlink" title="Activity启动模式"></a>Activity启动模式</h2><p><strong>standard、singleTop、singTask、singleInstance</strong></p><p>（1）standard模式<br>    特点：1.Activity的默认启动模式<br>              2.每启动一个Activity就会在栈顶创建一个新的实例。例如：闹钟程序<br>    缺点：当Activity已经位于栈顶时，而再次启动Activity时还需要在创建一个新的实例，不能直接复用。</p><p>（2）singleTop模式<br>    特点：该模式会判断要启动的Activity实例是否位于栈顶，如果位于栈顶直接复用，否则创建新的实例。 例如：浏览器的书签。<br>    缺点：如果Activity并未处于栈顶位置，则可能还会创建多个实例。</p><p>（3）singleTask模式<br>    特点：使Activity在整个应用程序中只有一个实例。每次启动Activity时系统首先检查栈中是否存在当前Activity实例，如果存在<br>              则直接复用，并把当前Activity之上所有实例全部出栈。例如：浏览器主界面。</p><p>（4）singleInstance模式<br>    特点：该模式的Activity会启动一个新的任务栈来管理Activity实例，并且该实例在整个系统中只有一个。无论从那个任务栈中    启动该Activity，都会是该Activity所在的任务栈转移到前台，从而使Activity显示。主要作用是为了在不同程序中共享一个Activity实例。</p><p>总结：Activity 的四种启动模式各有特色，在实际开发中，根据实际情况来选择合适的启动方式即可。</p><h2 id="程序中只能唯一一个页面，用哪种启动模式"><a href="#程序中只能唯一一个页面，用哪种启动模式" class="headerlink" title="程序中只能唯一一个页面，用哪种启动模式"></a>程序中只能唯一一个页面，用哪种启动模式</h2><h2 id="Android-的-ANR"><a href="#Android-的-ANR" class="headerlink" title="Android 的 ANR"></a>Android 的 ANR</h2><p>​ANR，是“Application Not Responding”的缩写，即“应用程序无响应”。如果你应用程序在UI线程被阻塞太长时间，就会出现ANR，通常出现ANR，系统会弹出一个提示提示框，让用户知道，该程序正在被阻塞，是否继续等待还是关闭。</p><h2 id="Android-Handle机制"><a href="#Android-Handle机制" class="headerlink" title="Android Handle机制"></a>Android Handle机制</h2><h2 id="子线程里面使用Handler，给主线程发送消息"><a href="#子线程里面使用Handler，给主线程发送消息" class="headerlink" title="子线程里面使用Handler，给主线程发送消息"></a>子线程里面使用Handler，给主线程发送消息</h2><p>一个线程中只能存在一个 Looper，Looper 是保存在 ThreadLocal 中的。主线程（UI 线程）已经创建了一 个 Looper，所以在主线程中不需要再创建 Looper，但是在其他线程中需要创建Looper。每个线程中可以有多个 Handler，即一个 Looper 可以处理来自多个 Handler 的消息。 Looper 中维护一个 MessageQueue，来维护消息队列，消息队列中的 Message 可以来自不同的 Handler。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">//主线程 在UI中的oncreate中</span><br><span class="line">  mhandler=new Handler(Looper.getMainLooper())&#123;</span><br><span class="line">            @Override</span><br><span class="line">            public void handleMessage(Message msg) &#123;</span><br><span class="line">                if(msg.what==0)&#123;</span><br><span class="line">                    Log.e(TAG, &quot;主线程收到消息:&quot;+(String) msg.obj );</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">//子线程</span><br><span class="line"> class Ctrl extends Thread &#123;</span><br><span class="line"> </span><br><span class="line">        Message msg;</span><br><span class="line">        public  void  run()&#123;</span><br><span class="line">            while (true)&#123;</span><br><span class="line">                try &#123;</span><br><span class="line">                    Thread.sleep(1000);</span><br><span class="line">                    msg=new Message();</span><br><span class="line">                    msg.what=0;</span><br><span class="line">                    msg.obj=&quot;hello&quot;;</span><br><span class="line">                    mhandler.sendMessage(msg);</span><br><span class="line">                &#125; catch (InterruptedException e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>mhandler.sendMessage(msg);</p><h2 id="子线程更新UI方式"><a href="#子线程更新UI方式" class="headerlink" title="子线程更新UI方式"></a>子线程更新UI方式</h2><p>方法一：</p><p>主线程中定义Handler</p><p>子线程发消息，通知Handler更新UI</p><p>方法二：</p><p>在子线程中通过**runOnUiThread()**方法更新UI，如果在非上下文类中，通过传递上下文实现调用。</p><p>方法三：</p><p>AsyncTask</p><p>Asynctask是一个抽象类，它是Android封装的一个轻量级异步类（轻量级体现在使用方便，代码简洁）,它可以在线程池中执行后台任务，然后把执行的进度和最终的结果呈现给主线程，并且更新UI。<br> Asynctask内部封装了两个线程池（<code>SerialExecutor</code>和<code>THREAD_POOL_EXECUTOR</code>），和一个<code>Handler（IntentHandler）</code>。</p><h2 id="两个Activity之间跳转执行生命周期"><a href="#两个Activity之间跳转执行生命周期" class="headerlink" title="两个Activity之间跳转执行生命周期"></a>两个Activity之间跳转执行生命周期</h2><p>比如说有两个 Activity ，A 和 B，当在 A 里面激活 B 组件的时候, A 会调用 onPause()方法,然后 B 调用 onCreate() 、onStart()、onResume()，此时 B 覆盖了窗体, A 会调用 onStop() 方法，当然如果 B 是个透明的，或者是对话框的样式，就不会调用 A 的 onStop() 方法。<br>此外，倘若 B 已经存在 Activity 栈中，则无需调用 onCreate() 方法。</p><h2 id="为什么用Fragment而不是View"><a href="#为什么用Fragment而不是View" class="headerlink" title="为什么用Fragment而不是View"></a>为什么用Fragment而不是View</h2><p>1、Fragment的复用粒度更大。Fragment有<strong>完整的生命周期</strong>，从代码设计角度讲可以提高内聚性，不同情况下还可以设计不同的Fragment，比如<strong>横屏和竖屏</strong>情况下View的显示不一样，那么可以建立2个不同的Fragment去处理，代码上面可以有效的扩展。</p><p>从形态上讲和Activity更为接近，当然从编程角度上看也比View更为复杂。但是Fragment可以组装更多的View同一展示，而且生命周期有助于资源的管理。</p><p>2、<strong>简单的直接view</strong>，复杂的才用fragment，fragment资源消耗比较大。</p><p>3、一个fragment必须总是绑定到一个activity中，虽然fragment有自己的生命周期，但同时也被它的宿主activity的生命周期直接影响。<br>大部分情况下，Fragment用来封转UI的模块化组件；但是也可以创建没有UI的Fragment来提供后台行为，该行为会一直持续到Activity重新启动。这特别适合于定期和UI交互的后台任务或者当因配置改变而导致Activity重新启动是，保存状态变得特别重要的场合。</p><h2 id="动态AddView-和使用RecyclerView的区别"><a href="#动态AddView-和使用RecyclerView的区别" class="headerlink" title="动态AddView 和使用RecyclerView的区别"></a>动态AddView 和使用RecyclerView的区别</h2><h2 id="LinkList-与ArrayList"><a href="#LinkList-与ArrayList" class="headerlink" title="LinkList 与ArrayList"></a>LinkList 与ArrayList</h2><p>ArrayList：</p><p> ArrayList是基于<strong>动态数组</strong>的数据结构。</p><p>因为是数组，所以ArrayList在初始化的时候，有<strong>初始大小10</strong>，插入新元素的时候，会判断是否需要扩容，扩容的步长是<strong>0.5倍原容量</strong>，扩容方式是利用数组的复制，因此有一定的开销；</p><p>LinkedList：</p><p>内部使用基于链表的数据结构实现存储，LinkedList有一个内部类作为存放元素的单元，里面有三个属性，用来存放元素本身以及前后2个单元的引用，另外LinkedList内部还有一个header属性，用来标识起始位置，LinkedList的第一个单元和最后一个单元都会指向header，因此形成了一个<strong>双向的链表结构。</strong></p><h2 id="UDP和TPC的区别，在网络协议哪一层"><a href="#UDP和TPC的区别，在网络协议哪一层" class="headerlink" title="UDP和TPC的区别，在网络协议哪一层"></a>UDP和TPC的区别，在网络协议哪一层</h2><p><em>TCP 和 UDP 是负责提供端到端通信的<strong>传输层协议</strong>。TCP 是面向连接的协议，而 UDP 是无连接协议</em>。</p><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/watermark%2Ctype_ZmFuZ3poZW5naGVpdGk%2Cshadow_10%2Ctext_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTQ0NTM4OTg%3D%2Csize_16%2Ccolor_FFFFFF%2Ct_70.png" alt="img"></p><h2 id="进程通信方式"><a href="#进程通信方式" class="headerlink" title="进程通信方式"></a>进程通信方式</h2><p>每个进程的用户地址空间都是独立的，一般而言是不能互相访问的，但内核空间是每个进程都共享的， 所以进程之间要通信必须通过内核。</p><p>进程间通信目的一般有共享数据，数据传输，消息通知，进程控制等。以 Unix&#x2F;Linux为例，介绍几种重要的进程间通信方式：<strong>管道、消息队列、****共享内存、信号量、信号、Socket</strong>。</p><p><strong>共享内存的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中</strong>。</p><p><strong>跨网络与不同主机上的进程之间通信，就需要Socket通信了</strong>。</p><h2 id="Android进程通信"><a href="#Android进程通信" class="headerlink" title="Android进程通信"></a>Android进程通信</h2><p>使用<strong>Bundle</strong></p><p>　　我们都知道Android中三大组件Activity，Service，Receiver都支持在Intent中传递Bundle数据，而Bundle实现了Parcelable接口，所以它可以方便的在不同的进程间进行传输。当我我们在一个进程中启动另外一个进程的Activity、Service、Receiver时，我们就可以在Bundle中附加我们所需要传输给远程进程的信息并通过intent发送出去。这里注意，我们传输的数据必须能够被序列化。</p><h2 id="快排"><a href="#快排" class="headerlink" title="快排"></a>快排</h2><p>快排通过中间取哨兵优化，在i&#x3D;&#x3D;j时停止</p><h2 id="三次握手与四次挥手"><a href="#三次握手与四次挥手" class="headerlink" title="三次握手与四次挥手"></a>三次握手与四次挥手</h2><p><strong>1、为什么需要三次握手</strong></p><p>目的：为了防止<strong>已失效的连接请求报文段</strong>突然又传送到了服务端，因而产生错误。主要防止资源的浪费。</p><p>具体过程：</p><p>　　当客户端发出第一个连接请求报文段时并没有丢失，而是在某个网络节点出现了长时间的滞留，以至于延误了连接请求在某个时间之后才到达服务器。这应该是一个早已失效的报文段。但是服务器在收到此失效的连接请求报文段后，以为是客户端的一个新请求，于是就想客户端发出了确认报文段，同意建立连接。假设不采用三次握手，那么只要服务器发出确认后，新的连接就可以建立了。但是由于客户端没有发出建立连接的请求，因此不会管服务器的确认，也不会向服务器发送数据，但服务器却以为新的运输连接已经建立，一直在等待，所以，服务器的资源就白白浪费掉了。</p><p><strong>1.1、如果在TCP第三次握手中的报文段丢失了会出现什么情况？</strong></p><p>　　客户端会认为此连接已建立，如果客户端向服务器发送数据，服务器将以RST包响应，这样就能感知到服务器的错误了。</p><p><strong>2、为什么要四次挥手</strong></p><p>　　为了保证在最后断开的时候，<strong>客户端能够发送最后一个ACK报文段能够被服务器接收到</strong>。如果客户端在收到服务器给它的断开连接的请求之后，回应完服务器就直接断开连接的话，若服务器没有收到回应就无法进入CLOSE状态，所以客户端要等待两个最长报文段寿命的时间，以便于服务器没有收到请求之后重新发送请求。</p><p>　　防止“已失效的连接请求报文”出现在连接中，在释放连接的过程中会有一些无效的滞留报文，这些报文在经过2MSL的时间内就可以发送到目的地，不会滞留在网络中。<strong>这样就可以避免在下一个连接中出现上一个连接的滞留报文了</strong>。</p><h2 id="HTTP"><a href="#HTTP" class="headerlink" title="HTTP"></a>HTTP</h2><h3 id="http1-0"><a href="#http1-0" class="headerlink" title="http1.0"></a>http1.0</h3><p>HTTP1.0最早在网页中使用是在1996年，那个时候只是使用一些较为简单的网页上和网络请求上,是一种<strong>无状态、无连接</strong>的应用层协议，几年后被HTTP1.1代替并广泛使用</p><h3 id="http1-1"><a href="#http1-1" class="headerlink" title="http1.1"></a>http1.1</h3><ol><li>http1.1基于<strong>文本解析</strong>,把所有请求和响应作为纯文本</li><li>http1.1加入了<strong>缓存处理（强缓存和协商缓存）</strong></li><li>http1.1拥有长连接，并支持请求<strong>管道化</strong>（<code>pipelining</code>），</li><li>http1.1流控制基于<strong>tcp连接</strong>。当连接建立时，两端通过系统默认机制建立缓冲区。并通过ack报文来通知对方接收窗口大小，因为http1.1 依靠传输层来避免流溢出，每个tcp连接需要一个独立的流控制机制</li></ol><p><strong>缓存处理（强缓存和协商缓存）</strong></p><p>浏览器缓存能优化性能，而浏览器缓存分为<strong>强缓存</strong>和<strong>协商缓存</strong>，都是从客户端读取缓存 <strong>强缓存</strong></p><ol><li>强缓存不发送请求，直接读取资源，可以获得返回200的状态码</li><li>利用http头中的<code>Expires</code>和<code>Cache-Control</code>两个字段来控制，都用来表示资源的缓存时间，Expires能设置失效时间，而Cache-Control能做到更多选项更细致，如果同时设置的话，其优先级<strong>高于</strong>Expires</li></ol><p><strong>协商缓存</strong></p><ol><li>通过服务器来确定缓存资源是否可用，通过request header判断是否命中请求，命中后返回304状态码，并返回新的request header通知客户端从缓存里取</li><li>普通刷新会启用弱缓存，忽略强缓存。只有在地址栏或收藏夹输入网址、通过链接引用资源等情况下，浏览器才会启用强缓存</li><li>如果时间过期，则向服务器发送header带有If-None-Match和If-Modified-Since的请求，回到1</li></ol><h3 id="http2"><a href="#http2" class="headerlink" title="http2"></a>http2</h3><ol><li>http2相比于http1.1，<strong>性能</strong>大幅度提升</li><li>http2通过一个连接来<strong>多路复用</strong></li><li>http2拥有<strong>头部压缩</strong></li><li>http2拥有<strong>新的二进制格式</strong>，使用二进制框架层把所有消息封装成二进制，且仍然保持http语法</li><li>http2允许客户端和服务器端实现他们自己的流控制机制，而不是依赖传输层,两端在传输层交换可用的缓冲区大小，来让他们在多路复用流上设置自己的接收窗口</li><li>http2让服务器可以将响应主动“<strong>推送</strong>”到客户端缓存中</li></ol><h3 id="htpp2头部压缩"><a href="#htpp2头部压缩" class="headerlink" title="htpp2头部压缩"></a>htpp2头部压缩</h3><ol><li>http2头部压缩又称为<strong>HAPCK</strong>，<strong>设计简单而灵活</strong>，是因为HPACK格式有意地<code>简单</code>且<code>不灵活</code>能降低由于实现错误而导致的互操作性或安全问题的风险</li><li>http1.1没有头部压缩，随着请求增加，冗余头部字段会不必要地占用带宽，从而显着增加延迟，而头部压缩可消除冗余报头字段，限制已知安全攻击的漏洞，并且在受限环境中使用有限的内存要求</li></ol><h3 id="http2多路复用"><a href="#http2多路复用" class="headerlink" title="http2多路复用"></a>http2多路复用</h3><ol><li>http 性能优化的关键并不在于高带宽，而是低延迟</li><li>tcp 连接会随着时间进行自我「调谐」，起初会限制连接的最大速度，如果数据成功传输，会随着时间的推移提高传输的速度,这种调谐则被称为 tcp 慢启动,由于这种原因，让原本就具有突发性和短时性的 http 连接变的十分低效</li><li>http&#x2F;2 通过让所有数据流共用同一个连接，可以更有效地使用 tcp 连接，让高带宽也能真正的服务于 http 的性能提升。而http1.1存在低性能的线头阻塞，一旦有一个请求超时，便会出现阻塞等待的情况</li></ol><h3 id="http3"><a href="#http3" class="headerlink" title="http3"></a>http3</h3><p>之前说了http2，那么http3就是为了解决http2相关问题而诞生，它基于一个新的传输层协议<strong>QUIC</strong>，而http3就是建立一个在QUIC上运行的HTTP新规范，而http3之前的版本都是基于TCP，QUIC就是为了替代TCP，解决TCP的一些缺陷</p><p><strong>tcp</strong></p><ol><li><strong>不支持流级复用</strong>，TCP会将所有对象序列化在同一个流中，因此，它不知道TCP段的对象级分区，无法在同一个流中复用数据包</li><li><strong>会产生冗余通信</strong>，tco三次连接握手会有冗余的消息交换序列</li><li><strong>可能会间歇性地挂起数据传输</strong>，tcp中有个因为序列顺序处理丢失的问题的缺陷称为行头阻塞</li></ol><p><strong>QUIC</strong></p><ol><li>同样拥有<strong>头部压缩</strong>，并优化了对乱序发送的支持，也优化了压缩率</li><li>放弃tcp，通过<strong>udp</strong>建立，提高了连接建立的速度，降低了延迟</li><li>tcp本身是无法解决<strong>队头拥塞</strong>，quic则<strong>解决</strong>了这个问题</li><li>Connection ID使得http3支持<strong>连接迁移</strong>以及NAT的重绑定</li></ol><h2 id="非对称加密的过程，公钥私钥"><a href="#非对称加密的过程，公钥私钥" class="headerlink" title="非对称加密的过程，公钥私钥"></a>非对称加密的过程，公钥私钥</h2><p>1、区别：加密一般分为两种，对称加密和非对称加密。对称加密就是加密解密都用同一个秘钥，比如DES、3DES（TripleDES）和AES等。<br>非对称加密就是加密和解密不是用的同一种秘钥，比如RSA算法、DSA算法、ECC算法、DH算法等。<br>在非对称加密中，用来加密的秘钥叫公钥，用来解密的秘钥叫私钥。公钥和私钥都是成对生成的，公钥分发给其他人用来加密，私钥用来解密。<br>2、优缺点：<br>对称加密：解密速度快，但保密性差。<br>非对称加密：加密算法保密性好，它消除了最终用户交换密钥的需要。但是加解密速度要远远低于对称加密。</p><h2 id="进程与线程"><a href="#进程与线程" class="headerlink" title="进程与线程"></a>进程与线程</h2><h2 id="线程如何切换的，谁负责切换"><a href="#线程如何切换的，谁负责切换" class="headerlink" title="线程如何切换的，谁负责切换"></a>线程如何切换的，谁负责切换</h2><p>cpu</p><h2 id="CPU-调度算法"><a href="#CPU-调度算法" class="headerlink" title="CPU 调度算法"></a>CPU 调度算法</h2><p>先来先服务调度（First Come First Served，FCFS）</p><p>最短作业优先调度（Shortest Job First，SJF）</p><p>优先级调度（Highest Privilege First，HPF）</p><p>高响应比优先调度（Highest Response Ratio NextHRRN）</p><p>轮转法调度（Round Robin，RR）</p><p>多级队列调度</p><p>多级反馈队列调度</p><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/watermark%2Ctype_ZmFuZ3poZW5naGVpdGk%2Cshadow_10%2Ctext_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RsOTYyNDU0%2Csize_16%2Ccolor_FFFFFF%2Ct_70.png" alt="img"></p><h2 id="锁的概念，乐观锁，悲观锁，关键字"><a href="#锁的概念，乐观锁，悲观锁，关键字" class="headerlink" title="锁的概念，乐观锁，悲观锁，关键字"></a>锁的概念，乐观锁，悲观锁，关键字</h2><p>程序中的锁，则是用来保证我们数据安全的机制和手段</p><p><strong>悲观锁</strong><br><strong>悲观锁（Pessimistic Lock）：</strong> 就是很悲观，每次去拿数据的时候都认为别人会修改。所以每次在拿数据的时候都会上锁。这样别人想拿数据就被挡住，直到悲观锁被释放，悲观锁中的共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程</p><p>但是在效率方面，处理加锁的机制会产生额外的开销，还有增加产生死锁的机会。另外还会降低并行性，如果已经锁定了一个线程A，其他线程就必须等待该线程A处理完才可以处理</p><p>数据库中的行锁，表锁，读锁（共享锁），写锁（排他锁），以及syncronized实现的锁均为悲观锁<br><strong>乐观锁</strong><br><strong>乐观锁（Optimistic Lock）：</strong> 就是很乐观，每次去拿数据的时候都认为别人不会修改。所以不会上锁，但是如果想要更新数据，则会在更新前检查在读取至更新这段时间别人有没有修改过这个数据。如果修改过，则重新读取，再次尝试更新，循环上述步骤直到更新成功（当然也允许更新失败的线程放弃操作）,乐观锁适用于多读的应用类型，这样可以提高吞吐量</p><h2 id="Lock-锁"><a href="#Lock-锁" class="headerlink" title="Lock 锁"></a>Lock 锁</h2><p>​在已经有了同步关键字synchronize的的情况下，Java依然在5.0版本中新增了一个同步锁对象lock.又称显示锁，之锁以新增它,是因为synchronize有一些不足，究竟synchronize有哪些不足？在后续课程synchronize与lock的区别，一节中详细介绍，本节主要是来介绍显示锁lock及使用，为什么叫显示锁？是因为我们可以手动的去获取锁与释放锁。之前使用synchronize的的时候，则是自动获取锁与释放锁，锁以synchronize的被称之为隐式锁，lock锁被称之为显示锁。</p><h2 id="GC算法，什么时候回收，怎么回收，如何查看对象有没有被引用"><a href="#GC算法，什么时候回收，怎么回收，如何查看对象有没有被引用" class="headerlink" title="GC算法，什么时候回收，怎么回收，如何查看对象有没有被引用"></a>GC算法，什么时候回收，怎么回收，如何查看对象有没有被引用</h2><p>​ 判断对象可被GC回收有两种办法分别是：<strong>引用计数算法</strong>和<strong>根可达性算法</strong>。</p><p>​引用计数算法是一个已经被淘汰的算法，它是给每个对象加一个计数器，当有其他对象引用该对象时，该对象的计数器加一，当这个引用失效时，计数器就会减一，当该对象的计数器为零时，就会认为该对象可以被所回收。</p><p>​引用计数算法是一个简单并且高效的算法，但这种算法却有一个非常大的弊端。就是这种算法会造成对象的循环引用，导致即使这个对象不再被需要，仍然存在一个一直指向它的引用，使得计数器不为零，导致该对象无法被回收，造成内存空间的浪费。</p><p>​根可达性算法是JVM默认的算法，他的原理就是定义一系列的根，我们把这些根称为：GC Roots。从GC Roots开始向下搜索，中间查找的路径被称为：引用链。</p><p>​当一个对象到GC Roots之间没有任何引用链相连接时，我们就认为这个对象可以被GC回收。</p><p>根可达性很好的解决了对象循环引用问题。</p><h2 id="泛型"><a href="#泛型" class="headerlink" title="泛型"></a>泛型</h2><p>泛型：就是指在类定义时不会设置类中的属性或方法参数的具体类型，而是在类使用时（创建对象）再进行类型的定义。会在编译期检查类型是否错误。</p><h2 id="堆栈，new是堆还是栈"><a href="#堆栈，new是堆还是栈" class="headerlink" title="堆栈，new是堆还是栈"></a>堆栈，new是堆还是栈</h2><p>栈由系统自动分配内存，用于存放函数参数值和局部变量等。<br>堆由开发人员进行分配和释放，若不释放，程序结束时则&#x2F;由于操作系统自动回收。</p><p>基本数据类型共8类，byte、short、int、long、float、double、char、boolean。</p><p>—<em>基本类型:变量名和值都放在栈中</em>; —引用类型:变量名(存放内存地址值,指向所引用的对象)放在栈中,该变量所指向的对象放在堆中。</p><h2 id="注解"><a href="#注解" class="headerlink" title="注解"></a>注解</h2><p>注解的英文名叫“Annotation”，是 Java 中给类、方法以及成员变量等元素增加元数据的方式。<strong>换言之注解就是用于描述这些元素的。</strong></p><p>Java 的注解可以应用在类、接口、方法、方法的参数、成员变量和方法内的局部变量之上</p><p>@Override 注解用于标注方法，它说明了被标注的方法重载了父类的方法，起到了断言的作用。如果我们在一个没有覆盖父类方法的方法上应用 @Override 注解时，Java编译器会告警。</p><h2 id="JVM内存模型，寄存器"><a href="#JVM内存模型，寄存器" class="headerlink" title="JVM内存模型，寄存器"></a>JVM内存模型，寄存器</h2><h2 id="Glide"><a href="#Glide" class="headerlink" title="Glide"></a>Glide</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Glide.with(this).load(url).into(imageView);</span><br></pre></td></tr></table></figure><p>Glide的缓存分为两个模块，一个是内存缓存，一个是硬盘缓存。</p><p>内存缓存的作用是防止应用重复将图片数据读取到内存当中；</p><p>硬盘缓存的作用是防止应用重复从网络或其他地方下载和读取数据。</p><h2 id="OKhttp"><a href="#OKhttp" class="headerlink" title="OKhttp"></a>OKhttp</h2><h3 id="1、拿到OkHttpClient对象"><a href="#1、拿到OkHttpClient对象" class="headerlink" title="1、拿到OkHttpClient对象"></a>1、拿到OkHttpClient对象</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">okhttpclient client=new OKhttpclient（）；</span><br></pre></td></tr></table></figure><h3 id="2-构造Request对象"><a href="#2-构造Request对象" class="headerlink" title="2 . 构造Request对象"></a>2 . 构造Request对象</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Request request = new Request.Builder()</span><br><span class="line">                .get()</span><br><span class="line">                .url(&quot;https:www.baidu.com&quot;)</span><br><span class="line">                .build();</span><br></pre></td></tr></table></figure><h3 id="3、将Request封装为Call"><a href="#3、将Request封装为Call" class="headerlink" title="3、将Request封装为Call"></a>3、将Request封装为Call</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Call call = client.newCall(request);</span><br></pre></td></tr></table></figure><h3 id="4-根据需要调用同步或者异步请求方法"><a href="#4-根据需要调用同步或者异步请求方法" class="headerlink" title="4 . 根据需要调用同步或者异步请求方法"></a>4 . 根据需要调用同步或者异步请求方法</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">//同步调用,返回Response,会抛出IO异常</span><br><span class="line">Response response = call.execute();</span><br><span class="line"></span><br><span class="line">//异步调用,并设置回调函数</span><br><span class="line">call.enqueue(new Callback() &#123;</span><br><span class="line">    @Override</span><br><span class="line">    public void onFailure(Call call, IOException e) &#123;</span><br><span class="line">        Toast.makeText(OkHttpActivity.this, &quot;get failed&quot;, Toast.LENGTH_SHORT).show();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void onResponse(Call call, final Response response) throws IOException &#123;</span><br><span class="line">        final String res = response.body().string();</span><br><span class="line">        runOnUiThread(new Runnable() &#123;</span><br><span class="line">            @Override</span><br><span class="line">            public void run() &#123;</span><br><span class="line">                contentTv.setText(res);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><h2 id="Protobuf"><a href="#Protobuf" class="headerlink" title="Protobuf"></a>Protobuf</h2><p>因为TCP协议只能发送字节流，因此需要将数据序列化。protobuf序列化和反序列化的时间开销都很少。因为<strong>序列化后的数据都是以二进制数据存储</strong>，因此空间开销也少很多。</p><p>ProtoBuf是跨语言的，使用ProtoBuf的第一步是先定一个<strong>proto 文件</strong>，使用生成器产生不同语音的代码。</p><h2 id="Git"><a href="#Git" class="headerlink" title="Git"></a>Git</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git status  查看当前状态</span><br><span class="line">git log  查看提交日志</span><br><span class="line">git merge dev  合并dev分支至当前分支</span><br><span class="line">git add .      添加当前目录全部文件至暂存区</span><br><span class="line">git commit -m &#x27;测试&#x27;     提交，提交信息为测试</span><br><span class="line">git push origin master  推送至远端分支（master为需要推送分支，按实际需要选择）</span><br><span class="line">git pull origin master  合并远端分支至本地 (git pull 等于 git fetch + git merge)</span><br><span class="line">git pull --rebase origin master rebase方式合并远端分支至本地</span><br><span class="line">git branch 查看当前分支</span><br><span class="line">git branch dev 创建dev分支  （dev可选）</span><br><span class="line">git branch -d dev 删除dev分支</span><br><span class="line">git branch -r 查看远程分支</span><br><span class="line">git branch -a 查看所有分支 （包括远程分支）</span><br><span class="line">git checkout master 切换至master分支</span><br><span class="line">git checkout -b dev 创建dev分支并切换至dev分支</span><br><span class="line">git checkout -b dev origin/dev 创建远程分支到本地</span><br><span class="line">git restore file 丢弃工作区修改（file为具体文件名称）</span><br><span class="line">git restore * 丢弃所有工作区修改</span><br><span class="line">git restore --staged file  回退暂存区文件 不会更改文件内容</span><br><span class="line">git rebase --continue   rebase后继续操作</span><br><span class="line">git rebase --abort 退出rebase 操作</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="图片加载过程"><a href="#图片加载过程" class="headerlink" title="图片加载过程"></a>图片加载过程</h2><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/d66350ccda3766cc89bd9f70538a7e0f.jpeg" alt="img"></p><p>第一步，资源匹配：</p><p>计算设备<strong>dpi</strong>，然后去dpi匹配的drawable文件夹查找图片，如果合适不缩放图片直接显示，如果不合适对图片进行缩放。</p><p>第二部，解码资源：</p><p>对图片资源进行解码，并获得图片资源Bitmap。</p><p>BitmapFactory.doDecode()进行解码；</p><p>先采样再缩放，输出Bitmap。</p><h2 id="setImageResource和setImageBitmap"><a href="#setImageResource和setImageBitmap" class="headerlink" title="setImageResource和setImageBitmap"></a>setImageResource和setImageBitmap</h2><p>第一种setImageResource 是从资源drawable中通过资源id找到文件转成可绘制对象drawable 然后绘制。这个方法会自动适配分辨率。适用于不频繁设置图片图片资源不会太大的情况。 但是</p><p>对于大图片时或者你需要不断的重复的设置图片 调用这个方法生成的drawable里一样会生成一个bitmap对象 因为bitmap是通过bitmapfactory生成的 有一部分要调用C库所以需要开辟一部分</p><p>native本地内存空间以及一部分jvm的内存空间。而native本地内存空间是C开辟的 jvm的gc垃圾回收器是回收不了这部分空间的，这个时候如果你频繁的调用setImageResource且没有手动调</p><p>recycle native的内存空间很难被释放掉。jvm的内存也不会及时得到回收这样就相当容易导致内存溢出。</p><hr><p>而setImageBitmap 当你需要频繁设置大图片时 通过bitmapfactory生成bitmap然后设置 然后每次设置前将之前的bitmap手动掉recycle 置为可回收状态 这样很大程度能防止内存泄露溢出</p><p>所以看你的需求 你的图片是不频繁设置且不会太大就用第一种 如果需求不断的重复更新设置那最好用第二个并且记住手动及时回收后再设置 如果有用到图片缓存的话则不要将大图片列入缓存</p><p>中 图片的缓存模块最好只存储小且利用频繁的图片以节省内存和时间开销 大图则需做手动回收 以保证低端点的机子不会oom</p><p>但通过查阅资料学习，我发现像setImageResource这些函数在完成decode后最终都是通过Java层的<strong>Createbitmap</strong>来完成，需要消耗更多内存。最优的降低内存的方式，是通过使用BitmapFactory.decodeStream()方法来创建一个bitmap，再将其设置为Imageview 的source，优化的原理在于BitmapFactory是通过JNI调用底层C&#x2F;C++实现的驱动完成了decode，从而节省了java空间。</p><p>但是随着Android的变迁Bitmap的回收机制也是在变化。</p>]]></content>
      
      
      <categories>
          
          <category> 面经 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Android </tag>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SCI Collections</title>
      <link href="/2021/09/09/SCI-Collections/"/>
      <url>/2021/09/09/SCI-Collections/</url>
      
        <content type="html"><![CDATA[<h1 id="SCI-Collections"><a href="#SCI-Collections" class="headerlink" title="SCI Collections"></a>SCI Collections</h1><h3 id="录用比较易-amp-审稿周期三月左右"><a href="#录用比较易-amp-审稿周期三月左右" class="headerlink" title="录用比较易 &amp; 审稿周期三月左右"></a>录用比较易 &amp; 审稿周期三月左右</h3><p>JOURNAL OF INTELLIGENT &amp; ROBOTIC SYSTEMS</p><table><thead><tr><th><a href="https://www.letpub.com.cn/index.php?page=journalapp&view=search&searchname=&searchissn=&searchfield=&searchimpactlow=&searchimpacthigh=&searchimpacttrend=&searchscitype=SCISCIE&searchcategory1=%E5%B7%A5%E7%A8%8B%E6%8A%80%E6%9C%AF&searchcategory2=%E8%AE%A1%E7%AE%97%E6%9C%BA%EF%BC%9A%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD&searchjcrkind=&searchopenaccess=NO&searchsort=issn&searchsortorder=desc&currentsearchpage=1#journallisttable">ISSN</a></th><th>期刊名</th><th>综合评分</th><th><a href="https://www.letpub.com.cn/index.php?page=journalapp&view=search&searchname=&searchissn=&searchfield=&searchimpactlow=&searchimpacthigh=&searchimpacttrend=&searchscitype=SCISCIE&searchcategory1=%E5%B7%A5%E7%A8%8B%E6%8A%80%E6%9C%AF&searchcategory2=%E8%AE%A1%E7%AE%97%E6%9C%BA%EF%BC%9A%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD&searchjcrkind=&searchopenaccess=NO&searchsort=impactor&searchsortorder=desc&currentsearchpage=1#journallisttable">期刊指标</a></th><th>中科院分区</th><th>学科领域</th><th>SCI&#x2F;SCIE</th><th>是否OA</th><th>录用比例</th><th>审稿周期</th><th>近期 文章</th><th><a href="https://www.letpub.com.cn/index.php?page=journalapp&view=search&searchname=&searchissn=&searchfield=&searchimpactlow=&searchimpacthigh=&searchimpacttrend=&searchscitype=SCISCIE&searchcategory1=%E5%B7%A5%E7%A8%8B%E6%8A%80%E6%9C%AF&searchcategory2=%E8%AE%A1%E7%AE%97%E6%9C%BA%EF%BC%9A%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD&searchjcrkind=&searchopenaccess=NO&searchsort=clickcount&searchsortorder=desc&currentsearchpage=1#journallisttable">查看数</a></th></tr></thead><tbody><tr><td>0885-6125</td><td><a href="https://www.letpub.com.cn/index.php?journalid=5615&page=journalapp&view=detail">MACHINE LEARNING</a>  MACH LEARN</td><td>6.4</td><td>h-index:135  CiteScore:6.10</td><td>3区</td><td>大类：工程技术  小类：计算机：人工智能</td><td>SCI  SCIE</td><td>No</td><td>容易</td><td>较慢,6-12周</td><td><a href="https://www.letpub.com.cn/index.php?page=journalapp&view=detail&journalid=5615&xuanxiangk_id=2#xuanxk_3">文章</a></td><td>71355</td></tr><tr><td>0921-7126</td><td><a href="https://www.letpub.com.cn/index.php?journalid=344&page=journalapp&view=detail">AI COMMUNICATIONS</a>  AI COMMUN</td><td>5.2</td><td>h-index:36  CiteScore:3.70</td><td>4区</td><td>大类：工程技术  小类：计算机：人工智能</td><td>SCIE</td><td>No</td><td>容易</td><td>约3.0个月</td><td><a href="https://www.letpub.com.cn/index.php?page=journalapp&view=detail&journalid=344&xuanxiangk_id=2#xuanxk_3">文章</a></td><td>21926</td></tr><tr><td>1567-7818</td><td><a href="https://www.letpub.com.cn/index.php?journalid=6045&page=journalapp&view=detail">Natural Computing</a></td><td>4.8</td><td>h-index:34  CiteScore:3.50</td><td>4区</td><td>大类：工程技术  小类：计算机：人工智能</td><td>SCIE</td><td>No</td><td>容易</td><td>较慢,6-12周</td><td><a href="https://www.letpub.com.cn/index.php?page=journalapp&view=detail&journalid=6045&xuanxiangk_id=2#xuanxk_3">文章</a></td><td>11306</td></tr><tr><td>0899-7667</td><td><a href="https://www.letpub.com.cn/index.php?journalid=6122&page=journalapp&view=detail">NEURAL COMPUTATION</a>  NEURAL COMPUT</td><td>6.6</td><td>h-index:148  CiteScore:9.40</td><td>3区</td><td>大类：工程技术  小类：计算机：人工智能</td><td>SCI  SCIE</td><td>No</td><td>较易</td><td>约3.0个月</td><td><a href="https://www.letpub.com.cn/index.php?page=journalapp&view=detail&journalid=6122&xuanxiangk_id=2#xuanxk_3">文章</a></td><td>85035</td></tr><tr><td>1541-1672</td><td><a href="https://www.letpub.com.cn/index.php?journalid=3332&page=journalapp&view=detail">IEEE INTELLIGENT SYSTEMS</a>  IEEE INTELL SYST</td><td>7.4</td><td>h-index:111  CiteScore:9.00</td><td>2区</td><td>大类：工程技术  小类：计算机：人工智能</td><td>SCI  SCIE</td><td>No</td><td>较易</td><td>&gt;12周，或约稿</td><td><a href="https://www.letpub.com.cn/index.php?page=journalapp&view=detail&journalid=3332&xuanxiangk_id=2#xuanxk_3">文章</a></td><td>50780</td></tr><tr><td>1088-467X</td><td><a href="https://www.letpub.com.cn/index.php?journalid=3613&page=journalapp&view=detail">Intelligent Data Analysis</a>  INTELL DATA ANAL                          <strong>ccf c类</strong></td><td>5.6</td><td>h-index:43  CiteScore:1.70</td><td>4区</td><td>大类：工程技术  小类：计算机：人工智能</td><td>SCIE</td><td>No</td><td>容易</td><td>约3.0个月</td><td><a href="https://www.letpub.com.cn/index.php?page=journalapp&view=detail&journalid=3613&xuanxiangk_id=2#xuanxk_3">文章</a></td><td>52264</td></tr><tr><td>1370-4621</td><td><a href="https://www.letpub.com.cn/index.php?journalid=6128&page=journalapp&view=detail">NEURAL PROCESSING LETTERS</a>  NEURAL PROCESS LETT                           <strong>ccf c类</strong></td><td>6.4</td><td>h-index:45  CiteScore:4.20</td><td>3区</td><td>大类：工程技术  小类：计算机：人工智能</td><td>SCIE</td><td>No</td><td>容易</td><td>约3.0个月</td><td><a href="https://www.letpub.com.cn/index.php?page=journalapp&view=detail&journalid=6128&xuanxiangk_id=2#xuanxk_3">文章</a></td><td>88945</td></tr><tr><td>1474-0346</td><td><a href="https://www.letpub.com.cn/index.php?journalid=206&page=journalapp&view=detail">ADVANCED ENGINEERING INFORMATICS</a>  ADV ENG INFORM</td><td>7.6</td><td>h-index:68  CiteScore:8.60</td><td>2区</td><td>大类：工程技术  小类：计算机：人工智能</td><td>SCIE</td><td>No</td><td>较易</td><td>约4.5个月</td><td><a href="https://www.letpub.com.cn/index.php?page=journalapp&view=detail&journalid=206&xuanxiangk_id=2#xuanxk_3">文章</a></td><td>94818</td></tr><tr><td>0956-5515</td><td><a href="https://www.letpub.com.cn/index.php?journalid=4698&page=journalapp&view=detail">JOURNAL OF INTELLIGENT MANUFACTURING</a>  J INTELL MANUF</td><td>7.7</td><td>h-index:67  CiteScore:10.60</td><td>2区</td><td>大类：工程技术  小类：计算机：人工智能</td><td>SCIE</td><td>No</td><td>容易</td><td>约3.0个月</td><td><a href="https://www.letpub.com.cn/index.php?page=journalapp&view=detail&journalid=4698&xuanxiangk_id=2#xuanxk_3">文章</a></td><td>104993</td></tr><tr><td><strong>0921-0296</strong></td><td><strong><a href="https://www.letpub.com.cn/index.php?journalid=4696&page=journalapp&view=detail">JOURNAL OF INTELLIGENT &amp; ROBOTIC SYSTEMS</a>  J INTELL ROBOT SYST</strong></td><td><strong>5.6</strong></td><td><strong>h-index:62  CiteScore:5.40</strong></td><td><strong>4区</strong></td><td><strong>大类：工程技术  小类：计算机：人工智能</strong></td><td><strong>SCIE</strong></td><td><strong>No</strong></td><td><strong>容易</strong></td><td><strong>偏慢,4-8周</strong></td><td><strong><a href="https://www.letpub.com.cn/index.php?page=journalapp&view=detail&journalid=4696&xuanxiangk_id=2#xuanxk_3">文章</a></strong></td><td><strong>76262</strong></td></tr><tr><td>1041-4347</td><td><a href="https://www.letpub.com.cn/index.php?journalid=3399&page=journalapp&view=detail">IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING</a>  IEEE T KNOWL DATA EN</td><td>7.9</td><td>h-index:148  CiteScore:13.30</td><td>2区</td><td>大类：工程技术  小类：计算机：人工智能</td><td>SCI  SCIE</td><td>No</td><td>较易</td><td>一般,3-8周</td><td><a href="https://www.letpub.com.cn/index.php?page=journalapp&view=detail&journalid=3399&xuanxiangk_id=2#xuanxk_3">文章</a></td><td>143407</td></tr><tr><td>1064-2307</td><td><a href="https://www.letpub.com.cn/index.php?journalid=4370&page=journalapp&view=detail">JOURNAL OF COMPUTER AND SYSTEMS SCIENCES INTERNATIONAL</a>  J COMPUT SYS SC INT+</td><td>4.8</td><td>h-index:17  CiteScore:1.60</td><td>4区</td><td>大类：工程技术  小类：计算机：人工智能</td><td>SCIE</td><td>No</td><td>容易</td><td>较慢,6-12周</td><td><a href="https://www.letpub.com.cn/index.php?page=journalapp&view=detail&journalid=4370&xuanxiangk_id=2#xuanxk_3">文章</a></td><td>15541</td></tr><tr><td>2162-237X</td><td><a href="https://www.letpub.com.cn/index.php?journalid=8837&page=journalapp&view=detail">IEEE Transactions on Neural Networks and Learning Systems</a>  IEEE T NEUR NET LEAR</td><td>9.0</td><td>h-index:180  CiteScore:19.80</td><td>1区</td><td>大类：工程技术  小类：计算机：人工智能</td><td>SCI  SCIE</td><td>No</td><td></td><td>一般,3-8周</td><td><a href="https://www.letpub.com.cn/index.php?page=journalapp&view=detail&journalid=8837&xuanxiangk_id=2#xuanxk_3">文章</a></td><td>244890</td></tr><tr><td>0218-0014</td><td><a href="https://www.letpub.com.cn/index.php?journalid=3842&page=journalapp&view=detail">INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE</a>  INT J PATTERN RECOGN</td><td>5.5</td><td>h-index:49  CiteScore:2.60</td><td>4区</td><td>大类：工程技术  小类：计算机：人工智能</td><td>SCIE</td><td>No</td><td>容易</td><td>较慢,6-12周</td><td><a href="https://www.letpub.com.cn/index.php?page=journalapp&view=detail&journalid=3842&xuanxiangk_id=2#xuanxk_3">文章</a></td><td>99072</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
          <category> 期刊 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SCI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>二学位面经</title>
      <link href="/2021/08/06/%E4%BA%8C%E5%AD%A6%E4%BD%8D%E9%9D%A2%E7%BB%8F/"/>
      <url>/2021/08/06/%E4%BA%8C%E5%AD%A6%E4%BD%8D%E9%9D%A2%E7%BB%8F/</url>
      
        <content type="html"><![CDATA[<h2 id="第二学士学位面经"><a href="#第二学士学位面经" class="headerlink" title="第二学士学位面经"></a>第二学士学位面经</h2><h3 id="金融学"><a href="#金融学" class="headerlink" title="金融学"></a>金融学</h3><h4 id="什么是商业银行，商业银行的负债业务？"><a href="#什么是商业银行，商业银行的负债业务？" class="headerlink" title="什么是商业银行，商业银行的负债业务？"></a>什么是商业银行，商业银行的负债业务？</h4><p>商业银行是用营利为目的，用多种负债来筹集资金，多项资产作为对象，具备信用创造功能的金融机构</p><p>存款货币银行的负债业务是指形成其资金来源的业务，包括自有资金和吸收的外来资金两部分。</p><p>外来资金主要是吸收存款、向中央银行借贷、向其他银行和货币市场拆借以及发行中长期金融债券等。</p><p>吸收存款包括活期存款、定期存款、储蓄存款</p><h4 id="年金和先付年金的关系"><a href="#年金和先付年金的关系" class="headerlink" title="年金和先付年金的关系"></a>年金和先付年金的关系</h4><p>先付年金就是在本期的期初付年金，这样的话，这一笔年金就可以计入周期内计算复利；</p><p>后付年金就是本期的期末付年金，这一笔年金在本期内不计入周期计算复利；</p><h4 id="存款准备金的定义，以及它的优缺点"><a href="#存款准备金的定义，以及它的优缺点" class="headerlink" title="存款准备金的定义，以及它的优缺点"></a>存款准备金的定义，以及它的优缺点</h4><p>存款准备金，是指金融机构为保证客户提取存款和资金清算需要而准备的在中央银行的存款</p><p>优点：</p><p>存款准备金制度的初始意义在于保证商业银行的支付和清算，之后逐渐演变成中央银行调控货币供应量的政策工具。</p><p>缺点：</p><p>1、作用效果过于猛烈。法定存款准备金比率的微小变动，就会造成法定准备金的较大波动，对经济造成强烈影响; </p><p>2、准备金比率的频繁变动会给银行带来许多的不确定性，增加了银行资金流动性管理的难度，因而易于受到商业银行和金融机构的反对。</p><h4 id="什么是外汇？"><a href="#什么是外汇？" class="headerlink" title="什么是外汇？"></a>什么是外汇？</h4><p>狭义上对于任何一国家的居民来说，相对于其本国的货币，一切外国的货币统称为外汇。外货就是货币。广义上外汇不仅是指外国的钞票和硬币，以外币履行支付义务的票据、银行的外币存储和以外币标示的有价证券也是外汇。</p><h4 id="什么是汇率？"><a href="#什么是汇率？" class="headerlink" title="什么是汇率？"></a>什么是汇率？</h4><p>国与国之间货币折算的比率叫做汇率，表现形式为一国货币单位所表示的另一个货币单位的价格，也称汇价。</p><h4 id="信用的概念"><a href="#信用的概念" class="headerlink" title="信用的概念"></a>信用的概念</h4><p>信用这个经济范畴指借贷行为。信用是指在商品交换或者其他经济活动中授信人在充分信任受信人能够实现其承诺的基础上，用契约关系向受信人放贷，并保障自己的本金能够回流和增值的价值运动。</p><h4 id="利息的概念"><a href="#利息的概念" class="headerlink" title="利息的概念"></a>利息的概念</h4><p>利息是指货币所有者因贷出货币或者货币资本从而从借贷人或债务人哪里获得的报酬</p><p>利率是利息除以本金。</p><h4 id="金融机构的概念"><a href="#金融机构的概念" class="headerlink" title="金融机构的概念"></a>金融机构的概念</h4><p>是指从事各种金融活动的组织，统称金融中，又称金融机构、金融中介机构。</p><p>金融机构包括银行、证券公司、保险公司、信托投资公司和基金管理公司等。 </p><h4 id="金融市场的概念"><a href="#金融市场的概念" class="headerlink" title="金融市场的概念"></a>金融市场的概念</h4><p>金融市场又称为资金市场，包括货币市场和资本市场，是资金融通市场。</p><p>金融市场属于要素市场，专门提供资本。在这个市场上可以进行资金融通，实现金融资源的配置，最终帮助实现实物资源的配置。</p><h4 id="金融工具的概念"><a href="#金融工具的概念" class="headerlink" title="金融工具的概念"></a>金融工具的概念</h4><p>金融资产又成金融工具，实现了资金从盈余部门向赤字部门的转移。</p><h4 id="数字货币的作用"><a href="#数字货币的作用" class="headerlink" title="数字货币的作用"></a>数字货币的作用</h4><p>保密、小额、监管、铸币税、新的世界货币话语权。</p><h4 id="通货膨胀，通货紧缩"><a href="#通货膨胀，通货紧缩" class="headerlink" title="通货膨胀，通货紧缩"></a>通货膨胀，通货紧缩</h4><p>通货膨胀（inflation），指在货币流通条件下，因货币供给大于货币实际需求，也即现实购买力大于产出供给，导致货币贬值，而引起的一段时间内物价持续而普遍地上涨现象，其实质是社会总需求大于社会总供给求远大于供。</p><p>通货紧缩(deflation) 是指当市场上流通货币减少，人民的货币所得减少，购买力下降，影响物价至下跌，造成通货紧缩。长期的货币紧缩会抑制投资与生产，导致失业率升高及经济衰退。通货紧缩就是产能过剩或需求不足导致物价、工资、利率、粮食、能源等各类价格持续下跌。</p><p>购买力是价格的倒数。</p><h4 id="货币的职能"><a href="#货币的职能" class="headerlink" title="货币的职能"></a>货币的职能</h4><p>具有价值尺度、流通手段、贮藏手段、支付手段和世界货币五种职能。其中最基本的职能是价值尺度和流通手段。</p><h4 id="货币制度"><a href="#货币制度" class="headerlink" title="货币制度"></a>货币制度</h4><p>货币制度涉及：货币材料的确定，货币单位的确定，流通中货币种类的确定等</p><h4 id="证券交易所的概念及特征"><a href="#证券交易所的概念及特征" class="headerlink" title="证券交易所的概念及特征"></a>证券交易所的概念及特征</h4><p>证券交易所是证券买卖双方公开交易的场所，是一个高度组织化、集中进行证券交易的市场，是整个证券市场的核心。《中华人民共和国证券法》规定，证券交易所是为证券集中交易提供场所和设施，组织和监督证券交易，实行自律管理的法人。</p><p><strong>证券交易所的特征</strong></p><p> （1）有固定的交易场所和交易时间。</p><p> （2）参加交易者为具备会员资格的证券经营机构，交易采取经纪制，即一般投资者不能直接进入交易所买卖证券，只能委托会员作为经纪人间接进行交易。</p><p> （3）交易的对象限于合乎一定标准的上市证券。</p><p> （4）通过公开竞价的方式决定交易价格。</p><p> （5）集中了证券的供求双方，具有较高的成交速度和成交率。</p><p> （6）实行“公开、公平、公正”原则，并对证券交易加以严格管理。</p><h4 id="自己提出一个关于金融学的问题并回答"><a href="#自己提出一个关于金融学的问题并回答" class="headerlink" title="自己提出一个关于金融学的问题并回答"></a>自己提出一个关于金融学的问题并回答</h4><p>货币创造机制连接宏微观，微观金融（什么人，在哪个市场上，用了什么金融工具进行交易：金融机构，金融市场，金融工具，受到约束）；宏观金融，国内货币均衡（货币供给，货币需求），国际货币均衡（汇率怎么影响国内），金融监管（一行两会）</p>]]></content>
      
      
      <categories>
          
          <category> 面经 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 金融学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>3月20日</title>
      <link href="/2021/03/20/3%E6%9C%8820%E6%97%A5/"/>
      <url>/2021/03/20/3%E6%9C%8820%E6%97%A5/</url>
      
        <content type="html"><![CDATA[<h1 id="3月20日"><a href="#3月20日" class="headerlink" title="3月20日"></a>3月20日</h1><h2 id="笔记"><a href="#笔记" class="headerlink" title="笔记"></a>笔记</h2><h3 id="白化处理"><a href="#白化处理" class="headerlink" title="白化处理"></a>白化处理</h3><h4 id="相关理论"><a href="#相关理论" class="headerlink" title="相关理论"></a>相关理论</h4><p>白化这个词，可能在深度学习领域比较常遇到，挺起来就是高大上的名词，然而其实白化是一个比PCA稍微高级一点的算法而已，所以如果熟悉PCA，那么其实会发现这是一个非常简单的算法。<br>白化的目的是去除输入数据的冗余信息。假设训练数据是图像，由于图像中相邻像素之间具有很强的相关性，所以用于训练时输入是冗余的；白化的目的就是降低输入的冗余性。</p><p>输入数据集X，经过白化处理后，新的数据X’满足两个性质：</p><ol><li>特征之间相关性较低；</li><li>所有特征具有相同的方差。<br>其实我们之前学的PCA算法中，可能PCA给我们的印象是一般用于降维操作。然而其实PCA如果不降维，而是仅仅使用PCA求出特征向量，然后把数据X映射到新的特征空间，这样的一个映射过程，其实就是满足了我们白化的第一个性质：除去特征之间的相关性。因此白化算法的实现过程，第一步操作就是PCA，求出新特征空间中X的新坐标，然后再对新的坐标进行方差归一化操作。</li></ol><h4 id="算法概述"><a href="#算法概述" class="headerlink" title="算法概述"></a>算法概述</h4><p>白化分为PCA白化、ZCA白化</p><h5 id="2-1-首先是PCA预处理"><a href="#2-1-首先是PCA预处理" class="headerlink" title="2.1 首先是PCA预处理"></a>2.1 首先是PCA预处理</h5><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/20190304191527979.png" alt="在这里插入图片描述"><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/20190304191534434.png" alt="在这里插入图片描述"><br>上面图片，左图表示原始数据X，然后我们通过协方差矩阵可以求得特征向量u1、u2，然后把每个数据点，投影到这两个新的特征向量，得到进行坐标如下：<br><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/20190304191558502.png" alt="在这里插入图片描述"><br>这就是所谓的pca处理。</p><h5 id="2-2-PCA白化"><a href="#2-2-PCA白化" class="headerlink" title="2.2 PCA白化"></a>2.2 PCA白化</h5><p>所谓的pca白化是指对上面的pca的新坐标X’,每一维的特征做一个标准差归一化处理。因为从上面我们看到在新的坐标空间中，(x1,x2)两个坐标轴方向的数据明显标准差不同，因此我们接着要对新的每一维坐标做一个标注差归一化处理：<br><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/20190304191618526.png" alt="在这里插入图片描述"><br>当然你也可以采用下面的公式：<br><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/20190304191624187.png" alt="在这里插入图片描述"><br>X’为经过PCA处理的新PCA坐标空间,然后λi就是第i维特征对应的特征值（前面pca得到的特征值），ε是为了避免除数为0。<br><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/20190304191656363.png" alt="在这里插入图片描述"></p><h5 id="2-3-ZCA白化"><a href="#2-3-ZCA白化" class="headerlink" title="2.3 ZCA白化"></a>2.3 ZCA白化</h5><p>ZCA白化是在PCA白化的基础上，又进行处理的一个操作。具体的实现是把上面PCA白化的结果，又变换到原来坐标系下的坐标：给人的感觉就像是在PCA空间做了处理完后，然后又把它变换到原始的数据空间，使得变换后的数据更接近原始数据。</p><h3 id="计算机视觉评价指标"><a href="#计算机视觉评价指标" class="headerlink" title="计算机视觉评价指标"></a>计算机视觉评价指标</h3><h4 id="图像分类"><a href="#图像分类" class="headerlink" title="图像分类"></a>图像分类</h4><p>Top-1 error rate：将输出的C维向量按照降序排列，如果最大值所对应label与ground truth label不符，则该图片属于分类错误，最后用分类错误的样本数量除以样本集的数量得到Top-1 error rate；</p><p>Top-5 error rate：将输出的C维向量按照降序排列，如果前5个对应的label没有包含ground truth label，则该图片属于分类错误，最后用分类错误的样本数量除以样本集的数量得到Top-5 error rate；</p><h4 id="目标检测"><a href="#目标检测" class="headerlink" title="目标检测"></a>目标检测</h4><h5 id="AP"><a href="#AP" class="headerlink" title="AP"></a>AP</h5><p>AP，average precision，平均精确度，比上文precision多了一个average，显然计算AP时有一个求平均的过程。在上文precision和recall的介绍中，两者是存在一定关系的，当调整算法的阈值提高recall时，precision会降低，反之，precision会提高，通俗的说就是提高recall可以让检测出来的样本更多的预测为正样本（减少FN），但这样会让一些负样本也预测为正样本（FP增高），导致precision降低。通过多次调整阈值，可以获得不同recall下的precision，最后累加这些precision求平均便得到了average precision。</p><p>预测的bounding box和ground truth bounding box之间的关系用IoU表示，IoU（Intersection over Union，交并比），指的是预测的bounding box和ground truth bounding box之间的交集和并集的面积比值，当两者完全重合时，IoU为100%，没有任何交集时为0，显然IoU值越大，模型预测的bounding box性能越好。</p><p>Top-N ranked指的对排序后的样本统计数据按照前n个样本划分N次rank，分别求出每次rank后的precision和recall，直至n&#x3D;N，N为预测的总数量。</p><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/20190918174751809.png" alt="img"></p><p>AP就是计算这条precision-recall曲线下的面积（area under curve，AUC）。</p><h5 id="mAP"><a href="#mAP" class="headerlink" title="mAP"></a>mAP</h5><p>AP指的是一个类别的指标（如上文的狗检测例子），而一个object detection任务包含多个类别，如VOC包含20类object，则会计算出20个AP，将其累加取平均便得到mAP。</p><h5 id="混淆矩阵"><a href="#混淆矩阵" class="headerlink" title="混淆矩阵"></a>混淆矩阵</h5><p>混淆矩阵又被称为错误矩阵， 在每个类别下，模型预测错误的结果数量，以及错误预测的类别和正确预测的数量都在一个矩阵下面显示出来，方便直观的评估模型分类的结果。</p>]]></content>
      
      
      <categories>
          
          <category> 随记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>自然语言处理BERT模型</title>
      <link href="/2021/01/21/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86BERT%E6%A8%A1%E5%9E%8B/"/>
      <url>/2021/01/21/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86BERT%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="自然语言处理BERT模型"><a href="#自然语言处理BERT模型" class="headerlink" title="自然语言处理BERT模型"></a>自然语言处理BERT模型</h1><h2 id="理论"><a href="#理论" class="headerlink" title="理论"></a>理论</h2><h3 id="Word2Vec模型通俗解读"><a href="#Word2Vec模型通俗解读" class="headerlink" title="Word2Vec模型通俗解读"></a>Word2Vec模型通俗解读</h3><p>向量一般采用50~300维，一般300维</p><p>余弦相似度度量</p><p>embeddings look up</p><p>神经网络前向传播计算lostfunction，后向传播通过lostfunction更新权重参数</p><h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><p>CBOW：预测中间值</p><p>Skip-gram：预测上下文</p><p>负采样模型</p><h3 id="掌握Tensorflow如何实现Word2Vec模型"><a href="#掌握Tensorflow如何实现Word2Vec模型" class="headerlink" title="掌握Tensorflow如何实现Word2Vec模型"></a>掌握Tensorflow如何实现Word2Vec模型</h3><h3 id="RNN网络架构与情感分析应用实例"><a href="#RNN网络架构与情感分析应用实例" class="headerlink" title="RNN网络架构与情感分析应用实例"></a>RNN网络架构与情感分析应用实例</h3><h3 id="自然语言处理通用框架BERT与案例解读"><a href="#自然语言处理通用框架BERT与案例解读" class="headerlink" title="自然语言处理通用框架BERT与案例解读"></a>自然语言处理通用框架BERT与案例解读</h3><h3 id="谷歌开源项目BERT源码解读与应用实例"><a href="#谷歌开源项目BERT源码解读与应用实例" class="headerlink" title="谷歌开源项目BERT源码解读与应用实例"></a>谷歌开源项目BERT源码解读与应用实例</h3><h2 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h2><h3 id="基于BERT的中文情感分析实战"><a href="#基于BERT的中文情感分析实战" class="headerlink" title="基于BERT的中文情感分析实战"></a>基于BERT的中文情感分析实战</h3><h3 id="基于BERT的中文命名实体识别实战"><a href="#基于BERT的中文命名实体识别实战" class="headerlink" title="基于BERT的中文命名实体识别实战"></a>基于BERT的中文命名实体识别实战</h3><h3 id="医学糖尿病数据命名实体识别"><a href="#医学糖尿病数据命名实体识别" class="headerlink" title="医学糖尿病数据命名实体识别"></a>医学糖尿病数据命名实体识别</h3><table><thead><tr><th>语言模型</th><th>语言模型需要大家熟悉下，后续词向量的基础</th></tr></thead><tbody><tr><td>使用Gemsim构建词向量dd</td><td></td></tr><tr><td>基于word2vec的分类任务ddd</td><td></td></tr><tr><td>NLP-文本特征方法对比</td><td>文本特征构造方法这么多，哪一个更好用呢？</td></tr><tr><td>LSTM情感分析</td><td>用这个项目来理解RNN模型所需的输入长什么样子</td></tr><tr><td>NLP-相似度模型</td><td></td></tr><tr><td>对话机器人</td><td>基于tensorlfow框架构建一个聊天机器人</td></tr><tr><td>动手打造自己的输入法</td><td>能不能构建一款自己的输入法呢？帮你搞定！</td></tr><tr><td>机器人写唐诗</td><td>看看模型写出的唐诗咋样！</td></tr><tr><td>NMT机器翻译框</td><td>开源项目，可以进行二次开发</td></tr><tr><td>地址邮编多序列任务</td><td>经典文本分类任务</td></tr><tr><td>自然语言处理通用框架BERT原理</td><td>这个就是上面说的BERT了，重点！重点！重点！</td></tr><tr><td>谷歌开源项目BERT源码解读</td><td>源码非常重要，每一行都需要理解</td></tr><tr><td>基于BERT的中文情感分析</td><td>基于开源项目进行模型开发</td></tr><tr><td>基于BERT的中文命名实体识别</td><td>基于开源项目进行命名实体识别</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
          <category> 自然语言处理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> BERT模型 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>1月9日</title>
      <link href="/2021/01/09/1%E6%9C%889%E6%97%A5/"/>
      <url>/2021/01/09/1%E6%9C%889%E6%97%A5/</url>
      
        <content type="html"><![CDATA[<h1 id="1月9日"><a href="#1月9日" class="headerlink" title="1月9日"></a>1月9日</h1><h2 id="笔记"><a href="#笔记" class="headerlink" title="笔记"></a>笔记</h2><h3 id="Phonto-OCR"><a href="#Phonto-OCR" class="headerlink" title="Phonto OCR"></a>Phonto OCR</h3><p>Photo Optical Character Recognition</p><h3 id="uri与url"><a href="#uri与url" class="headerlink" title="uri与url"></a>uri与url</h3><p><strong>URI包括URL和URN两个类别，URL是URI的子集，所以URL一定是URI，而URI不一定是URL</strong></p><p>URI &#x3D; Universal Resource Identifier 统一资源标志符，用来标识抽象或物理资源的一个紧凑字符串。<br>URL &#x3D; Universal Resource Locator 统一资源定位符，一种定位资源的主要访问机制的字符串，一个标准的URL必须包括：protocol、host、port、path、parameter、anchor。<br>URN &#x3D; Universal Resource Name 统一资源名称，通过特定命名空间中的唯一名称或ID来标识资源。</p><p><img src="/1%E6%9C%889%E6%97%A5/591228-20160116223301225-1866838315.png" alt="url_uri_diff"></p><p><strong>举个栗子：</strong></p><blockquote><p>个人的身份证号就是URN，个人的家庭地址就是URL，URN可以唯一标识一个人，而URL可以告诉邮递员怎么把货送到你手里。</p></blockquote><p><strong>再举个栗子：</strong></p><blockquote><p><a href="http://blog.csdn.net/">http://blog.csdn.net</a> 是个URL，通过这个网址可以告诉CDN找到我的博客所在地，并且还告诉用HTTP协议访问，而isbn:0-395-36341-1是RUN，一个国际标准书号，可以唯一确定哪本书。</p></blockquote><p>目前HTTP规范已经不使用URL，而是使用URI了，所以大家还是用URI吧，准没错！</p><blockquote><p>HTTP relies upon the Uniform Resource Identifier (URI) standard<br>[RFC3986] to indicate the target resource (Section 5.1) and<br>relationships between resources.</p></blockquote><h3 id="中间件"><a href="#中间件" class="headerlink" title="中间件"></a>中间件</h3><h3 id="协方差矩阵"><a href="#协方差矩阵" class="headerlink" title="协方差矩阵"></a>协方差矩阵</h3><h3 id="奇异值分解（SVD）"><a href="#奇异值分解（SVD）" class="headerlink" title="奇异值分解（SVD）"></a>奇异值分解（SVD）</h3><h3 id="特征值与特征向量"><a href="#特征值与特征向量" class="headerlink" title="特征值与特征向量"></a>特征值与特征向量</h3><h3 id="SMO算法"><a href="#SMO算法" class="headerlink" title="SMO算法"></a>SMO算法</h3><h3 id="标准化-x2F-归一化"><a href="#标准化-x2F-归一化" class="headerlink" title="标准化&#x2F;归一化"></a>标准化&#x2F;归一化</h3><h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><ol><li><p>提升模型精度</p><p>在机器学习算法的目标函数(例如SVM的RBF内核或线性模型的l1和l2正则化)，许多学习算法中目标函数的基础都是假设所有的特征都是零均值并且具有同一阶数上的方差。<strong>如果某个特征的方差比其他特征大几个数量级，那么它就会在学习算法中占据主导位置，导致学习器并不能像我们说期望的那样，从其他特征中学习。</strong></p></li><li><p>提升收敛速度</p><p><strong>对于线性model来说</strong>，数据归一化后，最优解的寻优过程明显会变得平缓，更容易正确的收敛到最优解。</p><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/1389398-20180501192405613-1987522197.png" alt="img"></p><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/1389398-20180501192354977-1299288822.png" alt="img"></p><p><strong>对于神经网络模型</strong>，避免饱和是一个需要考虑的因素，通常参数的选择决定于input数据的大小范围。</p></li></ol><h3 id="fflush（stdout）"><a href="#fflush（stdout）" class="headerlink" title="fflush（stdout）"></a>fflush（stdout）</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">在使用多个输出函数连续进行多次输出时，有可能发现输出错误。因为下一个数据再上一个数据还没输出完毕，还在输出缓冲区中时，下一个printf就把另一个数据加入输出缓冲区，结果冲掉了原来的数据，出现输出错误。 在 prinf（）；后加上fflush(stdout); 强制马上输出，避免错误。</span><br></pre></td></tr></table></figure><h3 id="norm函数"><a href="#norm函数" class="headerlink" title="norm函数"></a>norm函数</h3><h3 id="凸优化"><a href="#凸优化" class="headerlink" title="凸优化"></a>凸优化</h3><h3 id="ROS"><a href="#ROS" class="headerlink" title="ROS"></a>ROS</h3><p>ROS (Robot Operating System, 机器人操作系统) 提供一系列程序库和工具以帮助软件开发者创建机器人应用软件。它提供了硬件抽象、设备驱动、库函数、可视化、消息传递和软件包管理等诸多功能。ROS遵守BSD开源许可协议。</p><h3 id="下采样"><a href="#下采样" class="headerlink" title="下采样"></a>下采样</h3><p>对于一个样值序列间隔几个样值取样一次，这样得到新序列就是原序列的下采样。</p><h3 id="上采样"><a href="#上采样" class="headerlink" title="上采样"></a>上采样</h3><p>简单的理解就是把图片进行放大了。在算法中，在我们做图像识别过程中，需要对图像进行像素级别的分类，因此在卷积提取特征后需要通过上采样将feature map 还原到原图中。</p><p>在算法中常见的上采样方法有双线性插值以及转置卷积、上采样(unsampling)和上池化(unpooling).</p><p>常用的就是<code>双线性插值</code>以及<code>转置卷积</code></p><h2 id="英语"><a href="#英语" class="headerlink" title="英语"></a>英语</h2><p>special offers：特价优惠（special offer的复数）</p><p>curly brace：花括号</p><p>laid out：喝醉了的；安排；陈列；花费；责骂（lay out的过去式和过去分词形式）</p><p>CTR：click through rate</p><p>network latency：网络传输时间</p><p>more broadly：更广泛的</p><p>the aspect ratio of：长宽比</p><p>rounded number：取整（舍入，约整，圆整）数</p><p>cautionary story：警示故事</p><p>monkey around：鬼混，胡闹</p><p>sobering message：发人深省的消息</p><p>per capita &#x2F; per person：人均</p><p>For consistency：为了一致性</p><p>throughput：吞吐量</p><p>off-the-shelf：现成的</p><p>up to：忙于…，在做…；由…决定的</p>]]></content>
      
      
      <categories>
          
          <category> 随记 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>3D-Object-Detect</title>
      <link href="/2021/01/01/3D-Object-Detect/"/>
      <url>/2021/01/01/3D-Object-Detect/</url>
      
        <content type="html"><![CDATA[<h1 id="3D-Object-Detection"><a href="#3D-Object-Detection" class="headerlink" title="3D Object Detection"></a>3D Object Detection</h1><h2 id="踩坑日记"><a href="#踩坑日记" class="headerlink" title="踩坑日记"></a>踩坑日记</h2><ol><li>spconv安装时，当使用的是cuda10.1记得安装update2版本，原始版本有bug</li><li>spconv pip install 步骤，会报以下错误</li></ol><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ERROR: spconv-1.1-cp36-cp36m-linux_x86_64.whl is not a supported wheel on this platform.</span><br></pre></td></tr></table></figure><p>解决办法如下：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python -m pip install spconv-1.2.1-cp37-cp37m-linux_x86_64.whl</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
          <category> 目标检测 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>电商推荐系统</title>
      <link href="/2021/01/01/%E7%94%B5%E5%95%86%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
      <url>/2021/01/01/%E7%94%B5%E5%95%86%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/</url>
      
        <content type="html"><![CDATA[<h1 id="电商推荐系统"><a href="#电商推荐系统" class="headerlink" title="电商推荐系统"></a>电商推荐系统</h1><h2 id="笔记"><a href="#笔记" class="headerlink" title="笔记"></a>笔记</h2><h3 id="MongoDB"><a href="#MongoDB" class="headerlink" title="MongoDB"></a>MongoDB</h3><p>文档数据库</p><h3 id="Scala"><a href="#Scala" class="headerlink" title="Scala"></a>Scala</h3><p>Scala是一门多范式的编程语言，一种类似<a href="https://baike.baidu.com/item/java/85979">java</a>的编程语言，设计初衷是实现可伸缩的语言、并集成<a href="https://baike.baidu.com/item/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%BC%96%E7%A8%8B">面向对象编程</a>和<a href="https://baike.baidu.com/item/%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B">函数式编程</a>的各种特性。</p><h3 id="UGC"><a href="#UGC" class="headerlink" title="UGC"></a>UGC</h3><p>UGC 互联网术语，全称为User Generated Content，也就是<strong>用户生成内容，即用户原创内容</strong>。UGC的概念最早起源于互联网领域，即用户将自己原创的内容通过互联网平台进行展示或者提供给其他用户。UGC是伴随着以提倡个性化为主要特点的Web2.0<a href="https://baike.baidu.com/item/%E6%A6%82%E5%BF%B5">概念</a>而兴起的，也可叫做<a href="https://baike.baidu.com/item/UCC/6493785">UCC</a>（User-created Content）。它并不是某一种具体的业务，而是一种用户使用<a href="https://baike.baidu.com/item/%E4%BA%92%E8%81%94%E7%BD%91/199186">互联网</a>的新方式，即由原来的以下载为主变成下载和上传并重。</p><p>随着互联网运用的发展，<a href="https://baike.baidu.com/item/%E7%BD%91%E7%BB%9C/143243">网络</a>用户的交互作用得以体现，用户既是网络内容的浏览者，也是网络内容的创造者。</p><h3 id="UDF"><a href="#UDF" class="headerlink" title="UDF"></a>UDF</h3><p>UDF（User-Defined Functions）即是用户定义的hive函数。hive自带的函数并不能完全满足业务需求，这时就需要我们自定义函数了</p><h3 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h3><p>Spark是一种快速、通用、可扩展的大数据分析引擎，2009年诞生于加州大学伯克利分校AMPLab，2010年开源，2013年6月成为Apache孵化项目，2014年2月成为Apache顶级项目。目前，Spark生态系统已经发展成为一个包含多个子项目的集合，其中包含<strong>SparkSQL、Spark Streaming、GraphX、MLlib</strong>等子项目，Spark是基于内存计算的大数据并行计算框架。<strong>Spark基于内存计算</strong>，提高了在大数据环境下数据处理的实时性，同时保证了高容错性和高可伸缩性，允许用户将Spark部署在大量廉价硬件之上，形成集群。Spark得到了众多大数据公司的支持，这些公司包括Hortonworks、IBM、Intel、Cloudera、MapR、Pivotal、百度、阿里、腾讯、京东、携程、优酷土豆。当前百度的Spark已应用于凤巢、大搜索、直达号、百度大数据等业务；阿里利用GraphX构建了大规模的图计算和图挖掘系统，实现了很多生产系统的推荐算法；腾讯Spark集群达到8000台的规模，是当前已知的世界上最大的Spark集群。</p><h4 id="为什么要学习Spark？"><a href="#为什么要学习Spark？" class="headerlink" title="为什么要学习Spark？"></a>为什么要学习Spark？</h4><h5 id="Hadoop的MapReduce计算模型存在的问题："><a href="#Hadoop的MapReduce计算模型存在的问题：" class="headerlink" title="Hadoop的MapReduce计算模型存在的问题："></a>Hadoop的MapReduce计算模型存在的问题：</h5><p>学习过Hadoop的MapReduce的学员都知道，MapReduce的核心是Shuffle（洗牌）。在整个Shuffle的过程中，至少会产生6次的I&#x2F;O。下图是我们在讲MapReduce的时候，画的Shuffle的过程。</p><p>中间结果输出：基于MapReduce的计算引擎通常会将中间结果输出到磁盘上，进行存储和容错。另外，当一些查询（如：Hive）翻译到MapReduce任务时，往往会产生多个Stage（阶段），而这些串联的Stage又依赖于底层文件系统（如HDFS）来存储每一个Stage的输出结果，而I&#x2F;O的效率往往较低，从而影响了MapReduce的运行速度。<img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/1367933-20181024083658261-227282946.png" alt="img"></p><h5 id="Spark的最大特点：基于内存"><a href="#Spark的最大特点：基于内存" class="headerlink" title="Spark的最大特点：基于内存"></a>Spark的最大特点：基于内存</h5><p>Spark是MapReduce的替代方案，而且兼容HDFS、Hive，可融入Hadoop的生态系统，以弥补MapReduce的不足。</p><h4 id="Spark的特点：快、易用、通用、兼容性"><a href="#Spark的特点：快、易用、通用、兼容性" class="headerlink" title="Spark的特点：快、易用、通用、兼容性"></a>Spark的特点：快、易用、通用、兼容性</h4><h5 id="快"><a href="#快" class="headerlink" title="快"></a>快</h5><p>与Hadoop的MapReduce相比，Spark基于内存的运算速度要快100倍以上，即使，Spark基于硬盘的运算也要快10倍。Spark实现了高效的DAG执行引擎，从而可以通过内存来高效处理数据流。<br><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/1367933-20181024083458424-1114607121.png" alt="img"> </p><h5 id="易用"><a href="#易用" class="headerlink" title="易用"></a>易用</h5><p>Spark支持Java、Python和Scala的API，还支持超过80种高级算法，使用户可以快速构建不同的应用。而且Spark支持交互式的Python和Scala的shell，可以非常方便地在这些shell中使用Spark集群来验证解决问题的方法。<br><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/1367933-20181024083543529-1547062484.png" alt="img"><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/1367933-20181024083554814-248989191.png" alt="img"></p><h5 id="通用"><a href="#通用" class="headerlink" title="通用"></a>通用</h5><p>Spark提供了统一的解决方案。Spark可以用于<strong>批处理</strong>、交互式查询（<strong>Spark SQL</strong>）、实时流处理（<strong>Spark Streaming</strong>）、机器学习（<strong>Spark MLlib</strong>）和图计算（<strong>GraphX</strong>）。这些不同类型的处理都可以在同一个应用中无缝使用。Spark统一的解决方案非常具有吸引力，毕竟任何公司都想用统一的平台去处理遇到的问题，减少开发和维护的人力成本和部署平台的物力成本。</p><p>另外Spark还可以很好的融入Hadoop的体系结构中可以直接操作HDFS，并提供Hive on Spark、Pig on Spark的框架集成Hadoop。<br><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/1367933-20181024083800247-1305213116.png" alt="img"></p><h5 id="兼容性"><a href="#兼容性" class="headerlink" title="兼容性"></a>兼容性</h5><p>Spark可以非常方便地与其他的开源产品进行融合。比如，Spark可以使用Hadoop的YARN和Apache Mesos作为它的资源管理和调度器，器，并且可以处理所有Hadoop支持的数据，包括HDFS、HBase和Cassandra等。这对于已经部署Hadoop集群的用户特别重要，因为不需要做任何数据迁移就可以使用Spark的强大处理能力。Spark也可以不依赖于第三方的资源管理和调度器，它实现了Standalone作为其内置的资源管理和调度框架，这样进一步降低了Spark的使用门槛，使得所有人都可以非常容易地部署和使用Spark。此外，Spark还提供了在EC2上部署Standalone的Spark集群的工具。<br><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/1367933-20181024083830119-1645632631.png" alt="img"></p><h3 id="Spark-Core"><a href="#Spark-Core" class="headerlink" title="Spark Core"></a>Spark Core</h3><h4 id="主要功能"><a href="#主要功能" class="headerlink" title="主要功能"></a>主要功能</h4><p>Spark Core提供Spark最基础与最核心的功能，主要包括以下功能：</p><p>(1)  SparkContext：通常而言，Driver Application的执行与输出都是通过SparkContext来完成的。在正式提交Application之前，首先需要初始化SparkContext。SparkContext隐藏了网络通信、分布式部署、消息通信、存储能力、计算能力、缓存、测量系统、文件服务、Web服务等内容，应用程序开发者只需要使用SparkContext提供的API完成功能开发。SparkContext内置的DAGScheduler负责创建Job，将DAG中的RDD划分到不同的Stage，提交Stage等功能。内置的TaskScheduler负责资源的申请，任务的提交及请求集群对任务的调度等工作。<br>(2)  存储体系：<strong>Spark优先考虑使用各节点的内存作为存储，当内存不足时才会考虑使用磁盘</strong>，这极大地减少了磁盘IO，提升了任务执行的效率，使得Spark适用于实时计算、流式计算等场景。此外，Spark还提供了以内存为中心的高容错的分布式文件系统Tachyon供用户进行选择。Tachyon能够为Spark提供可靠的内存级的文件共享服务。<br>(3)  计算引擎：计算引擎由SparkContext中的DAGScheduler、RDD以及具体节点上的Executor负责执行的Map和Reduce任务组成。DAGScheduler和RDD虽然位于SparkContext内部，但是在任务正式提交与执行之前会将Job中的RDD组织成有向无环图（DAG），并对Stage进行划分，决定了任务执行阶段任务的数量、迭代计算、shuffle等过程。<br>(4)  部署模式：由于单节点不足以提供足够的存储和计算能力，所以作为大数据处理的Spark在SparkContext的TaskScheduler组件中提供了对Standalone部署模式的实现和Yarn、Mesos等分布式资源管理系统的支持。通过使用Standalone、Yarn、Mesos等部署模式为Task分配计算资源，提高任务的并发执行效率。</p><h4 id="Spark-Core子框架"><a href="#Spark-Core子框架" class="headerlink" title="Spark Core子框架"></a>Spark Core子框架</h4><p>Spark的几大子框架包括：</p><p>(1)、Spark SQL：首先使用SQL语句解析器（SqlParser）将SQL转换为语法树（Tree），并且使用规则执行器（RuleExecutor）将一系列规则（Rule）应用到语法树，最终生成物理执行计划并执行。其中，规则执行器包括语法分析器（Analyzer）和优化器（Optimizer）。<br>(2)、Spark Streaming：用于流式计算。Spark Streaming支持Kafka、Flume、Twitter、MQTT、ZeroMQ、Kinesis和简单的TCP套接字等多种数据输入源。输入流接收器（Receiver）负责接入数据，是接入数据流的接口规范。Dstream是Spark Streaming中所有数据流的抽象，Dstream可以被组织为Dstream Graph。Dstream本质上由一系列连续的RDD组成。<br>(3)、GraphX：Spark提供的分布式图计算框架。GraphX主要遵循整体同步并行（bulk Synchronous parallel，BSP）计算模式下的Pregel模型实现。GraphX提供了对图的抽象Graph，Graph由顶点（Vertex），边（Edge）及继承了Edge的EdgeTriplet三种结构组成。GraphX目前已经封装了最短路径，网页排名，连接组件，三角关系统计等算法的实现，用户可以选择使用。<br>(4)、MLlib：Spark提供的机器学习框架。机器学习是一门设计概率论、统计学、逼近论、凸分析、算法复杂度理论等多领域的交叉学科。MLlib目前已经提供了基础统计、分析、回归、决策树、随机森林、朴素贝叶斯、保序回归、协同过滤、聚类、维数缩减、特征提取与转型、频繁模式挖掘、预言模型标记语言、管道等多种数理统计、概率论、数据挖掘方面的数学算法。</p><h4 id="Spark架构"><a href="#Spark架构" class="headerlink" title="Spark架构"></a>Spark架构</h4><blockquote><p>Spark采用了分布式计算中的Master-Slave模型。Master作为整个集群的控制器，负责整个集群的正常运行；Worker是计算节点，接受主节点命令以及进行状态汇报；Executor负责任务（Tast）的调度和执行；Client作为用户的客户端负责提交应用；Driver负责控制一个应用的执行。</p></blockquote><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/20180116172542912" alt="这里写图片描述"></p><blockquote><p>Spark集群启动时，需要从主节点和从节点分别启动Master进程和Worker进程，对整个集群进行控制。在一个Spark应用的执行过程中，Driver是应用的逻辑执行起点，运行Application的main函数并创建SparkContext，DAGScheduler把对Job中的RDD有向无环图根据依赖关系划分为多个Stage，每一个Stage是一个TaskSet， TaskScheduler把Task分发给Worker中的Executor；Worker启动Executor，Executor启动线程池用于执行Task。</p></blockquote><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/20180116172611353" alt="这里写图片描述"></p><h4 id="Spark计算模型"><a href="#Spark计算模型" class="headerlink" title="Spark计算模型"></a>Spark计算模型</h4><blockquote><p>RDD：弹性分布式数据集，是一种<strong>内存抽象</strong>，可以理解为一个大数组，数组的元素是RDD的分区Partition，分布在集群上；在物理数据存储上，RDD的每一个Partition对应的就是一个数据块Block，<strong>Block可以存储在内存中，当内存不够时可以存储在磁盘上。</strong></p></blockquote><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/20180116172839701" alt="这里写图片描述"><br><strong>RDD逻辑物理结构</strong></p><p>Hadoop将Mapreduce计算的结果写入磁盘，在机器学习、图计算、PageRank等迭代计算下，重用中间结果导致的反复I&#x2F;O耗时过长，成为了计算性能的瓶颈。为了提高迭代计算的性能和分布式并行计算下共享数据的容错性，伯克利的设计者依据两个特性而设计了RDD:</p><p>1、数据集分区存储在节点的内存中，减少迭代过程（如机器学习算法）反复的I&#x2F;O操作从而提高性能。<br>2、数据集不可变，并记录其转换过程，从而实现无共享数据读写同步问题、以及出错的可重算性。</p><p><strong>Operations：算子</strong></p><blockquote><p>算子是RDD中定义的函数，可以对RDD中的数据进行转换和操作。如下图，Spark从外部空间（HDFS）读取数据形成RDD_0，Tranformation算子对数据进行操作（如fliter）并转化为新的RDD_1、RDD_2，通过Action算子（如collect&#x2F;count）触发Spark提交作业。</p><p>如上的分析过程可以看出，Tranformation算子并不会触发Spark提交作业，直至Action算子才提交作业，这是一个延迟计算的设计技巧，可以避免内存过快被中间计算占满，从而提高内存的利用率。</p></blockquote><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/20180116173006041" alt="这里写图片描述"></p><blockquote><p>下图是算子的列表，分三大类：Value数据类型的Tranformation算子；Key-Value数据类型的Tranformation算子；Action算子。</p></blockquote><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/20180116173059020" alt="这里写图片描述"></p><p><strong>Lineage Graph：血统关系图</strong></p><blockquote><p>下图的第一阶段生成RDD的有向无环图，即是血统关系图，记录了RDD的更新过程，当这个RDD的部分分区数据丢失时，它可以通过Lineage获取足够的信息来重新运算和恢复丢失的数据分区。DAGScheduler依据RDD的依赖关系将有向无环图划分为多个Stage，一个Stage对应着一系列的Task，由TashScheduler分发给Worker计算。</p></blockquote><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/20180116173117901" alt="这里写图片描述"></p><h4 id="组件"><a href="#组件" class="headerlink" title="组件"></a>组件</h4><h5 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h5><blockquote><p>spark生态系统中，Spark Core，包括各种Spark的各种核心组件，它们能够对内存和硬盘进行操作，或者调用CPU进行计算。<br>spark core定义了RDD、DataFrame和DataSet</p></blockquote><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/20180117085511437" alt="这里写图片描述"></p><blockquote><p>spark最初只有RDD，DataFrame在Spark 1.3中被首次发布，DataSet在Spark1.6版本中被加入。</p></blockquote><h5 id="RDD"><a href="#RDD" class="headerlink" title="RDD"></a>RDD</h5><blockquote><p>RDD：Spark的核心概念是RDD (resilient distributed dataset)，指的是一个只读的，可分区的分布式数据集，这个数据集的全部或部分可以缓存在内存中，在多次计算间重用。</p></blockquote><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import org.apache.spark.sql.SQLContext</span><br><span class="line">import org.apache.spark.&#123;SparkConf, SparkContext&#125;</span><br><span class="line"> </span><br><span class="line">object Run &#123;</span><br><span class="line">  def main(args: Array[String]) &#123;</span><br><span class="line">    val conf = new SparkConf().setAppName(&quot;test&quot;).setMaster(&quot;local&quot;)</span><br><span class="line">    val sc = new SparkContext(conf)</span><br><span class="line">    sc.setLogLevel(&quot;WARN&quot;)</span><br><span class="line">    val sqlContext = new SQLContext(sc)</span><br><span class="line"> </span><br><span class="line">    /**</span><br><span class="line">      * id      age</span><br><span class="line">      * 1       30</span><br><span class="line">      * 2       29</span><br><span class="line">      * 3       21</span><br><span class="line">      */</span><br><span class="line">    case class Person(id: Int, age: Int)</span><br><span class="line">    val idAgeRDDPerson = sc.parallelize(Array(Person(1, 30), Person(2, 29), Person(3, 21)))</span><br><span class="line"> </span><br><span class="line">    // 优点1</span><br><span class="line">    // idAge.filter(_.age &gt; &quot;&quot;) // 编译时报错, int不能跟String比</span><br><span class="line"> </span><br><span class="line">    // 优点2</span><br><span class="line">    idAgeRDDPerson.filter(_.age &gt; 25) // 直接操作一个个的person对象</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">1234567891011121314151617181920212223242526</span><br></pre></td></tr></table></figure><h5 id="DataFrame"><a href="#DataFrame" class="headerlink" title="DataFrame"></a>DataFrame</h5><blockquote><p>在Spark中，DataFrame是一种以RDD为基础的分布式数据集，类似于传统数据库中的二维表格。DataFrame与RDD的主要区别在于，前者带有schema元信息，即DataFrame所表示的二维表数据集的每一列都带有名称和类型。这使得Spark SQL得以洞察更多的结构信息，从而对藏于DataFrame背后的数据源以及作用于DataFrame之上的变换进行了针对性的优化，最终达到大幅提升运行时效率的目标。反观RDD，由于无从得知所存数据元素的具体内部结构，Spark Core只能在stage层面进行简单、通用的流水线优化。</p></blockquote><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/20180117085747723" alt="这里写图片描述"></p><blockquote><p>DataFrame引入了schema和off-heap</p><p>schema : RDD每一行的数据, 结构都是一样的.<br>这个结构就存储在schema中。 Spark通过schame就能够读懂数据， 因此在通信和IO时就只需要序列化和反序列化数据，而结构的部分就可以省略了。 off-heap : 意味着JVM堆以外的内存，这些内存直接受操作系统管理（而不是JVM）。Spark能够以二进制的形式序列化数据(不包括结构)到off-heap中，当要操作数据时，就直接操作off-heap内存。由于Spark理解schema，所以知道该如何操作。</p><p>off-heap就像地盘，schema就像地图， Spark有地图又有自己地盘了， 就可以自己说了算了， 不再受JVM的限制，也就不再收GC的困扰了。通过schema和off-heap，DataFrame解决了RDD的缺点，但是却丢了RDD的优点。 DataFrame不是类型安全的， API也不是面向对象风格的。</p></blockquote><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import org.apache.spark.sql.types.&#123;DataTypes, StructField, StructType&#125;</span><br><span class="line">import org.apache.spark.sql.&#123;Row, SQLContext&#125;</span><br><span class="line">import org.apache.spark.&#123;SparkConf, SparkContext&#125;</span><br><span class="line"> </span><br><span class="line">object Run &#123;</span><br><span class="line">  def main(args: Array[String]) &#123;</span><br><span class="line">    val conf = new SparkConf().setAppName(&quot;test&quot;).setMaster(&quot;local&quot;)</span><br><span class="line">    val sc = new SparkContext(conf)</span><br><span class="line">    sc.setLogLevel(&quot;WARN&quot;)</span><br><span class="line">    val sqlContext = new SQLContext(sc)</span><br><span class="line">    /**</span><br><span class="line">      * id      age</span><br><span class="line">      * 1       30</span><br><span class="line">      * 2       29</span><br><span class="line">      * 3       21</span><br><span class="line">      */</span><br><span class="line">    val idAgeRDDRow = sc.parallelize(Array(Row(1, 30), Row(2, 29), Row(4, 21)))</span><br><span class="line"> </span><br><span class="line">    val schema = StructType(Array(StructField(&quot;id&quot;, DataTypes.IntegerType), StructField(&quot;age&quot;, DataTypes.IntegerType)))</span><br><span class="line"> </span><br><span class="line">    val idAgeDF = sqlContext.createDataFrame(idAgeRDDRow, schema)</span><br><span class="line">    // API不是面向对象的</span><br><span class="line">    idAgeDF.filter(idAgeDF.col(&quot;age&quot;) &gt; 25) </span><br><span class="line">    // 不会报错, DataFrame不是编译时类型安全的</span><br><span class="line">    idAgeDF.filter(idAgeDF.col(&quot;age&quot;) &gt; &quot;&quot;) </span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">123456789101112131415161718192021222324252627</span><br></pre></td></tr></table></figure><h5 id="DataSet"><a href="#DataSet" class="headerlink" title="DataSet"></a>DataSet</h5><blockquote><p>Dataset是一个强类型的特定领域的对象，这种对象可以函数式或者关系操作并行地转换。每个Dataset也有一个被称为一个DataFrame的类型化视图，这种DataFrame是Row类型的Dataset，即Dataset[Row]</p><p>Dataset是“懒惰”的，只在执行行动操作时触发计算。本质上，数据集表示一个逻辑计划，该计划描述了产生数据所需的计算。当执行行动操作时，Spark的查询优化程序优化逻辑计划，并生成一个高效的并行和分布式物理计划。</p><p>DataSet结合了RDD和DataFrame的优点,，并带来的一个新的概念Encoder 当序列化数据时，Encoder产生字节码与off-heap进行交互，能够达到按需访问数据的效果， 而不用反序列化整个对象。 Spark还没有提供自定义Encoder的API，但是未来会加入。</p></blockquote><p>下面看DataFrame和DataSet在2.0.0-preview中的实现</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">下面这段代码, 在1.6.x中创建的是DataFrame</span><br><span class="line">// 上文DataFrame示例中提取出来的</span><br><span class="line">val idAgeRDDRow = sc.parallelize(Array(Row(1, 30), Row(2, 29), Row(4, 21)))</span><br><span class="line"> </span><br><span class="line">val schema = StructType(Array(StructField(&quot;id&quot;, DataTypes.IntegerType), StructField(&quot;age&quot;, DataTypes.IntegerType)))</span><br><span class="line"> </span><br><span class="line">val idAgeDF = sqlContext.createDataFrame(idAgeRDDRow, schema)</span><br><span class="line">1234567</span><br><span class="line">但是同样的代码在2.0.0-preview中, 创建的虽然还叫DataFrame</span><br><span class="line"></span><br><span class="line">// sqlContext.createDataFrame(idAgeRDDRow, schema) 方法的实现, 返回值依然是DataFrame</span><br><span class="line">def createDataFrame(rowRDD: RDD[Row], schema: StructType): DataFrame = &#123;</span><br><span class="line">sparkSession.createDataFrame(rowRDD, schema)</span><br><span class="line">&#125;</span><br><span class="line">123456</span><br><span class="line">但是其实却是DataSet, 因为DataFrame被声明为Dataset[Row]</span><br><span class="line"></span><br><span class="line">package object sql &#123;</span><br><span class="line">  // ...省略了不相关的代码</span><br><span class="line"> </span><br><span class="line">  type DataFrame = Dataset[Row]</span><br><span class="line">&#125;</span><br><span class="line">1234567</span><br><span class="line">因此当我们从1.6.x迁移到2.0.0的时候, 无需任何修改就直接用上了DataSet.</span><br><span class="line"></span><br><span class="line">下面是一段DataSet的示例代码</span><br><span class="line"></span><br><span class="line">import org.apache.spark.sql.types.&#123;DataTypes, StructField, StructType&#125;</span><br><span class="line">import org.apache.spark.sql.&#123;Row, SQLContext&#125;</span><br><span class="line">import org.apache.spark.&#123;SparkConf, SparkContext&#125;</span><br><span class="line"> </span><br><span class="line">object Test &#123;</span><br><span class="line">  def main(args: Array[String]) &#123;</span><br><span class="line">    val conf = new SparkConf().setAppName(&quot;test&quot;).setMaster(&quot;local&quot;) // 调试的时候一定不要用local[*]</span><br><span class="line">    val sc = new SparkContext(conf)</span><br><span class="line">    val sqlContext = new SQLContext(sc)</span><br><span class="line">    import sqlContext.implicits._</span><br><span class="line"> </span><br><span class="line">    val idAgeRDDRow = sc.parallelize(Array(Row(1, 30), Row(2, 29), Row(4, 21)))</span><br><span class="line"> </span><br><span class="line">    val schema = StructType(Array(StructField(&quot;id&quot;, DataTypes.IntegerType), StructField(&quot;age&quot;, DataTypes.IntegerType)))</span><br><span class="line"> </span><br><span class="line">    // 在2.0.0-preview中这行代码创建出的DataFrame, 其实是DataSet[Row]</span><br><span class="line">    val idAgeDS = sqlContext.createDataFrame(idAgeRDDRow, schema)</span><br><span class="line"> </span><br><span class="line">    // 在2.0.0-preview中, 还不支持自定的Encoder, Row类型不行, 自定义的bean也不行</span><br><span class="line">    // 官方文档也有写通过bean创建Dataset的例子，但是我运行时并不能成功</span><br><span class="line">    // 所以目前需要用创建DataFrame的方法, 来创建DataSet[Row]</span><br><span class="line">    // sqlContext.createDataset(idAgeRDDRow)</span><br><span class="line"> </span><br><span class="line">    // 目前支持String, Integer, Long等类型直接创建Dataset</span><br><span class="line">    Seq(1, 2, 3).toDS().show()</span><br><span class="line">    sqlContext.createDataset(sc.parallelize(Array(1, 2, 3))).show()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">1234567891011121314151617181920212223242526272829303132</span><br></pre></td></tr></table></figure><h5 id="RDD和DataFrame比较"><a href="#RDD和DataFrame比较" class="headerlink" title="RDD和DataFrame比较"></a>RDD和DataFrame比较</h5><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/20180117090559218" alt="这里写图片描述"></p><blockquote><p>DataFrame与RDD相同之处，都是不可变分布式弹性数据集。不同之处在于，DataFrame的数据集都是按指定列存储，即结构化数据。类似于传统数据库中的表。<br>DataFrame的设计是为了让大数据处理起来更容易。DataFrame允许开发者把结构化数据集导入DataFrame，并做了higher-level的抽象; DataFrame提供特定领域的语言（DSL）API来操作你的数据集。</p><p>上图直观地体现了DataFrame和RDD的区别。左侧的RDD[Person]虽然以Person为类型参数，但Spark框架本身不了解Person类的内部结构。而右侧的DataFrame却提供了详细的结构信息，使得Spark SQL可以清楚地知道该数据集中包含哪些列，每列的名称和类型各是什么。DataFrame多了数据的结构信息，即schema。RDD是分布式的Java对象的集合。DataFrame是分布式的Row对象的集合。DataFrame除了提供了比RDD更丰富的算子以外，更重要的特点是提升执行效率、减少数据读取以及执行计划的优化，比如filter下推、裁剪等。</p></blockquote><h5 id="RDD和DataSet比较"><a href="#RDD和DataSet比较" class="headerlink" title="RDD和DataSet比较"></a>RDD和DataSet比较</h5><blockquote><p>DataSet以Catalyst逻辑执行计划表示，并且数据以编码的二进制形式被存储，不需要反序列化就可以执行sorting、shuffle等操作。</p><p>DataSet创立需要一个显式的Encoder，把对象序列化为二进制，可以把对象的scheme映射为Spark SQl类型，然而RDD依赖于运行时反射机制。</p><p>通过上面两点，DataSet的性能比RDD的要好很多</p></blockquote><h5 id="DataFrame和DataSet比较"><a href="#DataFrame和DataSet比较" class="headerlink" title="DataFrame和DataSet比较"></a>DataFrame和DataSet比较</h5><p>Dataset可以认为是DataFrame的一个特例，主要区别是Dataset每一个record存储的是一个强类型值而不是一个Row。因此具有如下三个特点：</p><p>1.DataSet可以在编译时检查类型<br>2.是面向对象的编程接口。用wordcount举例：<br>3.后面版本DataFrame会继承DataSet，DataFrame是面向Spark SQL的接口。<br>DataFrame和DataSet可以相互转化， <a href="http://df.as/">df.as</a>[ElementType]这样可以把DataFrame转化为DataSet，ds.toDF()这样可以把DataSet转化为DataFrame。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">//DataFrame</span><br><span class="line"> </span><br><span class="line">// Load a text file and interpret each line as a java.lang.String</span><br><span class="line">val ds = sqlContext.read.text(&quot;/home/spark/1.6/lines&quot;).as[String]</span><br><span class="line">val result = ds</span><br><span class="line">  .flatMap(_.split(&quot; &quot;))               // Split on whitespace</span><br><span class="line">  .filter(_ != &quot;&quot;)                     // Filter empty words</span><br><span class="line">  .toDF()                              // Convert to DataFrame to perform aggregation / sorting</span><br><span class="line">  .groupBy($&quot;value&quot;)                   // Count number of occurences of each word</span><br><span class="line">  .agg(count(&quot;*&quot;) as &quot;numOccurances&quot;)</span><br><span class="line">  .orderBy($&quot;numOccurances&quot; desc)      // Show most common words first</span><br><span class="line"></span><br><span class="line">//DataSet,完全使用scala编程，不要切换到DataFrame</span><br><span class="line"> </span><br><span class="line">val wordCount =</span><br><span class="line">  ds.flatMap(_.split(&quot; &quot;))</span><br><span class="line">    .filter(_ != &quot;&quot;)</span><br><span class="line">    .groupBy(_.toLowerCase()) // Instead of grouping on a column expression (i.e. $&quot;value&quot;) we pass a lambda function</span><br><span class="line">    .count()</span><br><span class="line"></span><br><span class="line">1234567891011121314151617181920</span><br></pre></td></tr></table></figure><h5 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h5><p><strong>什么时候用RDD？使用RDD的一般场景:</strong></p><p>你需要使用low-level的transformation和action来控制你的数据集；<br>你得数据集非结构化，比如，流媒体或者文本流；<br>你想使用函数式编程来操作你得数据，而不是用特定领域语言（DSL）表达；<br>你不在乎schema，比如，当通过名字或者列处理（或访问）数据属性不在意列式存储格式；<br>你放弃使用DataFrame和Dataset来优化结构化和半结构化数据集<br>RDD在Apache Spark 2.0中惨遭抛弃？<br>答案当然是 NO !<br>通过后面的描述你会得知：Spark用户可以在RDD，DataFrame和Dataset三种数据集之间无缝转换，而是只需使用超级简单的API方法。</p><p><strong>什么时候使用DataFrame或者Dataset？</strong></p><p>你想使用丰富的语义，high-level抽象，和特定领域语言API，那你可DataFrame或者Dataset；<br>你处理的半结构化数据集需要high-level表达， filter，map，aggregation，average，sum ，SQL 查询，列式访问和使用lambda函数，那你可DataFrame或者Dataset；<br>你想利用编译时高度的type-safety，Catalyst优化和Tungsten的code生成，那你可DataFrame或者Dataset；<br>你想统一和简化API使用跨Spark的Library，那你可DataFrame或者Dataset；<br>如果你是一个R使用者，那你可DataFrame或者Dataset；<br>如果你是一个Python使用者，那你可DataFrame或者Dataset；</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">你可以无缝的把DataFrame或者Dataset转化成一个RDD，只需简单的调用 .rdd：</span><br><span class="line"></span><br><span class="line">// select specific fields from the Dataset, apply a predicate</span><br><span class="line">// using the where() method, convert to an RDD, and show first 10</span><br><span class="line">// RDD rows</span><br><span class="line"> </span><br><span class="line">val deviceEventsDS = ds.select($&quot;device_name&quot;, $&quot;cca3&quot;, $&quot;c02_level&quot;).where($&quot;c02_level&quot; &gt; 1300)</span><br><span class="line">// convert to RDDs and take the first 10 rows</span><br><span class="line"> </span><br><span class="line">val eventsRDD = deviceEventsDS.rdd.take(10)</span><br></pre></td></tr></table></figure><h4 id="Spark-SQL"><a href="#Spark-SQL" class="headerlink" title="Spark SQL"></a>Spark SQL</h4><p>​spark SQL是spark的一个模块，主要用于进行结构化数据的处理。它提供的最核心的编程抽象就是DataFrame。</p><h4 id="Spark-Streaming"><a href="#Spark-Streaming" class="headerlink" title="Spark Streaming"></a>Spark Streaming</h4><p>Spark Streaming是核心Spark API的扩展，可实现可扩展、高吞吐量、可容错的实时数据流处理。数据可以从诸如Kafka，Flume，Kinesis或TCP套接字等众多来源获取，并且可以使用由高级函数（如map，reduce，join和window）开发的复杂算法进行流数据处理。最后，处理后的数据可以被推送到文件系统，数据库和实时仪表板。而且，您还可以在数据流上应用Spark提供的机器学习和图处理算法。</p><h3 id="Flume-ng"><a href="#Flume-ng" class="headerlink" title="Flume-ng"></a>Flume-ng</h3><p>Flume是一个分布式、可靠、高可用的海量日志聚合系统，支持在系统中定制各类数据发送方，用于收集数据；同时，Flume提供对数据的简单处理，并写到各种数据接收方的能力。</p><p>Flume在0.9.x和1.x之间有较大的架构调整，1.x版本之后的改称为Flume NG。0.9.x的称为Flume OG。</p><p><strong>Flume OG体系架构如下，</strong>Flume OG已经不再进行版本更新：</p><h3 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h3><h4 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h4><p>Kafka是最初由Linkedin公司开发，是一个分布式、分区的、多副本的、多订阅者，基于zookeeper协调的分布式日志系统（也可以当做<strong>MQ系统</strong>），常见可以用于web&#x2F;nginx日志、访问日志，消息服务等等，Linkedin于2010年贡献给了Apache基金会并成为顶级开源项目。</p><p>主要应用场景是：日志收集系统和消息系统。</p><p>Kafka主要设计目标如下：</p><ul><li>以时间复杂度为O(1)的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间的访问性能。</li><li>高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒100K条消息的传输。</li><li>支持Kafka Server间的消息分区，及分布式消费，同时保证每个partition内的消息顺序传输。</li><li>同时支持离线数据处理和实时数据处理。</li><li>Scale out:支持在线水平扩展</li></ul><h4 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h4><table><thead><tr><th><strong>名词</strong></th><th align="center"><strong>解释</strong></th></tr></thead><tbody><tr><td>Producer</td><td align="center">消息的生成者</td></tr><tr><td>Consumer</td><td align="center">消息的消费者</td></tr><tr><td>ConsumerGroup</td><td align="center">消费者组，可以并行消费Topic中的partition的消息</td></tr><tr><td>Broker</td><td align="center">缓存代理，Kafka集群中的一台或多台服务器统称broker.</td></tr><tr><td>Topic</td><td align="center">Kafka处理资源的消息源(feeds of messages)的不同分类</td></tr><tr><td>Partition</td><td align="center">Topic物理上的分组，一个topic可以分为多个partion,每个partion是一个有序的队列。partion中每条消息都会被分配一个 有序的Id(offset)</td></tr><tr><td>Message</td><td align="center">消息，是通信的基本单位，每个producer可以向一个topic（主题）发布一些消息</td></tr><tr><td>Producers</td><td align="center">消息和数据生成者，向Kafka的一个topic发布消息的 过程叫做producers</td></tr><tr><td>Consumers</td><td align="center">消息和数据的消费者，订阅topic并处理其发布的消费过程叫做consumers</td></tr></tbody></table><ul><li><h3 id="3-1-Producers的概念"><a href="#3-1-Producers的概念" class="headerlink" title="3.1 Producers的概念"></a>3.1 Producers的概念</h3></li></ul><ol><li>消息和数据生成者，向Kafka的一个topic发布消息的过程叫做producers  </li><li>Producer将消息发布到指定的Topic中，同时Producer也能决定将此消息归属于哪个partition；比如基于round-robin方式     或者通过其他的一些算法等；</li><li>异步发送批量发送可以很有效的提高发送效率。kafka producer的异步发送模式允许进行批量发送，先将消息缓存到内存中，然后一次请求批量发送出去。</li></ol><ul><li><h3 id="3-2-broker的概念"><a href="#3-2-broker的概念" class="headerlink" title="3.2 broker的概念:"></a>3.2 broker的概念:</h3></li></ul><ol><li>Broker没有副本机制，一旦broker宕机，该broker的消息将都不可用。</li><li>Broker不保存订阅者的状态，由订阅者自己保存。</li><li>无状态导致消息的删除成为难题（可能删除的消息正在被订阅），Kafka采用基于时间的SLA（服务保证），消息保存一定时间（通常7天）后会删除。</li><li>消费订阅者可以rewind back到任意位置重新进行消费，当订阅者故障时，可以选择最小的offset(id)进行重新读取消费消息</li></ol><ul><li><h3 id="3-3-Message组成"><a href="#3-3-Message组成" class="headerlink" title="3.3 Message组成"></a>3.3 Message组成</h3></li></ul><ol><li>Message消息：是通信的基本单位，每个producer可以向一个topic发布消息。</li><li>Kafka中的Message是以topic为基本单位组织的，不同的topic之间是相互独立的，每个topic又可以分成不同的partition每个partition储存一部分</li><li>partion中的每条Message包含以下三个属性：</li></ol><table><thead><tr><th>offset</th><th>long</th></tr></thead><tbody><tr><td>MessageSize</td><td>int32</td></tr><tr><td>data</td><td>messages的具体内容</td></tr></tbody></table><ul><li><h3 id="3-4-Consumers的概念"><a href="#3-4-Consumers的概念" class="headerlink" title="3.4 Consumers的概念"></a>3.4 Consumers的概念</h3><p> 消息和数据消费者，订阅topic并处理其发布的消息的过程叫做consumers.<br> 在kafka中，我们可以认为一个group是一个“订阅者”，一个topic中的每个partions只会被一个“订阅者”中的一个consumer<br> 消费，不过一个consumer可以消费多个partitions中的消息<br> 注:<br>  Kafka的设计原理决定，对于一个topic，同一个group不能多于partition个数的consumer同时消费，否则将意味着某些           consumer无法得到消息</p></li><li><h3 id="3-5-关键术语"><a href="#3-5-关键术语" class="headerlink" title="3.5 关键术语"></a>3.5 关键术语</h3></li></ul><p><strong>主题，分区和偏移</strong></p><p>主题是特定的数据流。它与NoSQL数据库中的表非常相似。与NoSQL数据库中的表一样，该主题被拆分为分区，使主题能够分布在各个节点上。与表中的主键一样，主题具有每个分区的偏移量。您可以使用其主题，分区和偏移量唯一标识消息。</p><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/2019051511064032.png" alt="img"></p><p><strong>分区</strong></p><p>分区使主题可以在群集中分布。分区是水平可伸缩性的并行度单位。一个主题可以跨节点进行多个分区扩展。</p><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/20190515110659387.png" alt="img"></p><p>消息根据分区键分配给分区; 如果没有分区键，则随机分配该分区。使用正确的密钥来避免热点非常重要。</p><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/20190515110713341.png" alt="img"></p><p>分区中的每个消息都被分配一个称为偏移量的增量ID。每个分区的偏移量是唯一的，消息只在分区内排序。写入分区的消息是不可变的。</p><h4 id="消息系统介绍"><a href="#消息系统介绍" class="headerlink" title="消息系统介绍"></a>消息系统介绍</h4><p>一个消息系统负责将数据从一个应用传递到另外一个应用，应用只需关注于数据，无需关注数据在两个或多个应用间是如何传递的。分布式消息传递基于可靠的消息队列，在客户端应用和消息系统之间异步传递消息。有两种主要的消息传递模式：<strong>点对点传递模式、发布-订阅模式</strong>。大部分的消息系统选用发布-订阅模式。<strong>Kafka就是一种发布-订阅模式</strong>。</p><h4 id="点对点消息传递模式"><a href="#点对点消息传递模式" class="headerlink" title="点对点消息传递模式"></a>点对点消息传递模式</h4><p>在点对点消息系统中，消息持久化到一个队列中。此时，将有一个或多个消费者消费队列中的数据。但是一条消息只能被消费一次。当一个消费者消费了队列中的某条数据之后，该条数据则从消息队列中删除。该模式即使有多个消费者同时消费数据，也能保证数据处理的顺序。这种架构描述示意图如下：</p><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/1228818-20180507190326476-771565746.png" alt="img"></p><p><strong>生产者发送一条消息到queue，只有一个消费者能收到</strong>。</p><h4 id="发布-订阅消息传递模式"><a href="#发布-订阅消息传递模式" class="headerlink" title="发布-订阅消息传递模式"></a>发布-订阅消息传递模式</h4><p>在发布-订阅消息系统中，消息被持久化到一个topic中。与点对点消息系统不同的是，消费者可以订阅一个或多个topic，消费者可以消费该topic中所有的数据，同一条数据可以被多个消费者消费，数据被消费后不会立马删除。在发布-订阅消息系统中，消息的生产者称为发布者，消费者称为订阅者。该模式的示例图如下：</p><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/1228818-20180507190443404-1266011458.png" alt="img"></p><p><strong>发布者发送到topic的消息，只有订阅了topic的订阅者才会收到消息</strong>。</p><h4 id="Kafka的优点"><a href="#Kafka的优点" class="headerlink" title="Kafka的优点"></a>Kafka的优点</h4><h5 id="解耦"><a href="#解耦" class="headerlink" title="解耦"></a>解耦</h5><p>在项目启动之初来预测将来项目会碰到什么需求，是极其困难的。消息系统在处理过程中间插入了一个隐含的、基于数据的接口层，两边的处理过程都要实现这一接口。这允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。</p><h5 id="冗余（副本）"><a href="#冗余（副本）" class="headerlink" title="冗余（副本）"></a>冗余（副本）</h5><p>有些情况下，处理数据的过程会失败。除非数据被持久化，否则将造成丢失。消息队列把数据进行持久化直到它们已经被完全处理，通过这一方式规避了数据丢失风险。许多消息队列所采用的”插入-获取-删除”范式中，在把一个消息从队列中删除之前，需要你的处理系统明确的指出该消息已经被处理完毕，从而确保你的数据被安全的保存直到你使用完毕。</p><h5 id="扩展性"><a href="#扩展性" class="headerlink" title="扩展性"></a>扩展性</h5><p>因为消息队列解耦了你的处理过程，所以增大消息入队和处理的频率是很容易的，只要另外增加处理过程即可。不需要改变代码、不需要调节参数。扩展就像调大电力按钮一样简单。</p><h5 id="灵活性-amp-峰值处理能力"><a href="#灵活性-amp-峰值处理能力" class="headerlink" title="灵活性&amp;峰值处理能力"></a>灵活性&amp;峰值处理能力</h5><p>在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见；如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃。</p><h5 id="可恢复性"><a href="#可恢复性" class="headerlink" title="可恢复性"></a>可恢复性</h5><p>系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。</p><h5 id="顺序保证"><a href="#顺序保证" class="headerlink" title="顺序保证"></a>顺序保证</h5><p>在大多使用场景下，数据处理的顺序都很重要。大部分消息队列本来就是排序的，并且能保证数据会按照特定的顺序来处理。Kafka保证一个Partition内的消息的有序性。</p><h5 id="缓冲"><a href="#缓冲" class="headerlink" title="缓冲"></a>缓冲</h5><p>在任何重要的系统中，都会有需要不同的处理时间的元素。例如，加载一张图片比应用过滤器花费更少的时间。消息队列通过一个缓冲层来帮助任务最高效率的执行———写入队列的处理会尽可能的快速。该缓冲有助于控制和优化数据流经过系统的速度。</p><h5 id="异步通信"><a href="#异步通信" class="headerlink" title="异步通信"></a>异步通信</h5><p>很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。</p><h4 id="常用Message-Queue对比"><a href="#常用Message-Queue对比" class="headerlink" title="常用Message Queue对比"></a>常用Message Queue对比</h4><h5 id="RabbitMQ"><a href="#RabbitMQ" class="headerlink" title="RabbitMQ"></a>RabbitMQ</h5><p>RabbitMQ是使用Erlang编写的一个开源的消息队列，本身支持很多的协议：AMQP，XMPP, SMTP, STOMP，也正因如此，它非常重量级，更适合于企业级的开发。同时实现了Broker构架，这意味着消息在发送给客户端时先在中心队列排队。对路由，负载均衡或者数据持久化都有很好的支持。</p><h5 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h5><p>Redis是一个基于Key-Value对的NoSQL数据库，开发维护很活跃。虽然它是一个Key-Value数据库存储系统，但它本身支持MQ功能，所以完全可以当做一个轻量级的队列服务来使用。对于RabbitMQ和Redis的入队和出队操作，各执行100万次，每10万次记录一次执行时间。测试数据分为128Bytes、512Bytes、1K和10K四个不同大小的数据。实验表明：入队时，当数据比较小时Redis的性能要高于RabbitMQ，而如果数据大小超过了10K，Redis则慢的无法忍受；出队时，无论数据大小，Redis都表现出非常好的性能，而RabbitMQ的出队性能则远低于Redis。</p><h5 id="ZeroMQ"><a href="#ZeroMQ" class="headerlink" title="ZeroMQ"></a>ZeroMQ</h5><p>ZeroMQ号称最快的消息队列系统，尤其针对大吞吐量的需求场景。ZeroMQ能够实现RabbitMQ不擅长的高级&#x2F;复杂的队列，但是开发人员需要自己组合多种技术框架，技术上的复杂度是对这MQ能够应用成功的挑战。ZeroMQ具有一个独特的非中间件的模式，你不需要安装和运行一个消息服务器或中间件，因为你的应用程序将扮演这个服务器角色。你只需要简单的引用ZeroMQ程序库，可以使用NuGet安装，然后你就可以愉快的在应用程序之间发送消息了。但是ZeroMQ仅提供非持久性的队列，也就是说如果宕机，数据将会丢失。其中，Twitter的Storm 0.9.0以前的版本中默认使用ZeroMQ作为数据流的传输（Storm从0.9版本开始同时支持ZeroMQ和Netty作为传输模块）。</p><h5 id="ActiveMQ"><a href="#ActiveMQ" class="headerlink" title="ActiveMQ"></a>ActiveMQ</h5><p>ActiveMQ是Apache下的一个子项目。 类似于ZeroMQ，它能够以代理人和点对点的技术实现队列。同时类似于RabbitMQ，它少量代码就可以高效地实现高级应用场景。</p><h5 id="Kafka-x2F-Jafka"><a href="#Kafka-x2F-Jafka" class="headerlink" title="Kafka&#x2F;Jafka"></a>Kafka&#x2F;Jafka</h5><p>Kafka是Apache下的一个子项目，是一个高性能跨语言分布式发布&#x2F;订阅消息队列系统，而Jafka是在Kafka之上孵化而来的，即Kafka的一个升级版。具有以下特性：快速持久化，可以在O(1)的系统开销下进行消息持久化；高吞吐，在一台普通的服务器上既可以达到10W&#x2F;s的吞吐速率；完全的分布式系统，Broker、Producer、Consumer都原生自动支持分布式，自动实现负载均衡；支持Hadoop数据并行加载，对于像Hadoop的一样的日志数据和离线分析系统，但又要求实时处理的限制，这是一个可行的解决方案。Kafka通过Hadoop的并行加载机制统一了在线和离线的消息处理。Apache Kafka相对于ActiveMQ是一个非常轻量级的消息系统，除了性能非常好之外，还是一个工作良好的分布式系统。</p><h2 id="算法笔记"><a href="#算法笔记" class="headerlink" title="算法笔记"></a>算法笔记</h2><h3 id="统计推荐"><a href="#统计推荐" class="headerlink" title="统计推荐"></a>统计推荐</h3><p>主要就是通过spark.sql使用查询语句进行排行的</p><h4 id="历史热门商品推荐"><a href="#历史热门商品推荐" class="headerlink" title="历史热门商品推荐"></a>历史热门商品推荐</h4><p>根据评价次数进行排行</p><h4 id="近期热门"><a href="#近期热门" class="headerlink" title="近期热门"></a>近期热门</h4><p>按月进行热门热门商品推荐</p><h4 id="平均评分成绩排行"><a href="#平均评分成绩排行" class="headerlink" title="平均评分成绩排行"></a>平均评分成绩排行</h4><p>对通过商品的评分取均值进行排行</p><h3 id="离线推荐"><a href="#离线推荐" class="headerlink" title="离线推荐"></a>离线推荐</h3><h4 id="ALS算法"><a href="#ALS算法" class="headerlink" title="ALS算法"></a>ALS算法</h4><p>隐语义模型是一种比较常用的协同过滤算法，基本思想是对稀疏矩阵进行模型分解，评估出缺失项的值，以此来得到一个基本的训练模型。然后依照此模型可以针对新的用户和物品数据进行评估。ALS是采用交替的最小二乘法来算出缺失项的。交替的最小二乘法是在最小二乘法的基础上发展而来的。</p><p>协同过滤算法，用户特征，商品特征，推荐</p><h5 id="模型评估和参数选取"><a href="#模型评估和参数选取" class="headerlink" title="模型评估和参数选取"></a>模型评估和参数选取</h5><h6 id="均方根误差"><a href="#均方根误差" class="headerlink" title="均方根误差"></a>均方根误差</h6><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/image-20210120003810727.png" alt="image-20210120003810727"></p><h4 id="特征向量"><a href="#特征向量" class="headerlink" title="特征向量"></a>特征向量</h4><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/image-20210120003449718.png" alt="image-20210120003449718"></p><p>tpi 商品p的特征向量， tqi商品q的特征向量</p><p>基于商品的特征向量，计算商品的相似度，进行推荐</p><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/image-20210120003935012.png" alt="image-20210120003935012"></p><h3 id="实时推荐"><a href="#实时推荐" class="headerlink" title="实时推荐"></a>实时推荐</h3><p>背景：用户对产品的偏好随时间的推移总是会改变</p><p>要求：</p><ol><li><p>用户评分后或者最近几次评分后系统可以更新推荐结果</p></li><li><p>计算快，准确率可适当降低</p></li></ol><p>推荐算法公式：</p><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/clip_image002.jpg" alt="img"></p><p>Rr表示用户u 对商品r 的评分；</p><p>sim(q,r)表示商品q 与商品r 的相似度，设定最小相似度为0.6，当商品q和商品r 相似度低于0.6 的阈值，则视为两者不相关并忽略；</p><p>sim_sum 表示q 与RK 中商品相似度大于最小阈值的个数；</p><p>incount 表示RK 中与商品q 相似的、且本身评分较高（&gt;&#x3D;3）的商品个数；</p><p>recount 表示RK 中与商品q 相似的、且本身评分较低（&lt;3）的商品个数；</p><p>公式前部分：对于每个候选商品q，从u 最近的K 个评分中，找出与q 相似度较高（&gt;&#x3D;0.6）的u 已评分商品们（复用离线的相似表），对于这些商品们中的每个商品r，将r 与q 的相似度乘以用户u 对r 的评分，将这些乘积计算平均数，作为用户u 对商品q 的评分预测</p><p>后半部分（奖惩因子）：</p><p>incount：跟候选商品q相似且评分大于某一阈值（&gt;&#x3D;3)的个数</p><p>与候选商品q的相似度越高还评分越高的，我们应该更大力度的推荐，优先级更高。</p>]]></content>
      
      
      <categories>
          
          <category> 开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 推荐系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Git</title>
      <link href="/2020/12/28/Git/"/>
      <url>/2020/12/28/Git/</url>
      
        <content type="html"><![CDATA[<h1 id="Git"><a href="#Git" class="headerlink" title="Git"></a>Git</h1><h3 id="撤销merge操作"><a href="#撤销merge操作" class="headerlink" title="撤销merge操作"></a>撤销merge操作</h3><p><strong>方法一，reset 到 merge 前的版本，然后再重做接下来的操作，要求每个合作者都晓得怎么将本地的 HEAD 都回滚回去：</strong></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ git checkout 【行merge操作时所在的分支】</span><br><span class="line">$ git reset --merge </span><br><span class="line">$ // git reset --hard 【merge前的版本号】 </span><br></pre></td></tr></table></figure><p><strong>方法二，当 merge 以后还有别的操作和改动时，git 正好也有办法能撤销 merge，用 git revert</strong>：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ git revert -m 【要撤销的那条merge线的编号，从1开始计算（怎么看哪条线是几啊？）】 【merge前的版本号】</span><br><span class="line">Finished one revert.</span><br><span class="line">[master 88edd6d] Revert &quot;Merge branch &#x27;jk/post-checkout&#x27;&quot;</span><br><span class="line"> 1 files changed, 0 insertions(+), 2 deletions(-)</span><br></pre></td></tr></table></figure><p>这样会创建新的 commit 来抵消对应的 merge 操作，而且以后 git merge 【那个编号所代表的分支】 会提示：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Already up-to-date.</span><br></pre></td></tr></table></figure><p>因为使用方法二会让 git 误以为这个分支的东西都是咱们不想要的。</p><p><strong>方法三，怎么撤销方法二：</strong></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ git revert 【方法二撤销merge时提交的commit的版本号，这里是88edd6d】</span><br><span class="line">Finished one revert.</span><br><span class="line">[master 268e243] Revert &quot;Revert &quot;Merge branch &#x27;jk/post-checkout&#x27;&quot;&quot;</span><br><span class="line"> 1 files changed, 2 insertions(+), 0 deletions(-)</span><br></pre></td></tr></table></figure><p>这样就行了，可以正常 merge 了，不过可能会有很多冲突：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ git merge jk/post-checkout</span><br><span class="line">Auto-merging test.txt</span><br><span class="line">Merge made by recursive.</span><br><span class="line"> test.txt |    1 +</span><br><span class="line"> 1 files changed, 1 insertions(+), 0 deletions(-)</span><br></pre></td></tr></table></figure><h3 id="HEAD-detached-from-XXXX解决方法"><a href="#HEAD-detached-from-XXXX解决方法" class="headerlink" title="HEAD detached from XXXX解决方法"></a>HEAD detached from XXXX解决方法</h3><p>这是由于指针指向了其中的一次提交，checkout到分支即可。</p><h3 id="远程关联及删除"><a href="#远程关联及删除" class="headerlink" title="远程关联及删除"></a>远程关联及删除</h3><p>Git 创建本地分支以及切换到本地分支</p><p>&#x2F;&#x2F; test 是分支名称</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git checkout -b test</span><br></pre></td></tr></table></figure><p>创建远程分支，名称我设置为和本地一样，当然可以随便设置</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git push origin test:test</span><br></pre></td></tr></table></figure><p>进行分支关联</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git branch --set-upstream-to=origin/test test</span><br></pre></td></tr></table></figure><p>删除远程分支</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git push origin -d test</span><br></pre></td></tr></table></figure><p>删除本地分支 注意删除时候要切换到其他分支</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git branch -d test</span><br></pre></td></tr></table></figure><h3 id="把别人的项目修改后，提交到自己的-github，并同步更新"><a href="#把别人的项目修改后，提交到自己的-github，并同步更新" class="headerlink" title="把别人的项目修改后，提交到自己的 github，并同步更新"></a>把别人的项目修改后，提交到自己的 github，并同步更新</h3><p>如果你在 github 上 clone 了别人的项目，在本地做了一些修改后，直接git push肯定会遇到问题。因为你提交的远程仓库是别人的仓库。</p><h3 id="如何把-clone-后修改的代码提交到自己的-github-上呢？"><a href="#如何把-clone-后修改的代码提交到自己的-github-上呢？" class="headerlink" title="如何把 clone 后修改的代码提交到自己的 github 上呢？"></a>如何把 clone 后修改的代码提交到自己的 github 上呢？</h3><p>方法一：</p><ul><li>修改 <code>.git/config</code> 这个文件，把 <code>url</code> 换成自己新建的仓库地址</li></ul><p>方法二：</p><ul><li>先 fork 别人的代码，在你的 github 上就出现了同名的项目，这个项目就属于你自己了，然后把这个项目 <code>git clone</code> 到本地，改改改，然后 <code>git push</code> 即可</li></ul><h3 id="你-fork-了别人的项目之后，他更新了代码，你-fork-的项目如何与原项目同步更新？"><a href="#你-fork-了别人的项目之后，他更新了代码，你-fork-的项目如何与原项目同步更新？" class="headerlink" title="你 fork 了别人的项目之后，他更新了代码，你 fork 的项目如何与原项目同步更新？"></a>你 fork 了别人的项目之后，他更新了代码，你 fork 的项目如何与原项目同步更新？</h3><p>方法一：（最简单的方法）</p><ul><li><p>远程仓库执行 <code>fork</code> 操作，得到自己的 <code>url</code></p></li><li><p><code>git clone url</code> 到本地</p></li><li><p>配置远程分支：<code>git remote add upstream [fork项目的地址]</code></p></li><li><p>运行 <code>git remote -v</code>，会出现：</p><p>origin <a href="https://gitee.com/phpzhi/testPro.git">https://gitee.com/phpzhi/testPro.git</a> (fetch)<br>origin <a href="https://gitee.com/phpzhi/testPro.git">https://gitee.com/phpzhi/testPro.git</a> (push)<br>upstream <a href="https://gitee.com/opan/testPro.git">https://gitee.com/opan/testPro.git</a> (fetch)<br>upstream <a href="https://gitee.com/opan/testPro.git">https://gitee.com/opan/testPro.git</a> (push)</p></li><li><p>执行 <code>git fetch upstream</code> 拉取远程仓库的代码</p></li><li><p>合并拉取的代码 <code>git merge upstream/master</code></p></li><li><p>上传 <code>git push</code></p></li></ul><p>方法二：让原项目的作者把你加入该项目的成员，即可对该项目进行各种骚操作（废话。。）</p><p>方法三：</p><ul><li>首先 <code>git clone</code> 原项目到本地</li><li>在 github 上 <code>fork</code> 该项目，这时有了自己的仓库地址 <code>url</code></li><li>执行 <code>git remote add name url</code>，name 是你的仓库别名，可以随便改，但不要跟已有的冲突</li><li>最后，通过 <code>git fetch origin</code> 来获取原项目的最新代码</li><li><code>git merge -m &lt;msg&gt;</code> 大功告成！<br>（这里如果产生了冲突，就手动解决，完了之后执行 <code>git add .</code> 和<code>git commit -m msg</code>，最后<code>git push name</code></li></ul><p>方法四：通过创建新的分支，进行合并操作（操作有点多）</p><ul><li><code>fork</code> 原项目到自己的 git 上，拥有了自己 <code>url</code></li><li>执行 <code>git clone url</code></li><li>创建分支，<code>git branch branchname</code></li><li>切换分支，<code>git checkout branchname</code></li><li>随便修修改改，以后就在这个分支开发了，写完代码后，将修改提交到自己的 git 上，第1次推送的时候会有提示<code>git push --set-upstream origin branchname</code>，照着打就行</li><li>当原项目有更新后，我们可以找到，在码云项目名称(<code>forked from xxx / xxx</code>)后面那里有一个<code>强制拉取代码</code>按钮。我们先切换到 <code>master</code> 分支，再点它，就会同步原项目的修改，放心，你的分支内容不会受到影响。<br>（至于 github 的，点击 <code>Pull Request</code>，<code>New Pull Request</code>，下拉框里将<code>原项目-&gt;自己的项目</code>，点击 <code>compare across forks</code>，按照提示一通操作完成后，点击绿色的<code>Merge Pull Request</code>，OK了）</li><li>这时候在本地，切换到 <code>master</code> 分支，执行 <code>git pull</code>，将这些修改同步下来</li><li>切换到 <code>branchname</code> 分支，执行 <code>git merge master -m msg</code> ，将这些修改合并到自己的开发项目中，ok，开心了不？</li><li>大功告成！</li></ul><h3 id="扩展：如何把自己对项目的改动，提交到-fork-的那个原项目呢？"><a href="#扩展：如何把自己对项目的改动，提交到-fork-的那个原项目呢？" class="headerlink" title="扩展：如何把自己对项目的改动，提交到 fork 的那个原项目呢？"></a>扩展：如何把自己对项目的改动，提交到 fork 的那个原项目呢？</h3><p>  在你 fork 的项目页面上，有一个按钮叫 <code>Pull Request</code>，点了它就会把你的修改发送到对方的项目里，最终由原项目主人决定是否接受你的修改~</p>]]></content>
      
      
      <categories>
          
          <category> 开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>专业实践</title>
      <link href="/2020/12/28/%E4%B8%93%E4%B8%9A%E5%AE%9E%E8%B7%B5/"/>
      <url>/2020/12/28/%E4%B8%93%E4%B8%9A%E5%AE%9E%E8%B7%B5/</url>
      
        <content type="html"><![CDATA[<h1 id="专业实践"><a href="#专业实践" class="headerlink" title="专业实践"></a>专业实践</h1><h2 id="技术选型"><a href="#技术选型" class="headerlink" title="技术选型"></a>技术选型</h2><h3 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h3><p>Redis（Remote Dictionary Server )，即远程字典服务，是一个开源的使用ANSI C语言编写、支持网络、<strong>可基于内存亦可持久化的日志型、Key-Value数据库</strong>，并提供多种语言的API。从2010年3月15日起，Redis的开发工作由VMware主持。从2013年5月开始，Redis的开发由Pivotal赞助。</p><h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><p>redis是一个<strong>key-value存储系统</strong>。和Memcached类似，它支持存储的value类型相对更多，包括string(字符串)、list(链表)、set(集合)、zset(sorted set –有序集合)和hash（哈希类型）。这些数据类型都支持push&#x2F;pop、add&#x2F;remove及取交集并集和差集及更丰富的操作，而且这些操作都是<strong>原子性</strong>的。在此基础上，<strong>redis支持各种不同方式的排序</strong>。与memcached一样，<strong>为了保证效率，数据都是缓存在内存中</strong>。<strong>区别的是redis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，并且在此基础上实现了master-slave(主从)同步。</strong></p><p>Redis 是一个<strong>高性能</strong>的key-value数据库。 redis的出现，很大程度补偿了<a href="https://baike.baidu.com/item/memcached">memcached</a>这类key&#x2F;value存储的不足，<strong>在部 分场合可以对关系数据库起到很好的补充作用</strong>。它提供了Java，C&#x2F;C++，C#，PHP，JavaScript，Perl，Object-C，Python，Ruby，Erlang等客户端，使用很方便。</p><blockquote><p><strong>memcached</strong>是一套分布式的高速缓存系统，由<a href="https://baike.baidu.com/item/LiveJournal">LiveJournal</a>的Brad Fitzpatrick开发，但被许多网站使用。这是一套<a href="https://baike.baidu.com/item/%E5%BC%80%E6%94%BE%E6%BA%90%E4%BB%A3%E7%A0%81">开放源代码</a><a href="https://baike.baidu.com/item/%E8%BD%AF%E4%BB%B6">软件</a>，以BSD license授权发布。</p><p>memcached缺乏<a href="https://baike.baidu.com/item/%E8%AE%A4%E8%AF%81">认证</a>以及<a href="https://baike.baidu.com/item/%E5%AE%89%E5%85%A8">安全</a>管制，这代表应该将memcached服务器放置在<a href="https://baike.baidu.com/item/%E9%98%B2%E7%81%AB%E5%A2%99">防火墙</a>后。</p><p>memcached的<a href="https://baike.baidu.com/item/API">API</a>使用三十二比特的<a href="https://baike.baidu.com/item/%E5%BE%AA%E7%8E%AF%E5%86%97%E4%BD%99%E6%A0%A1%E9%AA%8C">循环冗余校验</a>（CRC-32）计算<a href="https://baike.baidu.com/item/%E9%94%AE%E5%80%BC">键值</a>后，将数据分散在不同的机器上。当表格满了以后，接下来新增的数据会以<a href="https://baike.baidu.com/item/LRU">LRU</a>机制替换掉。由于memcached通常只是当作缓存系统使用，所以使用memcached的应用程序在写回较慢的系统时（像是后端的<a href="https://baike.baidu.com/item/%E6%95%B0%E6%8D%AE%E5%BA%93">数据库</a>）需要额外的代码更新memcached内的数据。</p></blockquote><p><strong>Redis支持主从同步</strong>。数据可以从主服务器向任意数量的从服务器上同步，从服务器可以是关联其他从服务器的主服务器。这使得<strong>Redis可执行单层树复制</strong>。存盘可以有意无意的对数据进行写操作。由于完全实现了发布&#x2F;订阅机制，使得从数据库在任何地方同步树时，可订阅一个频道并接收主服务器完整的消息发布记录。同步对读取操作的可扩展性和数据冗余很有帮助。</p><p>redis的官网地址，非常好记，是redis.io。（域名后缀io属于国家域名，是british Indian Ocean territory，即英属印度洋领地），Vmware在资助着redis项目的开发和维护。</p><h4 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h4><p>下面是官方的bench-mark数据：</p><p>测试完成了50个并发执行100000个请求。</p><p>设置和获取的值是一个256字节字符串。</p><p>Linux box是运行Linux 2.6,这是X3320 Xeon 2.5 ghz。</p><p>文本执行使用loopback接口(127.0.0.1)。</p><p>结果:读的速度是110000次&#x2F;s,写的速度是81000次&#x2F;s 。</p><h4 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 注册服务</span></span><br><span class="line">redis-server --service-install redis.windows.conf</span><br><span class="line"><span class="comment"># 启动服务</span></span><br><span class="line">redis-server --service-start</span><br><span class="line"><span class="comment"># 停止服务</span></span><br><span class="line">redis-server --service-stop</span><br><span class="line"><span class="comment"># 删除服务</span></span><br><span class="line">redis-server --service-uninstall</span><br></pre></td></tr></table></figure><h3 id="Mongodb"><a href="#Mongodb" class="headerlink" title="Mongodb"></a>Mongodb</h3><p>MongoDB是一个基于分布式文件存储的数据库。由C++语言编写。旨在为WEB应用提供可扩展的高性能数据存储解决方案。</p><p>MongoDB是一个介于关系数据库和非关系数据库之间的产品，是非关系数据库当中功能最丰富，最像关系数据库的。它支持的数据结构非常松散，是类似<a href="https://baike.baidu.com/item/json">json</a>的<a href="https://baike.baidu.com/item/bson">bson</a>格式，因此可以存储比较复杂的数据类型。Mongo最大的特点是它支持的查询语言非常强大，其语法有点类似于面向对象的查询语言，几乎可以实现类似关系数据库单表查询的绝大部分功能，而且还支持对数据建立<a href="https://baike.baidu.com/item/%E7%B4%A2%E5%BC%95">索引</a>。</p><h3 id="RabbitMQ"><a href="#RabbitMQ" class="headerlink" title="RabbitMQ"></a>RabbitMQ</h3><h4 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h4><p><a href="http://mp.weixin.qq.com/s?__biz=MzI3ODcxMzQzMw==&mid=2247492279&idx=2&sn=69e1127940d2bdb8dca44917282b907e&chksm=eb506781dc27ee97caaf95e10bbdb55d89faf70cae276a7a4afb8b1486ae6139aef248252c8b&scene=21#wechat_redirect">MQ</a>全称为Message Queue, 消息队列（<a href="http://mp.weixin.qq.com/s?__biz=MzI3ODcxMzQzMw==&mid=2247492279&idx=2&sn=69e1127940d2bdb8dca44917282b907e&chksm=eb506781dc27ee97caaf95e10bbdb55d89faf70cae276a7a4afb8b1486ae6139aef248252c8b&scene=21#wechat_redirect">MQ</a>）是一种应用程序对应用程序的通信方法。应用程序通过读写出入队列的消息（针对应用程序的数据）来通信，而无需专用连接来链接它们。</p><p>消息传递指的是程序之间通过在消息中发送数据进行通信，而不是通过直接调用彼此来通信，直接调用通常是用于诸如远程过程调用的技术。排队指的是应用程序通过 队列来通信。队列的使用除去了接收和发送应用程序同时执行的要求。</p><p><a href="http://mp.weixin.qq.com/s?__biz=MzI3ODcxMzQzMw==&mid=2247494139&idx=2&sn=a33f1781bf8ee8094827118a4ffe394d&chksm=eb506ccddc27e5db0191cce12d753b683de89f2cf285410b514fed9bfa46f5a9b1f4b817968f&scene=21#wechat_redirect">RabbitMQ</a>是使用Erlang语言开发的开源消息队列系统，基于AMQP协议来实现。AMQP的主要特征是面向消息、队列、路由(包括点对点和发布&#x2F;订阅)、可靠性、安全。</p><p>AMQP协议更多用在企业系统内，对数据一致性、稳定性和可靠性要求很高的场景，对性能和吞吐量的要求还在其次。</p><h4 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h4><h5 id="1-解耦（为面向服务的架构（SOA）提供基本的最终一致性实现）"><a href="#1-解耦（为面向服务的架构（SOA）提供基本的最终一致性实现）" class="headerlink" title="1. 解耦（为面向服务的架构（SOA）提供基本的最终一致性实现）"></a>1. 解耦（为面向服务的架构（SOA）提供基本的最终一致性实现）</h5><p>场景说明：用户下单后，订单系统需要通知库存系统。传统的做法是，订单系统调用库存系统的接口。</p><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/1218593-20200921081913448-1945672992.webp" alt="img"></p><p>传统模式的缺点：</p><ul><li>假如库存系统无法访问，则订单减库存将失败，从而导致订单失败</li><li>订单系统与库存系统耦合</li></ul><p>引入消息队列</p><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/1218593-20200921081913854-1671937319.webp" alt="img"></p><ul><li>订单系统：用户下单后，订单系统完成持久化处理，将消息写入消息队列，返回用户订单下单成功</li><li>库存系统：订阅下单的消息，采用拉&#x2F;推的方式，获取下单信息，库存系统根据下单信息，进行库存操作</li><li>假如：在下单时库存系统不能正常使用。也不影响正常下单，因为下单后，订单系统写入消息队列就不再关心其他的后续操作了。实现订单系统与库存系统的应用解耦</li><li>为了保证库存肯定有，可以将队列大小设置成库存数量，或者采用其他方式解决。</li></ul><p>基于消息的模型，关心的是“通知”，而非“处理”。</p><p>短信、邮件通知、缓存刷新等操作使用消息队列进行通知。</p><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/1218593-20200921081914144-597556887.webp" alt="img"></p><p><strong>消息队列和RPC的区别与比较：</strong></p><p><a href="http://mp.weixin.qq.com/s?__biz=MzI3ODcxMzQzMw==&mid=2247490569&idx=2&sn=5cb8c394079957c961d14ecacb295767&chksm=eb53993fdc2410293f95fecc661996374ba352702173c6d1dd16ab8870379f0fce7fe039389e&scene=21#wechat_redirect">RPC</a>: 异步调用，及时获得调用结果，具有强一致性结果，关心业务调用处理结果。</p><p>消息队列：两次异步<a href="http://mp.weixin.qq.com/s?__biz=MzI3ODcxMzQzMw==&mid=2247490569&idx=2&sn=5cb8c394079957c961d14ecacb295767&chksm=eb53993fdc2410293f95fecc661996374ba352702173c6d1dd16ab8870379f0fce7fe039389e&scene=21#wechat_redirect">RPC</a>调用，将调用内容在队列中进行转储，并选择合适的时机进行投递（错峰流控）</p><h5 id="2-异步提升效率"><a href="#2-异步提升效率" class="headerlink" title="2. 异步提升效率"></a>2. 异步提升效率</h5><p>场景说明：用户注册后，需要发注册邮件和注册短信。传统的做法有两种</p><p>1.串行的方式；2.并行方式</p><p>（1）串行方式：将注册信息写入数据库成功后，发送注册邮件，再发送注册短信。以上三个任务全部完成后，返回给客户端</p><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/1218593-20200921081914465-464155286.webp" alt="img"></p><p>（2）并行方式：将注册信息写入数据库成功后，发送注册邮件的同时，发送注册短信。以上三个任务完成后，返回给客户端。与串行的差别是，并行的方式可以提高处理的时间</p><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/1218593-20200921081914743-1271337046.webp" alt="img"></p><p>（3）引入消息队列，将不是必须的业务逻辑，异步处理。改造后的架构如下：</p><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/1218593-20200921081915004-641904196.webp" alt="img"></p><h5 id="3-流量削峰"><a href="#3-流量削峰" class="headerlink" title="3. 流量削峰"></a>3. 流量削峰</h5><p>流量削锋也是消息队列中的常用场景，一般在秒杀或团抢活动中使用广泛。关于秒杀系列文章可以关注公众号Java技术栈获取阅读。</p><p>应用场景：系统其他时间A系统每秒请求量就100个，系统可以稳定运行。系统每天晚间八点有秒杀活动，每秒并发请求量增至1万条，但是系统最大的处理能力只能每秒处理1000个请求，于是系统崩溃，服务器宕机。</p><p>之前架构：大量用户（100万用户）通过浏览器在晚上八点高峰期同时参与秒杀活动。大量的请求涌入我们的系统中，高峰期达到每秒钟5000个请求，大量的请求打到<a href="http://mp.weixin.qq.com/s?__biz=MzI3ODcxMzQzMw==&mid=2247486173&idx=2&sn=0603756b36279b5f5f036151af85f9fd&chksm=eb538febdc2406fd70748604c500eeaea584306c137cb2020ab5a72187c9359926015e00a46d&scene=21#wechat_redirect">MySQL</a>上，每秒钟预计执行3000条SQL。</p><p>但是一般的<a href="http://mp.weixin.qq.com/s?__biz=MzI3ODcxMzQzMw==&mid=2247486173&idx=2&sn=0603756b36279b5f5f036151af85f9fd&chksm=eb538febdc2406fd70748604c500eeaea584306c137cb2020ab5a72187c9359926015e00a46d&scene=21#wechat_redirect">MySQL</a>每秒钟扛住2000个请求就不错了，如果达到3000个请求的话可能<a href="http://mp.weixin.qq.com/s?__biz=MzI3ODcxMzQzMw==&mid=2247486173&idx=2&sn=0603756b36279b5f5f036151af85f9fd&chksm=eb538febdc2406fd70748604c500eeaea584306c137cb2020ab5a72187c9359926015e00a46d&scene=21#wechat_redirect">MySQL</a>直接就瘫痪了，从而系统无法被使用。但是高峰期过了之后，就成了低峰期，可能也就1万用户访问系统，每秒的请求数量也就50个左右，整个系统几乎没有任何压力。</p><p>引入<a href="http://mp.weixin.qq.com/s?__biz=MzI3ODcxMzQzMw==&mid=2247492279&idx=2&sn=69e1127940d2bdb8dca44917282b907e&chksm=eb506781dc27ee97caaf95e10bbdb55d89faf70cae276a7a4afb8b1486ae6139aef248252c8b&scene=21#wechat_redirect">MQ</a>：100万用户在高峰期的时候，每秒请求有5000个请求左右，将这5000请求写入MQ里面，系统A每秒最多只能处理2000请求，因为MySQL每秒只能处理2000个请求。</p><p>系统A从<a href="http://mp.weixin.qq.com/s?__biz=MzI3ODcxMzQzMw==&mid=2247492279&idx=2&sn=69e1127940d2bdb8dca44917282b907e&chksm=eb506781dc27ee97caaf95e10bbdb55d89faf70cae276a7a4afb8b1486ae6139aef248252c8b&scene=21#wechat_redirect">MQ</a>中慢慢拉取请求，每秒就拉取2000个请求，不要超过自己每秒能处理的请求数量即可。<a href="http://mp.weixin.qq.com/s?__biz=MzI3ODcxMzQzMw==&mid=2247492279&idx=2&sn=69e1127940d2bdb8dca44917282b907e&chksm=eb506781dc27ee97caaf95e10bbdb55d89faf70cae276a7a4afb8b1486ae6139aef248252c8b&scene=21#wechat_redirect">MQ</a>，每秒5000个请求进来，结果只有2000个请求出去，所以在秒杀期间（将近一小时）可能会有几十万或者几百万的请求积压在MQ中。</p><p>这个短暂的高峰期积压是没问题的，因为高峰期过了之后，每秒就只有50个请求进入MQ了，但是系统还是按照每秒2000个请求的速度在处理，所以说，只要高峰期一过，系统就会快速将积压的消息消费掉。</p><p>我们在此计算一下，每秒在MQ积压3000条消息，1分钟会积压18万，1小时积压1000万条消息，高峰期过后，1个多小时就可以将积压的1000万消息消费掉。</p><p><img src="/%E4%B8%93%E4%B8%9A%E5%AE%9E%E8%B7%B5/1218593-20200921081915304-1079912638.webp" alt="img"></p><h4 id="引入消息队列的优缺点"><a href="#引入消息队列的优缺点" class="headerlink" title="引入消息队列的优缺点"></a>引入消息队列的优缺点</h4><h5 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h5><p>优点就是以上的那些场景应用，就是在特殊场景下有其对应的好处，解耦、异步、削峰。</p><h5 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h5><ul><li>**系统的可用性降低<br>**系统引入的外部依赖越多，系统越容易挂掉，本来只是A系统调用BCD三个系统接口就好，ABCD四个系统不报错整个系统会正常运行。引入了<a href="http://mp.weixin.qq.com/s?__biz=MzI3ODcxMzQzMw==&mid=2247492279&idx=2&sn=69e1127940d2bdb8dca44917282b907e&chksm=eb506781dc27ee97caaf95e10bbdb55d89faf70cae276a7a4afb8b1486ae6139aef248252c8b&scene=21#wechat_redirect">MQ</a>之后，虽然ABCD系统没出错，但<a href="http://mp.weixin.qq.com/s?__biz=MzI3ODcxMzQzMw==&mid=2247492279&idx=2&sn=69e1127940d2bdb8dca44917282b907e&chksm=eb506781dc27ee97caaf95e10bbdb55d89faf70cae276a7a4afb8b1486ae6139aef248252c8b&scene=21#wechat_redirect">MQ</a>挂了以后，整个系统也会崩溃。</li><li>**系统的复杂性提高<br>**引入了MQ之后，需要考虑的问题也变得多了，如何保证消息没有重复消费？如何保证消息不丢失？怎么保证消息传递的顺序？</li><li>**一致性问题<br>**A系统发送完消息直接返回成功，但是BCD系统之中若有系统写库失败，则会产生数据不一致的问题。</li></ul><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>所以总结来说，消息队列是一种十分复杂的架构，引入它有很多好处，但是也得针对它带来的坏处做各种额外的技术方案和架构来规避。</p><p>引入<a href="http://mp.weixin.qq.com/s?__biz=MzI3ODcxMzQzMw==&mid=2247492279&idx=2&sn=69e1127940d2bdb8dca44917282b907e&chksm=eb506781dc27ee97caaf95e10bbdb55d89faf70cae276a7a4afb8b1486ae6139aef248252c8b&scene=21#wechat_redirect">MQ</a>系统复杂度提升了一个数量级，但是在有些场景下，就是复杂十倍百倍，还是需要使用<a href="http://mp.weixin.qq.com/s?__biz=MzI3ODcxMzQzMw==&mid=2247492279&idx=2&sn=69e1127940d2bdb8dca44917282b907e&chksm=eb506781dc27ee97caaf95e10bbdb55d89faf70cae276a7a4afb8b1486ae6139aef248252c8b&scene=21#wechat_redirect">MQ</a>。</p><h3 id="Elasticsearch"><a href="#Elasticsearch" class="headerlink" title="Elasticsearch"></a>Elasticsearch</h3><p>Elasticsearch是一个基于<a href="https://baike.baidu.com/item/Lucene/6753302">Lucene</a>的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。Elasticsearch是用Java语言开发的，并作为Apache许可条款下的开放源码发布，是一种流行的企业级搜索引擎。Elasticsearch用于<a href="https://baike.baidu.com/item/%E4%BA%91%E8%AE%A1%E7%AE%97/9969353">云计算</a>中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。官方客户端在Java、.NET（C#）、PHP、Python、Apache Groovy、Ruby和许多其他语言中都是可用的。根据DB-Engines的排名显示，Elasticsearch是最受欢迎的企业搜索引擎，其次是Apache Solr，也是基于Lucene。</p><h3 id="Logstash"><a href="#Logstash" class="headerlink" title="Logstash"></a>Logstash</h3><p>logstash是一种分布式日志收集框架，开发语言是JRuby，当然是为了与Java平台对接，不过与Ruby语法兼容良好，非常简洁强大，经常与ElasticSearch，Kibana配置，组成著名的ELK技术栈，非常适合用来做日志数据的分析。</p><p>当然它可以单独出现，作为日志收集软件，你可以收集日志到多种存储系统或临时中转系统，如MySQL，redis，kakfa，HDFS, lucene，solr等，并不一定是ElasticSearch。</p><p><strong>Logstash is a tool for managing events and logs. You can use it to collect logs, parse them, and store them for later use (like, for searching).</strong></p><p>ref: <a href="http://doc.yonyoucloud.com/doc/logstash-best-practice-cn/index.html">Logstash 最佳实践</a></p><h3 id="Kibana"><a href="#Kibana" class="headerlink" title="Kibana"></a>Kibana</h3><p>Kibana是一款开源的数据分析和可视化平台,它是Elastic Stack成员之一,设计用于和Elasticsearch协作。您可以使用Kibana对Elasticsearch索引中的数据进行搜索、查看、交互操作。您可以很方便的利用图表、表格及地图对数据进行多元化的分析和呈现。</p><h3 id="OSS"><a href="#OSS" class="headerlink" title="OSS"></a>OSS</h3><p>阿里云对象存储服务，简称 OSS，是一种面向海量数据规模的分布式存储服务，具有稳定、可靠、安全、低成本的特点，能够提供十一个九的数据可靠性。OSS提供与平台无关的RESTful API接口，您可以在互联网任何位置存储和访问。OSS的容量和处理能力弹性扩展，并提供多种存储类型供您选择，全面优化存储成本。</p><h4 id="Lombok插件"><a href="#Lombok插件" class="headerlink" title="Lombok插件"></a>Lombok插件</h4><p>通过@Data注解的方式省去了我们平时开发定义JavaBean之后，生成其属性的构造器、getter、setter、equals、hashcode、toString方法；但是，在编译时会自动生成这些方法，在.class文件中。</p><h2 id="笔记"><a href="#笔记" class="headerlink" title="笔记"></a>笔记</h2><h3 id="NoSQL-与-SQL"><a href="#NoSQL-与-SQL" class="headerlink" title="NoSQL 与 SQL"></a>NoSQL 与 SQL</h3><p>1、数据存储方式不同。</p><p>关系bai型和非关系型数据库的主要差异是数据存储的方式。关系型数据天然就是表格式的，因此存储在数据表的行和列中。数据表可以彼此关联协作存储，也很容易提取数据。</p><p>与其相反，非关系型数据不适合存储在数据表的行和列中，而是大块组合在一起。非关系型数据通常存储在数据集中，就像文档、键值对或者图结构。你的数据及其特性是选择数据存储和提取方式的首要影响因素。</p><p>2、扩展方式不同。</p><p>SQL和NoSQL数据库最大的差别可能是在扩展方式上，要支持日益增长的需求当然要扩展。</p><p>要支持更多并发量，SQL数据库是纵向扩展，也就是说提高处理能力，使用速度更快速的计算机，这样处理相同的数据集就更快了。</p><p>因为数据存储在关系表中，操作的性能瓶颈可能涉及很多个表，这都需要通过提高计算机性能来客服。虽然SQL数据库有很大扩展空间，但最终肯定会达到纵向扩展的上限。而NoSQL数据库是横向扩展的。</p><p>而非关系型数据存储天然就是分布式的，NoSQL数据库的扩展可以通过给资源池添加更多普通的数据库服务器(节点)来分担负载。<br>3、对事务性的支持不同。</p><p>如果数据操作需要高事务性或者复杂数据查询需要控制执行计划，那么传统的SQL数据库从性能和稳定性方面考虑是你的最佳选择。SQL数据库支持对事务原子性细粒度控制，并且易于回滚事务。</p><p>虽然NoSQL数据库也可以使用事务操作，但稳定性方面没法和关系型数据库比较，所以它们真正闪亮的价值是在操作的扩展性和大数据量处理方面。</p><h3 id="Apache-Licence-2-0"><a href="#Apache-Licence-2-0" class="headerlink" title="Apache Licence 2.0"></a>Apache Licence 2.0</h3><h3 id="Maven-生命周期"><a href="#Maven-生命周期" class="headerlink" title="Maven 生命周期"></a>Maven 生命周期</h3><h3 id="Fuchsia"><a href="#Fuchsia" class="headerlink" title="Fuchsia"></a>Fuchsia</h3><p>Fuchsia，是由<a href="https://baike.baidu.com/item/Google">Google</a>公司开发的继<a href="https://baike.baidu.com/item/Android/60243">Android</a>和[Chrome OS](<a href="https://baike.baidu.com/item/Chrome">https://baike.baidu.com/item/Chrome</a> OS)之后的第三个系统，已在<a href="https://baike.baidu.com/item/Github">Github</a>中公开的部分源码可以得知。Google对于Fuchsia的说明是“Pink（粉红）+Purple（紫色）&#x3D;Fuchsia（灯笼海棠，一个新的操作系统）”。</p><h3 id="背压"><a href="#背压" class="headerlink" title="背压"></a>背压</h3>]]></content>
      
      
      <categories>
          
          <category> 开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>术语</title>
      <link href="/2020/12/27/%E6%9C%AF%E8%AF%AD/"/>
      <url>/2020/12/27/%E6%9C%AF%E8%AF%AD/</url>
      
        <content type="html"><![CDATA[<h1 id="术语"><a href="#术语" class="headerlink" title="术语"></a>术语</h1><p>PM<br>  项目经理( Project Manager )<br>  从职业角度，是指企业建立以项目经理责任制为核心，对项目实行质量、安全、进度、成本管理的责任保证体系和全面提高项目管理水平设立的重要管理岗位。项目经理是为项目的成功策划和执行负总责的人。<br>  项目经理是项目团队的领导者，项目经理首要职责是在预算范围内按时优质地领导项目小组完成全部项目工作内容，并使客户满意。为此项目经理必须在一系列的项目计划、组织和控制活动中做好领导工作，从而实现项目目标。<br>  当然在互联网公司这个有着项目经理or产品经理的意思。</p><p>  RD<br>  研发（Research and Development）<br>  如：软件RD工程师就是软件研发工程师，诸如PHP程序猿，Java程序猿，无论是爱疯的还是安卓的都是属于这一类别。偏向于后端的技术实现。</p><p>  FE<br>  前端（Front-End）；前端开发（Front-End Development）<br>  FE是web前端研发、前端开发的意思！</p><p>  UE<br>  用户体验（User Experience，简称UX或 UE）<br>  是一种纯主观的在用户使用一个产品（服务）的过程中建立起来的心理感受。因为它是纯主观的，就带有一定的不确定因素。<br>  个体差异也决定了每个用户的真实体验是无法通过其他途径来完全模拟或再现的。但是对于一个界定明确的用户群体来讲，其用户体验的共性是能够经由良好设计的实验来认识到。<br>  计算机技术和互联网的发展，使技术创新形态正在发生转变，以用户为中心、以人为本越来越得到重视，用户体验也因此被称做创新2.0模式的精髓。<br>  另外还有有个组合叫法：UED（产品交互设计师，用户体验师）。</p><p>  UI<br>  用户界面（User Interface）<br>  UI设计则是指对软件的人机交互、操作逻辑、界面美观的整体设计。好的UI设计不仅是让软件变得有个性有品味，还要让软件的操作变得舒适、简单、自由、充分体现软件的定位和特点。<br>  UI还有其它的意义，如Unit Interval，Univ of Iowa，Unlock Instruction，Urgent Interrupt。</p><p>  QA<br>  测试（QUALITY ASSURANCE，中文意思是“质量保证”）<br>  其在ISO8402：1994中的定义是“为了提供足够的信任表明实体能够满足质量要求，而在质量管理体系中实施并根据需要进行证实的全部有计划和有系统的活动”。有些推行ISO9000的组织会设置这样的部门或岗位，负责ISO9000标准所要求的有关质量保证的职能，担任这类工作的人员就叫做QA人员。</p><p>  OP<br>  运维（Operations）<br>  OP这个词语代表的意思很多，这个简称来自于英文的Operations一词。我也不清楚谁最早用op代表运维工程师，不过2010年开始，这个词慢慢被很多人所知道。<br>  OP工作内容主要就是维护公司的服务器能够正常提供服务，细分的话包括系统部分，网络部分，应用程序部分，数据库部分，具体根据公司的规模和职位职能不同，运维的定义也不同。现在市面上主要的OP有三种：网络游戏运维，网站运维，大型项目测试和生产环境运维。</p><p>  DBA<br>  数据库管理员（Database Administrator，简称DBA）<br>  是一个负责管理和维护数据库服务器的人。数据库管理员负责全面管理和控制数据库系统。这个职位对不同的人意味着不同的意义。<br>  另外还有DB，既数据库（Database）。</p><p>还有就是互联网产品设计常用文档类型的缩写： BRD、MRD、PRD、FSD等</p><p>  MRD<br>　　市场需求文档（Market Requirements Document）<br>  获得老大的认同后，产品进入实施，需要先出MRD，具体来说要有更细致的市场与竞争对手分析，通过哪些功能来实现商业目的，功能&#x2F;非功能需求分哪几块，功能的优先级等等。实际工作中，这个阶段PD可能的产出物有Mind Manager的思维图，Excel的Feature List等。<br>　　市场需求文档（MRD）重点放在为一个被提议的新产品或者现有产品的改进定义市场需求。与BRD指出商业问题和解决这些问题的解决方案不同，MRD更深入提议解决方案的细节。它包括一些或者所有这些细节：<br>      a. 解决商业问题所需要的特色<br>      b. 市场竞争分析<br>      c. 功能和非功能需求<br>      d. 特色&#x2F;需求的优先级<br>      e. 用例<br>　　MRD通常是由拥有产品经理，产品营销经理或者行业分析师头衔的人撰写的。MRD通常是一份连续的5-25页Word文档，或者正如之后描述那样在一些机构中甚至更长。</p><p>  PRD<br>　　产品需求文档（Product Requirements Document）<br>  进步一细化，这部分是PD写得最多的内容，也就是传统意义上的需求分析，我们这里主要指UC（use case）文档。主要内容有，功能使用的具体描述（每个UC一般有用例简述、行为者、前置条件、后置条件、UI描述、流程&#x2F;子流程&#x2F;分支流程，等几大块），Visio做的功能点业务流程，界面的说明，demo等。Demo方面，可能用dreamweaver、ps甚至画图板简单画一下，有时候也会有UI&#x2F;UE支持，出高保真的demo，开发将来可以直接用的那种。<br>　　产品需求文档（PRD）重点放在为一个被提议的新产品或者现有产品的改进定义市场需求。与MRD侧重于从市场需要角度看需求的不同，PRD侧重于从产品本身角度看待需求。通常在特点和功能需求上更深入细节，并也可能包括屏幕截图和用户界面流程。在那些MRD不包括具体需求和用例的机构中，PRD就包含这些具体内容。PRD通常是由拥有产品经理，行业分析师或者产品分析师头衔的人撰写的。PRD通常是一份连续的20-50页Word文档，或者针对复杂产品甚至更长。<br>　　提醒：一些机构将这里描述的MRD和PRD合并成一个文档，并称最后的文档为MRD。在这种情况下，MRD包括本段描述的内容，也包括上一段描述PRD的内容，并且可能超过50页。</p><p>  FSD<br>　　功能详细说明（Functional Specifications Document）<br>  有一点像“概要设计”，这步就开始往开发衔接了，产品UI、业务逻辑的细节都要确定，细化文档并保持更新。相应的，有很多内容，比如表结构设计，要由项目经理来编写了。<br>　　功能规格文档（FSD）把焦点集中在实现，定义产品功能需求的全部细节。FSD可能通过一张张的截屏和一条条功能点来定义产品规格。这是一份可以直接让工程师创建产品的文档。<br>  与MRD和PRD侧重于以市场需要和产品角度看需求不同，FSD把重点放在了以表格形式定义产品细节，再让工程师实现这些细节。FSD也可能包括完整的屏幕截图和UI设计细节。<br>  FSD通常是由拥有产品分析师，工程领导或者项目经理头衔的人撰写的 – 作者通常属于工程部门。通常一个连续几十页的Word或类似文档。</p>]]></content>
      
      
      <categories>
          
          <category> 工作 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>12月1日</title>
      <link href="/2020/12/01/12%E6%9C%881%E6%97%A5/"/>
      <url>/2020/12/01/12%E6%9C%881%E6%97%A5/</url>
      
        <content type="html"><![CDATA[<h1 id="12月1日"><a href="#12月1日" class="headerlink" title="12月1日"></a>12月1日</h1><h2 id="笔记"><a href="#笔记" class="headerlink" title="笔记"></a>笔记</h2><h3 id="范数"><a href="#范数" class="headerlink" title="范数"></a>范数</h3><p>范数(norm)是数学中的一种基本概念。在泛函分析中，它定义在赋范线性空间中，并满足一定的条件，即①非负性；②齐次性；③三角不等式。它常常被用来度量某个向量空间（或矩阵）中的每个向量的长度或大小。</p><h3 id="Honey-Pot-Projects"><a href="#Honey-Pot-Projects" class="headerlink" title="Honey Pot Projects"></a>Honey Pot Projects</h3><p>垃圾邮件分类项目</p><h3 id="Porter-Stemmer"><a href="#Porter-Stemmer" class="headerlink" title="Porter Stemmer"></a>Porter Stemmer</h3><p>波特词干提取法</p><h3 id="apt与apt-get"><a href="#apt与apt-get" class="headerlink" title="apt与apt-get"></a>apt与apt-get</h3><p>Debian 作为 Ubuntu、Linux Mint 和 elementary OS 等 Linux 操作系统的母板，其具有强健的「包管理」系统，它的每个组件和应用程序都内置在系统中安装的软件包中。Debian 使用一套名为 <a href="https://wiki.debian.org/Apt">Advanced Packaging Tool</a>（APT）的工具来管理这种包系统，不过请不要把它与 apt 命令混淆，它们之间是其实不是同一个东西。</p><p>Debian 作为 Ubuntu、Linux Mint 和 elementary OS 等 Linux 操作系统的母板，其具有强健的「包管理」系统，它的每个组件和应用程序都内置在系统中安装的软件包中。Debian 使用一套名为 <a href="https://wiki.debian.org/Apt">Advanced Packaging Tool</a>（APT）的工具来管理这种包系统，不过请不要把它与 apt 命令混淆，它们之间是其实不是同一个东西。</p><p>如果你已阅读过我们的 apt-get 命令指南，可能已经遇到过许多类似的命令，如apt-cache、apt-config 等。如你所见，这些命令都比较低级又包含众多功能，普通的 Linux 用户也许永远都不会使用到。换种说法来说，就是最常用的 Linux 包管理命令都被分散在了 apt-get、apt-cache 和 apt-config 这三条命令当中。</p><p>apt 命令的引入就是为了解决命令过于分散的问题，它包括了 apt-get 命令出现以来使用最广泛的功能选项，以及 apt-cache 和 apt-config 命令中很少用到的功能。</p><p>在使用 apt 命令时，用户不必再由 apt-get 转到 apt-cache 或 apt-config，而且 apt 更加结构化，并为用户提供了管理软件包所需的必要选项。</p><blockquote><p>简单来说就是：apt &#x3D; apt-get、apt-cache 和 apt-config 中最常用命令选项的集合。</p></blockquote><p><strong>apt与apt-get之间的区别</strong></p><p>通过 apt 命令，用户可以在同一地方集中得到所有必要的工具，apt 的主要目的是提供一种以「让终端用户满意」的方式来处理 Linux 软件包的有效方式。</p><p>apt 具有更精减但足够的命令选项，而且参数选项的组织方式更为有效。除此之外，它默认启用的几个特性对最终用户也非常有帮助。例如，可以在使用 apt 命令安装或删除程序时看到进度条。</p><p>apt 还会在更新存储库数据库时提示用户可升级的软件包个数。</p><p>如果你使用 apt 的其它命令选项，也可以实现与使用 apt-get 时相同的操作。</p><p><strong>apt和apt-get命令之间的区别</strong></p><p>虽然 apt 与 apt-get 有一些类似的命令选项，但它并不能完全向下兼容 apt-get 命令。也就是说，可以用 apt 替换部分 apt-get 系列命令，但不是全部。</p><table><thead><tr><th>apt 命令</th><th>取代的命令</th><th>命令的功能</th></tr></thead><tbody><tr><td>apt install</td><td>apt-get install</td><td>安装软件包</td></tr><tr><td>apt remove</td><td>apt-get remove</td><td>移除软件包</td></tr><tr><td>apt purge</td><td>apt-get purge</td><td>移除软件包及配置文件</td></tr><tr><td>apt update</td><td>apt-get update</td><td>刷新存储库索引</td></tr><tr><td>apt upgrade</td><td>apt-get upgrade</td><td>升级所有可升级的软件包</td></tr><tr><td>apt autoremove</td><td>apt-get autoremove</td><td>自动删除不需要的包</td></tr><tr><td>apt full-upgrade</td><td>apt-get dist-upgrade</td><td>在升级软件包时自动处理依赖关系</td></tr><tr><td>apt search</td><td>apt-cache search</td><td>搜索应用程序</td></tr><tr><td>apt show</td><td>apt-cache show</td><td>显示安装细节</td></tr></tbody></table><p>当然，apt 还有一些自己的命令：</p><table><thead><tr><th>新的apt命令</th><th>命令的功能</th></tr></thead><tbody><tr><td>apt list</td><td>列出包含条件的包（已安装，可升级等）</td></tr><tr><td>apt edit-sources</td><td>编辑源列表</td></tr></tbody></table><p>需要大家注意的是：apt 命令也还在不断发展， 因此，你可能会在将来的版本中看到新的选项。</p><table><thead><tr><th>apt-get已弃用？</th></tr></thead><tbody><tr><td>目前还没有任何 Linux 发行版官方放出 apt-get 将被停用的消息，至少它还有比 apt 更多、更细化的操作功能。对于低级操作，仍然需要 apt-get。</td></tr></tbody></table><table><thead><tr><th>我应该使用apt还是apt-get？</th></tr></thead><tbody><tr><td>既然两个命令都有用，那么我该使用 apt 还是 apt-get 呢？作为一个常规 Linux 用户，系统极客建议大家尽快适应并开始首先使用 apt。不仅因为广大 Linux 发行商都在推荐 apt，更主要的还是它提供了 Linux 包管理的必要选项。</td></tr></tbody></table><p>最重要的是，apt 命令选项更少更易记，因此也更易用，所以没理由继续坚持 apt-get。</p><h3 id="Tomcat、Apache、Nginx"><a href="#Tomcat、Apache、Nginx" class="headerlink" title="Tomcat、Apache、Nginx"></a>Tomcat、Apache、Nginx</h3><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/1416817-20190718212645569-234672075.jpg" alt="img"></p><h4 id="一、-定义："><a href="#一、-定义：" class="headerlink" title="一、 定义："></a>一、 定义：</h4><h5 id="1-Apache"><a href="#1-Apache" class="headerlink" title="1. Apache"></a>1. Apache</h5><p>Apache HTTP服务器是一个模块化的服务器，可以运行在几乎所有广泛使用的计算机平台上。其属于应用服务器。Apache支持支持模块多，性能稳定，Apache本身是静态解析，适合静态HTML、图片等，但可以通过扩展脚本、模块等支持动态页面等。</p><p>（Apche可以支持PHPcgiperl,但是要使用Java的话，你需要Tomcat在Apache后台支撑，将Java请求由Apache转发给Tomcat处理。） 缺点：配置相对复杂，自身不支持动态页面。</p><h5 id="2-Tomcat："><a href="#2-Tomcat：" class="headerlink" title="2. Tomcat："></a>2. Tomcat：</h5><p>Tomcat是应用（Java）服务器，它只是一个Servlet(JSP也翻译成Servlet)容器，可以认为是Apache的扩展，但是可以独立于Apache运行。</p><h5 id="3-Nginx"><a href="#3-Nginx" class="headerlink" title="3. Nginx"></a>3. Nginx</h5><p>Nginx是俄罗斯人编写的十分轻量级的HTTP服务器,Nginx，它的发音为“engine X”，是一个高性能的HTTP和反向代理服务器，同时也是一个IMAP&#x2F;POP3&#x2F;SMTP 代理服务器。</p><h4 id="二、-区别"><a href="#二、-区别" class="headerlink" title="二、 区别"></a>二、 区别</h4><h5 id="1-Apache与Tomcat的比较"><a href="#1-Apache与Tomcat的比较" class="headerlink" title="1. Apache与Tomcat的比较"></a>1. Apache与Tomcat的比较</h5><p>相同点：</p><ul><li>两者都是Apache组织开发的 </li><li>两者都有HTTP服务的功能 </li><li>两者都是免费的</li></ul><p>不同点：</p><ul><li>Apache是专门用了提供HTTP服务的，以及相关配置的（例如虚拟主机、URL转发等等），而Tomcat是Apache组织在符合Java EE的JSP、Servlet标准下开发的一个JSP服务器.</li><li>Apache是一个Web服务器环境程序,启用他可以作为Web服务器使用,不过只支持静态网页如(ASP,PHP,CGI,JSP)等动态网页的就不行。如果要在Apache环境下运行JSP的话就需要一个解释器来执行JSP网页,而这个JSP解释器就是Tomcat。</li><li>Apache:侧重于HTTPServer ，Tomcat:侧重于Servlet引擎，如果以Standalone方式运行，功能上与Apache等效，支持JSP，但对静态网页不太理想；</li><li>Apache是Web服务器，Tomcat是应用（Java）服务器，它只是一个Servlet(JSP也翻译成Servlet)容器，可以认为是Apache的扩展，但是可以独立于Apache运行。</li></ul><p>实际使用中Apache与Tomcat常常是整合使用：</p><ul><li>如果客户端请求的是静态页面，则只需要Apache服务器响应请求。 </li><li>如果客户端请求动态页面，则是Tomcat服务器响应请求。 </li><li>因为JSP是服务器端解释代码的，这样整合就可以减少Tomcat的服务开销。</li></ul><p>可以理解Tomcat为Apache的一种扩展。</p><h5 id="2-Nginx与Apache比较"><a href="#2-Nginx与Apache比较" class="headerlink" title="2. Nginx与Apache比较"></a>2. Nginx与Apache比较</h5><ol><li>nginx相对于apache的优点</li></ol><ul><li>轻量级，同样起web 服务，比apache占用更少的内存及资源</li><li>抗并发，nginx 处理请求是异步非阻塞的，而apache 则是阻塞型的，在高并发下nginx 能保持低资源低消耗高性能</li><li>高度模块化的设计，编写模块相对简单 </li><li>提供负载均衡</li><li>社区活跃，各种高性能模块出品迅速</li></ul><ol start="2"><li>apache 相对于nginx 的优点</li></ol><ul><li>apache的 rewrite 比nginx 的强大 ；</li><li>支持动态页面；</li><li>支持的模块多，基本涵盖所有应用；</li><li>性能稳定，而nginx相对bug较多。</li></ul><ol start="3"><li>两者优缺点比较</li></ol><ul><li>Nginx 配置简洁, Apache 复杂 ；</li><li>Nginx 静态处理性能比 Apache 高 3倍以上 ；</li><li>Apache 对 PHP 支持比较简单，Nginx 需要配合其他后端用； </li><li>Apache 的组件比 Nginx 多 ；</li><li>apache是同步多进程模型，一个连接对应一个进程；nginx是异步的，多个连接（万级别）可以对应一个进程；</li><li>nginx处理静态文件好,耗费内存少；</li><li>动态请求由apache去做，nginx只适合静态和反向；</li><li>Nginx适合做前端服务器，负载性能很好；</li><li>Nginx本身就是一个反向代理服务器 ，且支持负载均衡</li></ul><h4 id="三、-总结"><a href="#三、-总结" class="headerlink" title="三、 总结"></a>三、 总结</h4><ul><li>Nginx优点：负载均衡、反向代理、处理静态文件优势。nginx处理静态请求的速度高于apache；</li><li>Apache优点：相对于Tomcat服务器来说处理静态文件是它的优势，速度快。Apache是静态解析，适合静态HTML、图片等。</li><li>Tomcat：动态解析容器，处理动态请求，是编译JSP\Servlet的容器，Nginx有动态分离机制，静态请求直接就可以通过Nginx处理，动态请求才转发请求到后台交由Tomcat进行处理。</li></ul><p>Apache在处理动态有优势，Nginx并发性比较好，CPU内存占用低，如果rewrite频繁，那还是Apache较适合。</p><p>真的日常工作中，一般的项目还是用nginx+tomcat来做会多一点。</p><h3 id="git-clone-–recursive"><a href="#git-clone-–recursive" class="headerlink" title="git clone –recursive"></a>git clone –recursive</h3><p>git clone –recursive 用于循环克隆git子项目</p><p>是为了解决如果Git仓库中含有子项目,<br>将子项目一起克隆下来的.</p><h4 id="submoudle"><a href="#submoudle" class="headerlink" title="submoudle"></a>submoudle</h4><p>某个工作中的项目需要包含并使用另一个项目(也许是第三方库，或者你独立开发的，用于多个父项目的库)。<br>现在问题来了：你想要把它们当做两个独立的项目，同时又想在一个项目中使用另一个。</p><p>Git 通过子模块来解决这个问题。<br>子模块允许你将一个 Git 仓库作为另一个 Git 仓库的子目录。<br>它能让你将另一个仓库克隆到自己的项目中，同时还保持提交的独立。</p><p>通过在 git submodule add 命令后面加上想要跟踪的项目的<br>相对或绝对 URL 来添加新的子模块。</p><p>默认情况下，子模块会将子项目放到一个与仓库同名的目录中.<br>如果你想要放到其他地方，那么可以在命令结尾添加一个不同的路径。</p><h2 id="英语"><a href="#英语" class="headerlink" title="英语"></a>英语</h2><p>forward propagation：前向传播</p><p>so far：到目前为止，迄今为止</p><p>sort of：有几分地；到某种程度；稍稍</p><p>consistent to：相一致</p><p>constrain to：约束到</p><p>refers to：指的是，引用，与</p><p>take from：v. 降低；减少</p><p>column major order：按列顺序；以列为主的顺序</p><p>wind up：结束；使紧张；卷起；（非正式）忽悠某人（wind sb up）；上紧(钟、表等的)发条</p><p>10 to the minus 4：10 ^ -4</p><p>reiterate：vt. 重申；反复地做</p><p>symmetric way： 对称现象</p><p>it serves little purpose：这没什么用</p><p>variance：方差</p><p>fixate on：执着于；专注于</p><p>stemming：词干分析</p><p>particularly tricky：是一件很棘手的事情</p><p>screening process：筛选工序；过虑程式</p><p>trade-off：n. 权衡；交换，交易；协定</p><p>As a reminder：作为一个提醒</p><p>flagging：adj. 下垂的；衰弱的 n. 石板路；铺砌石板</p><p>For a counter example：作为反例</p><p>what matters more… ：更重要的是…</p><p>euclidean length：欧几里得长度</p><p>Pythagoras theorem：毕达哥拉斯定理；勾股定理</p><p>orthogonal projection：正投影，正交投影；[数] 正射影，[测] 正射投影</p><p>line up：排列起；整队</p><p>pertain to：关于；从属于；适合</p><p>off the shelf：现成的，不用定制的</p><p>in terms of whether：关于是否</p><p>without further ado：没有再费周折；立即；干脆痛快</p><p>formalism：正式表达；n. 形式主义；形式体系</p>]]></content>
      
      
      <categories>
          
          <category> 随记 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>11月25日</title>
      <link href="/2020/11/25/11%E6%9C%8825%E6%97%A5/"/>
      <url>/2020/11/25/11%E6%9C%8825%E6%97%A5/</url>
      
        <content type="html"><![CDATA[<h1 id="11月25日"><a href="#11月25日" class="headerlink" title="11月25日"></a>11月25日</h1><h2 id="笔记"><a href="#笔记" class="headerlink" title="笔记"></a>笔记</h2><h3 id="贝叶斯定理"><a href="#贝叶斯定理" class="headerlink" title="贝叶斯定理"></a>贝叶斯定理</h3><h4 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h4><p>在现实世界中，我们每个人都需要预测。想要深入分析未来、思考是否买股票、政策给自己带来哪些机遇、提出新产品构想，或者只是计划一周的饭菜。</p><p>贝叶斯定理就是为了解决这些问题而诞生的，它可以根据过去的数据来预测出未来事情发生概率。</p><p>贝叶斯定理的思考方式为我们提供了有效的方法来帮助我们做决策，以便更好地预测未来的商业、金融、以及日常生活。</p><h4 id="公式"><a href="#公式" class="headerlink" title="公式"></a>公式</h4><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/640" alt="img"></p><h4 id="应用案例"><a href="#应用案例" class="headerlink" title="应用案例"></a>应用案例</h4><ol><li>全概率公式</li></ol><p>这个公式的作用是计算贝叶斯定理中的P(B)。</p><p>全概率公式：</p><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/640" alt="img"></p><ol start="2"><li>贝叶斯定理在做判断上的应用</li><li>贝叶斯定理在医疗行业的应用</li><li>贝叶斯垃圾邮件过滤器</li></ol><h3 id="LiDAR"><a href="#LiDAR" class="headerlink" title="LiDAR"></a>LiDAR</h3><p>LiDAR (Light Detection and Ranging) is a method used to generate accurate 3D representations of the surroundings, and it uses laser light to achieve this. Basically, the 3D target is illuminated with a laser light (a focused, directed beam of light) and the reflected light is collected by sensors. The time required for the light to reflect back to the sensor is calculated.</p><p><strong>Different sensors collect light from different parts of the object, and the times recorded by the sensors would be different. This difference in time calculated by the sensors can be used to calculate the depth of the object. This depth information combined with the 2D represenation of the image provides an accurate 3D representation of the object. This process is similar to actual human vision. Two eyes make observations in 2D and these two pieces of information are combined to form a 3D map (depth perception). This is how humans sense the world around us</strong>.</p><p>This technology is used to create 3D representations in many real world scenarios. For example, it is used in farms to help sow seeds and remove weeds. A moving robot uses LiDAR to to create a 3D map of its surroundings and using this map, it avoids obstacles and completes its tasks. This technology is also used in archaeology. LiDAR is used to create 3D renderings of 2D scans of artifacts. This gives an accurate idea of the 3D shape of the artifact when the artifact cannot be excavated for whatever reason. Finally, LiDAR can also be used to render high quality 3D maps of ocean floors and other inaccesible terrains, making it very useful to geologists and oceanographers. Below is a 3D map of an ocean floor generated using LiDAR:</p><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/yG3CewG.jpg" alt="img"></p><h3 id="Flash-LiDAR-Camera"><a href="#Flash-LiDAR-Camera" class="headerlink" title="Flash LiDAR Camera"></a>Flash LiDAR Camera</h3><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/C3zUR7X.jpg" alt="img"></p><h3 id="RPN"><a href="#RPN" class="headerlink" title="RPN"></a>RPN</h3><h3 id="Sensor-representations-in-the-brain"><a href="#Sensor-representations-in-the-brain" class="headerlink" title="Sensor representations in the brain"></a>Sensor representations in the brain</h3><ol><li>Seeing with your tongue</li></ol><p>用舌头神经去学习看东西 a system called BrainPort undergoing FDA trials</p><ol start="2"><li>Human echolocation(sonar)</li></ol><p>learn to interpret the pattern of sounds bouncing off your environment - that’s sonar</p><ol start="3"><li>Haptic belt: Direction sense</li></ol><p> if you have a strap around your waist, ring up buzzers and always have the northmost one buzzing</p><ol start="3"><li>implanting a 3rd eye</li></ol><p>some of the bizarre example, but </p><p>if you plug a third eye into a frog, the frog will learn to use that eye as well.</p><h3 id="结构体与共用体内存"><a href="#结构体与共用体内存" class="headerlink" title="结构体与共用体内存"></a>结构体与共用体内存</h3><p>结构体占用的内存大于等于所有成员占用的内存的总和（成员之间可能会存在缝隙），共用体占用的内存等于最长的成员占用的内存。共用体使用了内存覆盖技术，同一时刻只能保存一个成员的值，如果对新的成员赋值，就会把原来成员的值覆盖掉。</p><h2 id="英语"><a href="#英语" class="headerlink" title="英语"></a>英语</h2><p>defer to：尊重；听从</p><p>representation：表达式</p><p>1 over m： 1&#x2F;m</p><p>superimpose：添加；重叠；附加；安装</p><p>nested list structure: 嵌套列表</p><p>address the issue: 解决问题</p><p>have fall out of：跌落</p><p>fabrication plant: 加工厂；加工设备</p><p>susceptible to: 易受…影响的；对…敏感的</p><p>w.r.t. ： with respect to 的缩写。是 关于；谈及，谈到的意思。<br>i.e. ：也就是，亦即（源自拉丁文id est），换而言之。</p>]]></content>
      
      
      <categories>
          
          <category> 随记 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Python</title>
      <link href="/2020/11/23/Python/"/>
      <url>/2020/11/23/Python/</url>
      
        <content type="html"><![CDATA[<h1 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h1><h2 id="常用库"><a href="#常用库" class="headerlink" title="常用库"></a>常用库</h2><h3 id="Seaborn"><a href="#Seaborn" class="headerlink" title="Seaborn"></a>Seaborn</h3><p>Seaborn是基于matplotlib的图形可视化python包。它提供了一种高度交互式界面，便于用户能够做出各种有吸引力的统计图表。</p><p>Seaborn是在matplotlib的基础上进行了更高级的API封装，从而使得作图更加容易，在大多数情况下使用seaborn能做出很具有吸引力的图，而使用matplotlib就能制作具有更多特色的图。应该把Seaborn视为matplotlib的补充，而不是替代物。同时它能高度兼容numpy与pandas数据结构以及scipy与statsmodels等统计模式。</p><h3 id="print-f’-’"><a href="#print-f’-’" class="headerlink" title="print(f’***’)"></a>print(f’***’)</h3><p>python的print字符串前面加f表示格式化字符串，加f后可以在字符串里面使用用花括号括起来的变量和表达式，如果字符串里面没有表达式，那么前面加不加f输出应该都一样.</p><h3 id="loc和iloc函数"><a href="#loc和iloc函数" class="headerlink" title="loc和iloc函数"></a>loc和iloc函数</h3><h3 id="ipython"><a href="#ipython" class="headerlink" title="ipython"></a><strong>ipython</strong></h3>]]></content>
      
      
      <categories>
          
          <category> 开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>11月16日</title>
      <link href="/2020/11/16/11%E6%9C%8816%E6%97%A5/"/>
      <url>/2020/11/16/11%E6%9C%8816%E6%97%A5/</url>
      
        <content type="html"><![CDATA[<h1 id="11月16日"><a href="#11月16日" class="headerlink" title="11月16日"></a>11月16日</h1><h2 id="笔记"><a href="#笔记" class="headerlink" title="笔记"></a>笔记</h2><h3 id="EDA"><a href="#EDA" class="headerlink" title="EDA"></a>EDA</h3><p>探索性数据分析（Exploratory Data Analysis，简称EDA），摘抄网上的一个中文解释，是指对已有的数据（特别是调查或观察得来的原始数据）在尽量少的先验假定下进行探索，通过作图、制表、方程拟合、计算特征量等手段探索数据的结构和规律的一种数据分析方法。特别是党我们对面对大数据时代到来的时候，各种杂乱的“脏数据”，往往不知所措，不知道从哪里开始了解目前拿到手上的数据时候，探索性数据分析就非常有效。探索性数据分析是上世纪六十年代提出，其方法有美国统计学家John Tukey提出的。</p><h3 id="Pearson-correlation-coefficient"><a href="#Pearson-correlation-coefficient" class="headerlink" title="Pearson correlation coefficient"></a>Pearson correlation coefficient</h3><p>在统计学中，<strong>皮尔逊相关系数</strong>( Pearson correlation coefficient），又称<strong>皮尔逊积矩相关系数</strong>（Pearson product-moment correlation coefficient，简称 <strong>PPMCC</strong>或<strong>PCCs</strong>），是用于度量两个变量X和Y之间的相关（线性相关），其值介于-1与1之间。</p><h3 id="Jupyter中的感叹号与问好"><a href="#Jupyter中的感叹号与问好" class="headerlink" title="Jupyter中的感叹号与问好"></a>Jupyter中的感叹号与问好</h3><p>感叹号！用于执行来自操作系统的命令；</p><p>问题？标记用于提供笔记本内帮助：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"> df.fillna？ </span><br><span class="line">＃结果：</span><br><span class="line"> </span><br><span class="line">签名：df.fillna（value = <span class="literal">None</span>，method = <span class="literal">None</span>，axis = <span class="literal">None</span>，inplace = <span class="literal">False</span>，limit = <span class="literal">None</span>，downcast = <span class="literal">None</span>，** kwargs）</span><br><span class="line">文档字符串：</span><br><span class="line">使用指定方法填充NA / NaN值</span><br></pre></td></tr></table></figure><h3 id="SLAM"><a href="#SLAM" class="headerlink" title="SLAM"></a>SLAM</h3><p>提角点</p><p>RGBD点云</p><h3 id="光栅化"><a href="#光栅化" class="headerlink" title="光栅化"></a>光栅化</h3><p>光栅化是将几何数据经过一系列变换后最终转换为像素，从而呈现在显示设备上的过程，如下图：<img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/20130819125657765" alt="img"></p><p>光栅化的本质是坐标变换、几何离散化，如下图:</p><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/20130819125727703" alt="img"></p><h2 id="英语"><a href="#英语" class="headerlink" title="英语"></a>英语</h2><p>bowl-shaped: 碗型</p><p>step through：单步调试；逐句通过</p><p>tabular data：列表数据</p><p>left out：忽视，不考虑；被遗忘</p>]]></content>
      
      
      <categories>
          
          <category> 随记 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>11月9日</title>
      <link href="/2020/11/09/11%E6%9C%889%E6%97%A5/"/>
      <url>/2020/11/09/11%E6%9C%889%E6%97%A5/</url>
      
        <content type="html"><![CDATA[<h1 id="11月9日"><a href="#11月9日" class="headerlink" title="11月9日"></a>11月9日</h1><h2 id="笔记"><a href="#笔记" class="headerlink" title="笔记"></a>笔记</h2><h3 id="Lua"><a href="#Lua" class="headerlink" title="Lua"></a>Lua</h3><p>Lua 是一种轻量小巧的脚本语言，用标准C语言编写并以源代码形式开放， 其设计目的是为了嵌入应用程序中，从而为应用程序提供灵活的扩展和定制功能。</p><blockquote><p><strong>设计目的：</strong></p><p>其设计目的是为了嵌入应用程序中，从而为应用程序提供灵活的扩展和定制功能。</p><p><strong>应用场景：</strong></p><ul><li>游戏开发</li><li>独立应用脚本</li><li>Web 应用脚本</li><li>扩展和数据库插件如：MySQL Proxy 和 MySQL WorkBench</li><li>安全系统，如入侵检测系统</li></ul></blockquote><h3 id="Rust"><a href="#Rust" class="headerlink" title="Rust"></a>Rust</h3><p>Rust是一门系统编程语言 ，专注于安全，尤其是并发安全，支持函数式和命令式以及泛型等编程范式的多范式语言。Rust在语法上和C++类似，但是设计者想要在保证性能的同时提供更好的内存安全。 Rust最初是由Mozilla研究院的Graydon Hoare设计创造，然后在Dave Herman, Brendan Eich以及很多其他人的贡献下逐步完善的。Rust的设计者们通过在研发Servo网站浏览器布局引擎过程中积累的经验优化了Rust语言和Rust编译器。</p><p>Rust编译器是在MIT License 和 Apache License 2.0双重协议声明下的免费开源软件。 Rust已经连续四年（2016，2017，2018，2019）在Stack Overflow开发者调查的“最受喜爱编程语言”评选项目中折取桂冠。</p><blockquote><p><strong>设计特色:</strong></p><p>Rust致力于成为优雅解决高并发和高安全性系统问题的编程语言 ，适用于大型场景，即创造维护能够保持大型系统完整的边界。这就导致了它强调安全，内存布局控制和并发的特点。</p></blockquote><h3 id="MinGW"><a href="#MinGW" class="headerlink" title="MinGW"></a>MinGW</h3><p>MinGW是Windows的GCC端口.并非所有的Windows API都受支持(但是对于许多程序来说,支持的东西已经足够了)并且它仅适用于32位程序(通常也可以在64位Windows上运行,但有些不能,但是你不能将它们编译为64位).</p><p>MinGW-w64是一个改进版本,支持32位和64位,以及更多的WinAPI(仍然不是全部,因为它有很多工作,但比MinGW更多).</p><p>MinGW-w64只提供它们的源代码,但没有”只使用”编译器的二进制文件.</p><p>MinGW-builds是一个有点独立的项目,可以在最有用的配置中提供二进制文件.要获得专门构建的MinGW-w64,仍然可以进行手动编译.</p><h3 id="CMake"><a href="#CMake" class="headerlink" title="CMake"></a>CMake</h3><p>CMake是一个跨平台的安装（编译]）工具，可以用简单的语句来描述所有平台的安装(编译过程)。他能够输出各种各样的makefile或者project文件，能测试编译器所支持的C++特性,类似UNIX下的automake。只是 CMake 的组态档取名为 CMakeLists.txt。Cmake 并不直接建构出最终的软件，而是产生标准的建构档（如 Unix 的 Makefile 或 Windows Visual C++ 的 projects&#x2F;workspaces），然后再依一般的建构方式使用。这使得熟悉某个集成开发环境（IDE）的开发者可以用标准的方式建构他的软件，这种可以使用各平台的原生建构系统的能力是 CMake 和 SCons 等其他类似系统的区别之处。</p><p>CMake 可以编译源代码、制作程序库、产生适配器（wrapper）、还可以用任意的顺序建构执行档。CMake 支持 in-place 建构（二进档和源代码在同一个目录树中）和 out-of-place 建构（二进档在别的目录里），因此可以很容易从同一个源代码目录树中建构出多个二进档。CMake 也支持静态与动态程式库的建构。</p><p>“CMake”这个名字是“cross platform make”的缩写。虽然名字中含有“make”，<em><strong>但是CMake和Unix上常见的“make”系统是分开的，而且更为高阶。</strong></em></p><h3 id="MinIO-Client"><a href="#MinIO-Client" class="headerlink" title="MinIO Client"></a>MinIO Client</h3><p>MinIO Client (mc)为ls，cat，cp，mirror，diff，find等UNIX命令提供了一种替代方案。它支持文件系统和兼容Amazon S3的云存储服务（AWS Signature v2和v4）。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ls       列出文件和文件夹。</span><br><span class="line">mb       创建一个存储桶或一个文件夹。</span><br><span class="line">cat      显示文件和对象内容。</span><br><span class="line">pipe     将一个STDIN重定向到一个对象或者文件或者STDOUT。</span><br><span class="line">share    生成用于共享的URL。</span><br><span class="line">cp       拷贝文件和对象。</span><br><span class="line">mirror   给存储桶和文件夹做镜像。</span><br><span class="line">find     基于参数查找文件。</span><br><span class="line">diff     对两个文件夹或者存储桶比较差异。</span><br><span class="line">rm       删除文件和对象。</span><br><span class="line">events   管理对象通知。</span><br><span class="line">watch    监视文件和对象的事件。</span><br><span class="line">policy   管理访问策略。</span><br><span class="line">config   管理mc配置文件。</span><br><span class="line">update   检查软件更新。</span><br><span class="line">version  输出版本信息。</span><br></pre></td></tr></table></figure><h3 id="POSIX"><a href="#POSIX" class="headerlink" title="POSIX"></a>POSIX</h3><p><strong>可移植操作系统接口</strong>（英语：Portable Operating System Interface，缩写为<strong>POSIX</strong>）是IEEE为要在各种UNIX操作系统上运行软件，而定义API的一系列互相关联的标准的总称，其正式称呼为IEEE Std 1003，而国际标准名称为ISO&#x2F;[IEC 9945。此标准源于一个大约开始于1985年的项目。POSIX这个名称是由理查德·斯托曼（RMS）应IEEE的要求而提议的一个易于记忆的名称。它基本上是Portable Operating System Interface（可移植操作系统接口）的缩写，而<strong>X</strong>则表明其对Unix API的传承。</p><h3 id="斜杠与反斜杠"><a href="#斜杠与反斜杠" class="headerlink" title="斜杠与反斜杠"></a>斜杠与反斜杠</h3><p>Unix使用斜杆&#x2F; 作为路径分隔符，而web应用最新使用在Unix系统上面，所以目前所有的网络地址都采用 斜杆&#x2F; 作为分隔符。</p><p>Windows由于使用 斜杆&#x2F; 作为DOS命令提示符的参数标志了，为了不混淆，所以采用 反斜杠\ 作为路径分隔符。所以目前windows系统上的文件浏览器都是用 反斜杠\ 作为路径分隔符。<strong>随着发展，DOS系统已经被淘汰了，命令提示符也用的很少，斜杆和反斜杠在大多数情况下可以互换，没有影响。</strong></p><ol><li><p>浏览器地址栏网址使用 斜杆&#x2F; ;</p></li><li><p><strong>windows文件浏览器上使用 反斜杠\ ;</strong></p></li><li><p>出现在html url() 属性中的路径，指定的路径是网络路径，所以必须用 斜杆&#x2F; ;</p></li><li><p><strong>出现在普通字符串中的路径，如果代表的是windows文件路径，则使用 斜杆&#x2F; 和 反斜杠\ 是一样的；如果代表的是网络文件路径，则必须使用 斜杆&#x2F; ;</strong></p></li></ol><blockquote><p>在使用部分语言编程时（C++ &#x2F; JAva），由于转义字符 ‘\’ 的存在，上传或读取文件的路径的编写有两种方式，使用双反斜杠 ‘\‘, 或者正斜杠  ‘&#x2F;‘</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// e.g.</span><br><span class="line">D:\\boke\\test\\1.txt</span><br><span class="line">D:/boke/test/1.txt</span><br></pre></td></tr></table></figure></blockquote><h3 id="EDA"><a href="#EDA" class="headerlink" title="EDA"></a>EDA</h3><p>数据分析基线</p><h3 id="硬编码"><a href="#硬编码" class="headerlink" title="硬编码"></a>硬编码</h3><p>硬编码是将数据直接嵌入到程序或其他可执行对象的源代码中的软件开发实践，与从外部获取数据或在运行时生成数据不同。 硬编码数据通常只能通过编辑源代码和重新编译可执行文件来修改，尽管可以使用调试器或十六进制编辑器在内存或磁盘上进行更改。 硬编码的数据通常表示不变的信息，例如物理常量，版本号和静态文本元素。 另一方面，软编码数据对用户输入，HTTP服务器响应或配置文件等任意信息进行编码，并在运行时确定。</p><h3 id="UTC"><a href="#UTC" class="headerlink" title="UTC"></a>UTC</h3><p>协调世界时，又称世界统一时间、世界标准时间、国际协调时间。由于英文（CUT）和法文（TUC）的缩写不同，作为妥协，简称UTC。</p><p>协调世界时是以原子时秒长为基础，在时刻上尽量接近于世界时的一种时间计量系统。中国大陆采用ISO 8601-1988的《数据元和交换格式信息交换日期和时间表示法》（GB&#x2F;T 7408-1994）称之为国际协调时间，代替原来的GB&#x2F;T 7408-1994；中国台湾采用CNS 7648的《资料元及交换格式–资讯交换–日期及时间的表示法》，称之为世界统一时间。</p><h2 id="英语"><a href="#英语" class="headerlink" title="英语"></a>英语</h2><p>sourceforge：一套合作式软件开发管理系统</p><p>square root function：平方根</p><p>flattens out：变得平缓</p><p>lean in the direction of：向…的方向倾斜</p><p>warm up exercise: 热身运动</p><p>identity matrix: 单位矩阵</p><p>get around to：抽出时间来做……；开始考虑做……</p><p>Prof.   ： 教授</p><p>a copy of: 一份</p><p>greater than：&gt;</p><p>greater than colon: &gt;&#x3D;</p><p>uniform distribution： 均匀分布</p><p>Gaussian random variable：高斯随机变量</p><p>adjunct faculty：兼职教师；客座讲师；特约教授</p><p>element-wise: （矩阵对应元素逐个相运算, 点乘方式？）</p><p>exponentiation of: 求幂</p><p>neat trick：巧妙的花招</p><p>apostrophe symbol：撇号</p><p>quotation mark：引号</p><p>magic squares：幻方</p>]]></content>
      
      
      <categories>
          
          <category> 随记 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>11月3日</title>
      <link href="/2020/11/03/11%E6%9C%883%E6%97%A5/"/>
      <url>/2020/11/03/11%E6%9C%883%E6%97%A5/</url>
      
        <content type="html"><![CDATA[<h1 id="11月3日"><a href="#11月3日" class="headerlink" title="11月3日"></a>11月3日</h1><h2 id="笔记"><a href="#笔记" class="headerlink" title="笔记"></a>笔记</h2><h3 id="SEO（Search-Engine-Optimization）"><a href="#SEO（Search-Engine-Optimization）" class="headerlink" title="SEO（Search Engine Optimization）"></a>SEO（Search Engine Optimization）</h3><p>汉译为搜索引擎优化。是一种方式：利用搜索引擎的规则提高网站在有关搜索引擎内的自然排名。目的是让其在行业内占据领先地位，获得品牌收益。很大程度上是网站经营者的一种商业行为，将自己或自己公司的排名前移。</p><blockquote><p>搜索引擎优化的技术手段主要有黑帽（black hat）、白帽（white hat）两大类。通过作弊手法欺骗搜索引擎和访问者，最终将遭到搜索引擎惩罚的手段被称为黑帽，比如隐藏关键字、制造大量的meta字、alt标签等。而通过正规技术和方式，且被搜索引擎所接受的SEO技术，称为白帽。</p><ol><li>白帽方法</li></ol><p>  搜索引擎优化的白帽法遵循搜索引擎的接受原则。他们的建议一般是为用户创造内容、让这些内容易于被搜索引擎机器人索引、并且不会对搜寻引擎系统耍花招。一些网站的员工在设计或构建他们的网站时出现失误以致该网站排名靠后时，白帽法可以发现并纠正错误，譬如机器无法读取的选单、无效链接、临时改变导向、效率低下的索引结构等。</p><ol start="2"><li>黑帽方法</li></ol><p>  黑帽方法通过欺骗技术和滥用搜索算法来推销毫不相关、主要以商业为着眼的网页。黑帽SEO的主要目的是让网站得到他们所希望的排名进而获得更多的曝光率，这可能导致令普通用户不满的搜索结果。因此搜索引擎一旦发现使用“黑帽”技术的网站，轻则降低其排名，重则从搜索结果中永远剔除该网站。选择黑帽SEO服务的商家，一部分是因为不懂技术，在没有明白SEO价值所在的情况下被服务商欺骗；另一部分则只注重短期利益，存在赚一笔就走人的心态。</p></blockquote><h3 id="PWA"><a href="#PWA" class="headerlink" title="PWA"></a>PWA</h3><p>PWA（Progressive Web App）是一种理念，使用多种技术来增强web app的功能，可以让网站的体验变得更好，能够模拟一些原生功能，比如通知推送。在移动端利用标准化框架，让网页应用呈现和原生应用相似的体验。</p><blockquote><p><strong>技术特点：</strong>PWA不能包含原生OS相关代码。PWA仍然是网站，只是在缓存、通知、后台功能等方面表现更好。Electron程序相当于包裹OS原生启动器（Launcher）的网站，未来，许多Electron程序可能转化为PWA。</p></blockquote><h3 id="CLI"><a href="#CLI" class="headerlink" title="CLI"></a>CLI</h3><p><strong>命令行界面</strong>（英语：<strong>command-line interface</strong>，缩写：<strong>CLI</strong>）是在图形用户界面得到普及之前使用最为广泛的用户界面，它通常不支持鼠标，用户通过键盘输入指令，计算机接收到指令后，予以执行。也有人称之为<strong>字符用户界面</strong>（CUI）。</p><p>通常认为，命令行界面（CLI）没有图形用户界面（GUI）那么方便用户操作。因为，命令行界面的软件通常需要用户记忆操作的命令，但是，由于其本身的特点，命令行界面要较图形用户界面节约计算机系统的资源。在熟记命令的前提下，使用命令行界面往往要较使用图形用户界面的操作速度要快。所以，图形用户界面的操作系统中，都保留着可选的命令行界面。</p><h3 id="VI"><a href="#VI" class="headerlink" title="VI"></a>VI</h3><p>VI即（Visual Identity），通译为视觉识别，是CIS系统中最具传播力和感染力的层面。人们所感知的外部信息，有83%是通过视觉通道到达人们心智的。</p><p>也就是说，视觉是人们接受外部信息的最重要和最主要的通道。企业形象的视觉识别，即是将CI的非可视内容转化为静态的视觉识别符号，以无比丰富的多样的应用形式，在最为广泛的层面上，进行最直接的传播。设计科学、实施有利的视觉识别，是传播企业经营理念、建立企业知名度、塑造企业形象的快速便捷之途。</p><blockquote><ul><li>基本元素<ul><li>企业名称</li><li>企业标志</li><li>标准字</li><li>吉祥物</li><li>标准色彩</li><li>象征图案</li><li>标语口号</li></ul></li></ul></blockquote><h3 id="CIS"><a href="#CIS" class="headerlink" title="CIS"></a>CIS</h3><p>CIS（corporate identity system缩写）的俗称，上世纪80年代作为一套“品牌管理体系“引入国内，是当今企业管理对内对外文化、形象的基础理论，是狭义的“品牌”理论的实有构成部分，亦是一种拥有对内对外两面性的“标准”或“规则”，通过对理念、行为、视觉三方面进行标准化、规则化，使之具备特有性、价值性、长期性、认知性的一种识别系统的总称，可译为”企业统一化系统”、”企业自我同一化系统”、”企业识别体系”。</p><p>CIS理论把企业形象作为一个整体进行建设和发展。主要由三部分构成：1：企业的理念识别(mind identity，简称mi)；2：企业行为识别(behavior identity，简称bi)；3：企业视觉识别(visual identity, 简称vi)。mi是抽象思考的精神理念，难以具体显现其中内涵，表达其精神特质。bi是行为活动的动态形式。vi用视觉形象来进行个性识别。</p><h3 id="鱼骨图（因果图）"><a href="#鱼骨图（因果图）" class="headerlink" title="鱼骨图（因果图）"></a>鱼骨图（因果图）</h3><p>鱼骨图（又名因果图、石川图），指的是一种发现问题“根本原因”的分析方法，现代工商管理教育将其划分为问题型、原因型及对策型鱼骨图等几类。</p><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/d043ad4bd11373f0aec6ec0ca80f4bfbfaed04a3" alt="img"></p><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/8ad4b31c8701a18bcf17e5d6942f07082938feaf" alt="img"></p><h3 id="帕累托图"><a href="#帕累托图" class="headerlink" title="帕累托图"></a>帕累托图</h3><p>帕累托图（Pareto chart）是将出现的质量问题和质量改进项目按照重要程度依次排列而采用的一种图表。以意大利经济学家V.Pareto的名字而命名的。帕累托图又叫排列图、主次图，是按照发生频率大小顺序绘制的直方图，表示有多少结果是由已确认类型或范畴的原因所造成。</p><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/d009b3de9c82d15813dfd3298a0a19d8bd3e42cd" alt="img"></p><h3 id="AOAPC"><a href="#AOAPC" class="headerlink" title="AOAPC"></a>AOAPC</h3><p>全名&lt;<Art of Algorithms and Programming Contests>&gt;</p><h3 id="常见的开源协议"><a href="#常见的开源协议" class="headerlink" title="常见的开源协议"></a>常见的开源协议</h3><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/20180905230050673" alt="img"></p><h2 id="英语"><a href="#英语" class="headerlink" title="英语"></a>英语</h2><p>in this thread：在这篇贴子里</p><p>built-in：adj. 嵌入的；固定的  n. 内置</p><p>feel free：随意</p><p>sort of：稍稍；到某种程度；有几分地</p><p>over there：adv. 在那里</p><p>all the way up to：一直到</p><p>inner products：内积（即点积）；数量积</p><p>compact form：紧凑结构；紧密结合形式</p><p>element-wise：元素方式</p><p>Connectivity Map：连通图</p>]]></content>
      
      
      <categories>
          
          <category> 随记 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>强化学习论文阅读（一）</title>
      <link href="/2020/10/28/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB(%E4%B8%80)/"/>
      <url>/2020/10/28/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB(%E4%B8%80)/</url>
      
        <content type="html"><![CDATA[<h1 id="强化学习论文阅读（一）"><a href="#强化学习论文阅读（一）" class="headerlink" title="强化学习论文阅读（一）"></a>强化学习论文阅读（一）</h1><h1 id="GNN-RL"><a href="#GNN-RL" class="headerlink" title="GNN + RL"></a>GNN + RL</h1><h3 id="Deep-Reinforcement-Learning-meets-Graph-Neural-Networks-An-optical-network-routing-use-case"><a href="#Deep-Reinforcement-Learning-meets-Graph-Neural-Networks-An-optical-network-routing-use-case" class="headerlink" title="Deep Reinforcement Learning meets Graph Neural Networks: An optical network routing use case"></a>Deep Reinforcement Learning meets Graph Neural Networks: An optical network routing use case</h3><h4 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h4><p>​最近在深度强化学习(DRL)方面的进展显示了决策问题的显著改善。网络社区已经开始研究DRL如何为诸如路由之类的网络优化问题提供一种新的解决方案。然而，大多数最先进的基于DRL的网络技术不能推广，这意味着它们只能在训练期间看到的网络拓扑上运行，而不能在新的拓扑上运行。这一重要限制背后的原因是，<strong>现有的DRL网络解决方案使用标准的神经网络(例如，完全连接)，不能学习图形结构的信息。本文提出将图神经网络(GNN)与DRL相结合。</strong>GNN最近被提出用于图形建模，<strong>我们的新型DRL+GNN体系结构能够学习、操作和推广到任意网络拓扑。</strong>为了展示它的泛化能力，我们在光传输网络(OTN)场景中评估它，其中代理需要有效地分配流量需求。我们的结果表明，我们的DRL+GNN代理能够在训练期间未见的拓扑中取得优异的性能。</p><blockquote><p>**Optical Transport Network(OTN)**：光传送网(OTN)是以<a href="https://www.maixj.net/ict/wdm-5266">光的波分复用(WDM)技术</a>为基础、在光层组织网络的传送网。由于在网络上传送的IP业务和其他基于包传送数据业务的爆炸式的增长，对传输容量的要求在不断迅猛增加，密集波分复用(DWDM)技术和光放大器(OA)技术的成熟和应用使传送网正在向以光联网技术为基础的光传送网发展。</p></blockquote><h4 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h4><p>现有的基于DRL的解决方案在应用于与网络相关的场景时仍然不能泛化。这妨碍了DRL代理在面对培训期间未见过的网络状态时做出正确决策的能力。</p><p>这种强大的限制背后的主要原因是计算机网络基本上是用图形表示的。</p><p>近年来，图神经网络(GNN)被提出用于对图进行建模和操作，以实现关系推理和组合推广。换句话说，GNN有助于学习图中实体之间的关系以及组成它们的规则。</p><p>具体来说，DRL代理使用的GNN是受到消息传递神经网络[1]的启发。利用这个框架，我们设计了一个能够捕获网络拓扑上路径和链接之间关系的GNN</p><blockquote><p><strong>Message-passing Neural Networks</strong>: [1]Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals, and George E Dahl. 2017. Neural message passing for quantum chemistry. In <em>Proceedings of the 34th International Conference on Machine Learning-</em> <em>Volume 70</em>. JMLR. org, 1263–1272.</p><p><strong>Bellman equation</strong>：</p></blockquote><h4 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h4><p>本文提出的解决方案结合了两种机器学习机制。首先，我们使用图神经网络(GNN)来建模计算机网络。其次，我们使用深度强化学习(DRL)来构建代理，学习如何有效地按照特定的优化目标运行网络。</p><blockquote><p>Message Passing Neural Networks (MPNN) are a well- known type of GNNs that use an iterative message-passing algorithm to propagate information between the nodes of the graph.</p><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/image-20201028151452253.png" alt="image-20201028151452253"></p><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/image-20201028151537097.png" alt="image-20201028151537097"></p></blockquote><blockquote><p>Markov Decision Process (MDP) 马尔可夫模型</p><p>Optical Add-Drop Multiplexer (ROADM) 光分插多路复用器</p><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/image-20201028160631785.png" alt="image-20201028160631785"></p><p>DQN algorithm: </p><p>[1]  Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioan- nis Antonoglou, Daan Wierstra, and Martin Riedmiller. 2013. Playing atari with deep reinforcement learning. <em>arXiv preprint arXiv:1312.5602</em> (2013).</p></blockquote><h4 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h4><p>Our agent implements the DQN algorithm [<a href="#_bookmark21">14</a>], where the q-value function is modelled by a GNN.</p><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/image-20201029161424259.png" alt="image-20201029161424259"></p><h4 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h4><p>To simulate the environment, we implemented the <em>env.step()</em> and <em>env.reset_env()</em> functions in the Gym framework [<a href="#_bookmark10">4</a>].</p><blockquote><p>[1] Greg Brockman, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John Schulman, Jie Tang, and Wojciech Zaremba. 2016. OpenAI Gym. arXiv:arXiv:1606.01540</p><p>hyperparameter: 超参数</p></blockquote><p>The optimizer used is a Stochastic Gradi- ent Descent [<a href="#_bookmark11">3</a>] method with Nesterov Momentum [<a href="#_bookmark30">23</a>].</p><p> “Shortest Available Path” (SAP) policy</p><p>RAND policy</p><p> load balancing policy：负载均衡策略</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>利用GNN作为DRL的输入完成对DRL在拓扑结构上的泛化应用</p><h3 id="Graph-Convolutional-Policy-for-Solving-Tree-Decomposition-via-Reinforcement-Learning-Heuristics"><a href="#Graph-Convolutional-Policy-for-Solving-Tree-Decomposition-via-Reinforcement-Learning-Heuristics" class="headerlink" title="Graph Convolutional Policy for Solving Tree Decomposition via Reinforcement Learning Heuristics"></a>Graph Convolutional Policy for Solving Tree Decomposition via Reinforcement Learning Heuristics</h3><p>树分解(TD)是分析复杂性和图的拓扑结构的中心。</p><blockquote><p>Independent Set, Clique, Satisfiability, Graph Coloring, Travelling Salesman Problem (TSP)</p><p>The Tree Decomposition (TD)</p></blockquote><p>提出了一种学习树分解问题启发式的方法，该方法比简单的多项式求解器更精确和更短的解决时间。</p><p>我们利用图卷积网络(Kipf和Welling, 2016)对嵌入方法进行了说明。最后，我们在强化学习框架中阐述了问题。</p><p>通俗地说，树分解度量给定图对树的重复程度</p><blockquote><p>S2V-DQN</p><p>QuickBB by <a href="#_bookmark11">(Gogate and Dechter,</a> <a href="#_bookmark11">2012),</a></p><p>Euclidean TSP</p></blockquote><h4 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h4><p>我们提出一个模型，可以直接学习如何解决这个组合优化问题使用单一的图训练。训练过程也可以使用大量的图来执行，但是这个工作的目的是展示一个简单的agent在单个图上训练的泛化能力。研究的视角是基于强化学习的启发式和局部搜索方法的结合。</p><h3 id="NP-Problem"><a href="#NP-Problem" class="headerlink" title="NP Problem"></a>NP Problem</h3><p>P问题：一个问题可以找到一个能在多项式的时间里解决它的算法。<br> eg. 最短路径问题，最小生成树问题…<br> NP问题：可以在多项式的时间里验证一个解的问题。<br> eg. 哈密顿路径，哈密顿回路…<br> 哈密顿回路就是NP问题，这个问题现在还没有找到多项式级的算法，但是验证一条路是否经过了每一个顶点非常容易。</p><h3 id="启发式算法"><a href="#启发式算法" class="headerlink" title="启发式算法"></a>启发式算法</h3><p>启发式算法（heuristic algorithm)是相对于<a href="https://baike.baidu.com/item/%E6%9C%80%E4%BC%98%E5%8C%96">最优化</a>算法提出的。一个问题的最优算法求得该问题每个实例的<a href="https://baike.baidu.com/item/%E6%9C%80%E4%BC%98%E8%A7%A3/5208902">最优解</a>。启发式算法可以这样定义：一个基于直观或经验构造的算法，在可接受的花费（指计算时间和空间）下给出待解决组合优化问题每一个实例的一个<a href="https://baike.baidu.com/item/%E5%8F%AF%E8%A1%8C%E8%A7%A3/962143">可行解</a>，该可行解与最优解的偏离程度一般不能被预计。现阶段，启发式算法以仿自然体算法为主，主要有<a href="https://baike.baidu.com/item/%E8%9A%81%E7%BE%A4%E7%AE%97%E6%B3%95/9646604">蚁群算法</a>、<a href="https://baike.baidu.com/item/%E6%A8%A1%E6%8B%9F%E9%80%80%E7%81%AB%E6%B3%95/10423893">模拟退火法</a>、<a href="https://baike.baidu.com/item/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/16600562">神经网络</a>等。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">遗传算法：是根据生物演化，模拟演化过程中基因染色体的选择、交叉和变异得到的算法。在进化过程中，较好的个体有较大的生存几率。</span><br><span class="line">模拟退火：是模拟统计物理中固体物质的结晶过程。在退火的过程中，如果搜索到好的解接受；否则，以一定的概率接受不好的解（即实现多样化或变异的思想），达到跳出局部最优解得目的。</span><br><span class="line">神经网络：模拟大脑神经处理的过程，通过各个神经元的竞争和协作，实现选择和变异的过程。</span><br><span class="line">禁忌搜索：模拟人的经验，通过禁忌表记忆最近搜索过程中的历史信息，禁忌某些解，以避免走回头路，达到跳出局部最优解的目的。</span><br><span class="line">蚂蚁算法：模拟蚂蚁的行为，拟人拟物，向蚂蚁的协作方式学习。</span><br><span class="line">这几种超启发式算法都有一个共同的特点：从随机的可行初始解出发，才用迭代改进的策略，去逼近问题的最优解。他们的基本要素：（1）随机初始可行解；（２）给定一个评价函数（常常与目标函数值有关）；（３）邻域，产生新的可行解；（４）选择和接受解得准则；（５）终止准则。</span><br></pre></td></tr></table></figure><h3 id="表示学习-representation-learning"><a href="#表示学习-representation-learning" class="headerlink" title="表示学习(representation learning)"></a>表示学习(representation learning)</h3><p>表示学习虽然从结构上讲只是数据的一个预处理手段，但是正如“工欲善其事，必先利其器”一样，它的出现提供了进行无监督学习和半监督学习的一种方法。其重要性不言而喻，以至于在花书中被单独列出来作为一章。表示学习一个比较典型的方法就是<strong>自编码器</strong>，有兴趣的可以自查。</p><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/v2-b2e25a17bb1c8777438aaa28587ed6e6_720w.jpg" alt="img"></p><h3 id="ADEPT学习法"><a href="#ADEPT学习法" class="headerlink" title="ADEPT学习法"></a>ADEPT学习法</h3><h2 id="英语笔记"><a href="#英语笔记" class="headerlink" title="英语笔记"></a>英语笔记</h2><p>decision-making problems: 决策问题</p><p>the networking community: 网络社区</p><p>state-of-the-art: adj. 最先进的；已经发展的；达到最高水准的</p><p>automated control problems: 自动控制问题</p><p>shogi：围棋</p><p>self-driving networks: 无人驾驶的网络</p><p>fully- connected, Convolutional Neural Networks: 全连接，卷积神经网络</p><p>relational reasoning and combinatorial generalization: 关系推理和组合推广</p><p>In Proceedings of: 在学报</p><p>the generalization capabilities: 泛化能力</p><p>tabula rasa:  白板（没有写字的书写板）；白纸状的心灵</p><p>differentiable functions：可微函数</p><p>pseudo-code：伪代码</p><p>nested loops : 嵌套循环</p><p> end-to-end：端到端</p><p>ongoing work：正在进行的工作</p><p>acknowledgments：致谢；鸣谢</p><p>combinatorial problem：组合问题</p><p>non-Euclidean graphs: 非欧几里得图</p><p>existing state：现有的状态</p><p> approaches to fundamental：基本方法</p><p>domain-specific knowledge：特定领域知识</p><p>dust off：抹去灰尘</p><p>exploitation（利用） 和 exploration （探索）</p>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 强化学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>10月25日</title>
      <link href="/2020/10/24/10%E6%9C%8825%E6%97%A5/"/>
      <url>/2020/10/24/10%E6%9C%8825%E6%97%A5/</url>
      
        <content type="html"><![CDATA[<h1 id="10月25日"><a href="#10月25日" class="headerlink" title="10月25日"></a>10月25日</h1><p>BP思路</p><p>卡尔曼滤波</p><p>模拟退火</p><p>贝尔曼方程</p><p>tkinter</p><p>涌向效应：</p><p>DeepMind</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">//多次运行产生的随机数一样，运行结果一样</span><br><span class="line">np.random.seed(<span class="number">2</span>) </span><br><span class="line"></span><br><span class="line">//ix,在panda0<span class="number">.2</span> 之后弃用，需要改成loc</span><br><span class="line">q_table.iloc[S_, :]</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="英语"><a href="#英语" class="headerlink" title="英语"></a>英语</h2><p>Epsilon：n. 希腊语字母之第五字；ε</p>]]></content>
      
      
      <categories>
          
          <category> 随记 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>10月21日</title>
      <link href="/2020/10/21/10%E6%9C%8821%E6%97%A5/"/>
      <url>/2020/10/21/10%E6%9C%8821%E6%97%A5/</url>
      
        <content type="html"><![CDATA[<h1 id="10月21日"><a href="#10月21日" class="headerlink" title="10月21日"></a>10月21日</h1><h2 id="笔记"><a href="#笔记" class="headerlink" title="笔记"></a>笔记</h2><p><strong>SIMD</strong>(单指令，多数据)</p><h2 id="英语"><a href="#英语" class="headerlink" title="英语"></a>英语</h2><p>makes sense：有意义；讲得通；言之有理</p><p>In order to convey these intuitions：为了更好的让你明白</p><p>tangent：切线，切面；正切</p><p>so far：到目前为止，迄今为止</p><p>or alternatively：或者，换个</p><p>convert or even divert：转换甚至转移</p><p>converse the local minimum：达到局部最小值</p><p>cuz：abbr. 因为（cause）</p><p>magenta point：红色的点</p><p>On a side note：此外</p><p>magnitude of：……的级数（地震）；……的大小</p><p>Sigma i equals one through m of theta zero plus theta one x i minus Yi squared：$\sum_1^n(\theta_0 + \theta_1x^i-y^i)$</p><p>other than</p><p>multivariate calculus：多元微积分</p><p>respect to：关于</p><p>be susceptible to local optima：易受局部优化的影响</p><p>wind up：结束</p><p>technical term：专业术语</p><p>convex function：凸函数</p><p>But for the demonstration：但为了演示</p><p>the intercept：截距</p><p>advanced linear algebra：高级线性代数</p><p>congrats on：恭喜你们</p><p>right for yourselves：对你的胃口；适合自己</p><p>generalization：一般化</p><p>by convention：按照惯例</p><p>a overly fancy term for：一个复杂的结构</p><p>And as promised：如之前所说</p><p>vectorization：向量化</p><p>pull out：提取出来</p><p>all in one shot：一步到位</p><p>assemble the answers：组装答案</p><p>in a second：很快</p><p>step through：单步调试；逐句通过</p><p>analogy to：类比</p><p>matrix transpose operation：矩阵的转置运算</p><p>a singular matrix or degenerate matrix：一种奇异矩阵或退化矩阵</p><p>proprietary software：[计] 专用软件，专有软件</p>]]></content>
      
      
      <categories>
          
          <category> 随记 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>10月20日</title>
      <link href="/2020/10/20/10%E6%9C%8820%E6%97%A5/"/>
      <url>/2020/10/20/10%E6%9C%8820%E6%97%A5/</url>
      
        <content type="html"><![CDATA[<h1 id="10月20日"><a href="#10月20日" class="headerlink" title="10月20日"></a>10月20日</h1><h2 id="笔记"><a href="#笔记" class="headerlink" title="笔记"></a>笔记</h2><h3 id="contour-plots-or-contour-figures"><a href="#contour-plots-or-contour-figures" class="headerlink" title="contour plots or contour figures"></a>contour plots or contour figures</h3><h3 id="人机耦合震荡"><a href="#人机耦合震荡" class="headerlink" title="人机耦合震荡"></a>人机耦合震荡</h3><h2 id="英语总结"><a href="#英语总结" class="headerlink" title="英语总结"></a>英语总结</h2><p>a range of：一套</p><p>refer to：表示；参考；涉及；指的是；适用于</p><p> in parentheses：在括号中；插入的</p><p>the ith row：第i行</p><p>x to the power of i：x的i次方</p><p>As mentioned：正如所说如前所述正如所说</p><p>a multiple-choice：一个选择题</p><p>kinda stuck：有点绕口</p><p>the sort of：那种；那一类的</p><p>standard terminology：标准术语</p><p>h<u>theta(x) equals theta<u>0</u></u> plus theta<u>1 of x：<img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/image-20201020100900591.png" alt="image-20201020100900591"></p><p>as a shorthand：简单起见</p><p>since：由于，因为，自..以后</p><p>building block：基本构成要素</p><p>go about：v. 着手做；四处走动；传开；从事</p><p>figure out ：理解；解决；算出；想出；断定</p><p>So just a recap：简单回顾一下</p><p>the 1 over the 2m：1&#x2F;2m</p><p>gradient descent:</p><p>optimization objective：优化目标</p><p>theta one times X：theta one 乘以 X</p><p>the slope of the straight line：直线的斜率</p><p>over here：在这里</p><p>devalue：贬值</p><p>This turns out to be：结果是</p><p>wound up：紧张的；兴奋的</p><p>trace out：描绘出；探寻；轨迹为</p><p>in visual terms：在视觉方面</p><p>end up doing：以…而告终</p><p>In other words：换句话说</p><p>a similar sort：一个类似</p><p>3-D surface plot：三维曲面图</p><p>concentric ellipses：同心椭圆</p><p>let’s break it out：我们把它写下来</p><p>further away from：距离更远</p><p>read off：读出；从…读取</p><p>contour line：[数] 轮廓线；[测] 等高线</p><p>one gets the following graphs：我们可以得到下面的图表</p><p>a slightly positive slope：稍微正的斜率</p><p>Just as an aside：顺便提一下</p><p> for the sake of brevity：为了简洁起见</p><p>for the sake of：为了；为了…的利益</p><p>start off with：从…开始，用…开始</p><p>a couple steps：几个步骤</p><p>So that’s the intuition in pictures：我们从图片中得到的直观感受</p><p>until convergence：直到收敛</p><p> let me unpack some of it：我来详细讲解一下</p><p>assignment operator：[计] 赋值运算符</p><p>whereas in contrast：然而反过来</p><p>asserting：声明</p><p>derive this derivative term：推出导数项</p><p>simultaneously update ：同步更新</p><p>partial derivatives and derivatives：偏导数和导数</p><p>in case：万一，假使</p><p>all the intuitions：所有知识</p><p>tangential line：切线</p><p>steepest descent：最陡下降</p>]]></content>
      
      
      <categories>
          
          <category> 随记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 随记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>10月14日</title>
      <link href="/2020/10/14/10%E6%9C%8814%E6%97%A5/"/>
      <url>/2020/10/14/10%E6%9C%8814%E6%97%A5/</url>
      
        <content type="html"><![CDATA[<h1 id="10月14日"><a href="#10月14日" class="headerlink" title="10月14日"></a>10月14日</h1><h2 id="笔记"><a href="#笔记" class="headerlink" title="笔记"></a>笔记</h2><h3 id="甘特图"><a href="#甘特图" class="headerlink" title="甘特图"></a>甘特图</h3><p>甘特图（Gantt chart）又称为横道图、条状图(Bar chart)。其通过条状图来显示项目，进度，和其他时间相关的系统进展的内在关系随着时间进展的情况。以提出者亨利·劳伦斯·甘特（Henry Laurence Gantt）先生的名字命名。</p><h4 id="含义"><a href="#含义" class="headerlink" title="含义"></a>含义</h4><p>甘特图以图示通过活动列表和时间刻度表示出特定项目的顺序与持续时间。一条线条图，横轴表示时间，纵轴表示项目，线条表示期间计划和实际完成情况。直观表明计划何时进行，进展与要求的对比。便于管理者弄清项目的剩余任务，评估工作进度。</p><p>甘特图是以作业排序为目的，将活动与时间联系起来的最早尝试的工具之一，帮助企业描述工作中心、超时工作等资源的使用。</p><blockquote><p>甘特图包含以下三个含义：</p><p>1、以图形或表格的形式显示活动；</p><p>2、通用的显示进度的方法；</p><p>3、构造时含日历天和持续时间，不将周末节假算在进度内。</p><p>简单、醒目、便于编制，在管理中广泛应用。</p><p>甘特图按内容不同，分为计划图表、负荷图表、机器闲置图表、人员闲置图表和进度表五种形式。</p></blockquote><h3 id="燃尽图"><a href="#燃尽图" class="headerlink" title="燃尽图"></a>燃尽图</h3><p>燃尽图也叫燃烧图，是罕见的敏捷度量。它的全称是“总剩余时间的燃尽图”，就是本次迭代中，所有故事（或拆分的任务，以下仅称故事）的剩余时间总和，随日期的变化而逐日递减的图。</p><p>燃尽图是在项目完成之前，对需要完成的工作的一种可视化表示。燃尽图有一个Y轴（工作）和X轴（时间）。理想情况下，该图表是一个向下的曲线，随着剩余工作的完成，“烧尽”至零。燃尽图向项目组成员和企业主提供工作进展的一个公共视图。这个词常常用于敏捷编程。(如下：燃尽图示意图)</p><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/%E7%87%83%E5%B0%BD%E5%9B%BE.png" alt="燃尽图"></p><p>燃尽图横坐标为工作日期，纵坐标估计剩余的工作量，每个点代表了在那一天估计剩余的工作量，通过折线依次连接起所有的点形成为估计剩余工作量的趋势线。另外还有一条控制线，为最初的估计工作量到结束日期的连线，一般用不同的颜色画上边的两根线。</p><h3 id="Confluence-企业开发协同文档"><a href="#Confluence-企业开发协同文档" class="headerlink" title="Confluence (企业开发协同文档)"></a>Confluence (企业开发协同文档)</h3><p>Confluence是一个专业的企业知识管理与协同软件，也可以用于构建企业wiki。使用简单，但它强大的编辑和站点管理特征能够帮助团队成员之间共享信息、文档协作、集体讨论，信息推送。</p><h3 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h3><p>Docker 是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的镜像中，然后发布到任何流行的 Linux 或 Windows 机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口。</p><h3 id="Devops"><a href="#Devops" class="headerlink" title="Devops"></a>Devops</h3><h4 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h4><p>DevOps 一词的来自于 Development 和 Operations 的组合，突出重视软件开发人员和运维人员的沟通合作，通过自动化流程来使得软件构建、测试、发布更加快捷、频繁和可靠。DevOps 其实包含了三个部分：开发、测试和运维。换句话 DevOps 希望做到的是软件产品交付过程中IT工具链的打通，使得各个团队减少时间损耗，更加高效地协同工作。</p><h4 id="DevOps-工具链"><a href="#DevOps-工具链" class="headerlink" title="DevOps 工具链"></a>DevOps 工具链</h4><ul><li>项目管理（PM）：Jira</li><li>代码管理：GitLab</li><li>持续集成（CI）：GitLab CI</li><li>镜像仓库：VMware Harbor</li><li>容器：Docker</li><li>容器平台： Rancher</li><li>镜像扫描：Clairctl</li><li>编排：Kubernetes</li><li>服务注册与发现：etcd</li><li>脚本语言：python</li><li>日志管理：EFK</li><li>系统监控：prometheus</li><li>Web服务器：Nginx</li><li>数据库：MySQL redis</li></ul><h4 id="DevOps-架构"><a href="#DevOps-架构" class="headerlink" title="DevOps 架构"></a>DevOps 架构</h4><blockquote><p> DevOps 流水线（工具链）</p></blockquote><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/%E9%A9%BB%E4%BA%91devops%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84.png" alt="驻云devops基础架构"></p><h4 id="DevOps环境部署"><a href="#DevOps环境部署" class="headerlink" title="DevOps环境部署"></a>DevOps环境部署</h4><p>具体安装步骤可参考链接：<a href="https://link.zhihu.com/?target=https://library.prof.wang/handbook/h/hdbk-MWnS99ThmLVDi7U5mVFrB9">王教授-DevOps平台</a></p><h3 id="CI-x2F-CD-管道"><a href="#CI-x2F-CD-管道" class="headerlink" title="CI&#x2F;CD 管道"></a>CI&#x2F;CD 管道</h3><p>持续集成Continuous Integration（CI）和持续交付Continuous Delivery（CD）</p><p>CI&#x2F;CD 管道是为了交付新版本的软件而必须执行的一系列步骤。持续集成&#x2F;持续交付（CI&#x2F;CD）管道是一套专注于使用 DevOps 或 站点可靠性工程（SRE）方法来改进软件交付的实践。</p><p>CI&#x2F;CD 管道加入了监控和自动化来改进应用开发过程，尤其是在集成和测试阶段以及交付和部署过程中。尽管可以手动执行 CI&#x2F;CD 管道的每个步骤，但 CI&#x2F;CD 管道的真正价值在于自动化。</p><h4 id="持续交付管道"><a href="#持续交付管道" class="headerlink" title="持续交付管道"></a>持续交付管道</h4><p>将源代码转换为可发布产品的多个不同的任务task和作业job通常串联成一个软件“管道”，一个自动流程成功完成后会启动管道中的下一个流程。这些管道有许多不同的叫法，例如持续交付管道、部署管道和软件开发管道。大体上讲，程序管理者在管道执行时管理管道各部分的定义、运行、监控和报告。</p><h4 id="CI-x2F-CD-管道的要素"><a href="#CI-x2F-CD-管道的要素" class="headerlink" title="CI&#x2F;CD 管道的要素"></a>CI&#x2F;CD 管道的要素</h4><p>构成 CI&#x2F;CD 管道的步骤被划分为不同的任务子集，称之为<em>管道阶段</em>。典型的管道阶段包括：</p><ul><li><strong>构建</strong> - 进行应用编译的阶段。</li><li><strong>测试</strong> - 进行代码测试的阶段。在此阶段采用自动化可以节省时间和精力。</li><li><strong>发布</strong> - 将应用交付到存储库的阶段。</li><li>﻿<strong>部署</strong> - 将代码部署到生产环境中的阶段。</li><li><strong>验证与合规</strong> - 验证版本的步骤取决于企业的需求。镜像安全性扫描工具（例如 Clair）可通过将镜像与已知漏洞（CVE） 进行比较，以此来确保镜像的质量。</li></ul><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/ci-cd-flow-desktop_0.png" alt="img"></p><p>这并不是管道阶段的完整列表。此列表只列举了一些常见阶段。具体管道会因您所在组织的要求而异。</p><h4 id="容器与-CI-x2F-CD-管道"><a href="#容器与-CI-x2F-CD-管道" class="headerlink" title="容器与 CI&#x2F;CD 管道"></a>容器与 CI&#x2F;CD 管道</h4><p>传统的 CI&#x2F;CD 系统是为使用虚拟机的管道而设计的</p><h3 id="2020-年必备的几个-DevOps-工具"><a href="#2020-年必备的几个-DevOps-工具" class="headerlink" title="2020 年必备的几个 DevOps 工具"></a><a href="https://segmentfault.com/a/1190000022908614">2020 年必备的几个 DevOps 工具</a></h3><h3 id="Octave"><a href="#Octave" class="headerlink" title="Octave"></a>Octave</h3><p>Octave是一款用于数值计算和绘图的开源软件。和Matlab一样,Octave 尤其精于矩阵运算:求解联立方程组、计算矩阵特征值和特征向量等等。</p><h3 id="Host文件"><a href="#Host文件" class="headerlink" title="Host文件"></a>Host文件</h3><h4 id="简介-1"><a href="#简介-1" class="headerlink" title="简介"></a>简介</h4><p>Hosts文件是一个没有扩展名的系统文件，它的主要作用是能加快域名解析，还可以屏蔽网站等。</p><p>Hosts文件主要作用是定义IP地址和主机名的映射关系，是一个映射IP地址和主机名的规定。可以用文本文件打开！当用户在浏览器中输入一个需要登录的网址时，系统会首先自动从Hosts文件中寻找对应的IP地址，一旦找到，浏览器会立即打开对应网页，如果没有找到，则浏览器会将网址提交DNS服务器进行IP地址解析。这也是提高快速打开网页的方法！</p><h4 id="位置"><a href="#位置" class="headerlink" title="位置"></a>位置</h4><p>C:\Windows\System32\drivers\etc</p><h3 id="时区"><a href="#时区" class="headerlink" title="时区"></a>时区</h3><p>由于世界各国家与地区经度不同，地方时也有所不同，因此会划分为不同的时区。</p><p>正式的时区划分包括24个时区，每一时区由一个英文字母表示。每隔经度15°划分一个时区，有一个例外，每个时区有一条中央子午线；例如，GMT属于“z”区，因此其时间后通常添加后缀“Z”（口语中用后缀“Zulu”）</p><p>地球是自西向东自转，东边比西边先看到太阳，东边的时间也比西边的早。东边时刻与西边时刻的差值不仅要以时计，而且还要以分和秒来计算，这给人们带来不便。</p><p>为了克服时间上的混乱，1884年在华盛顿召开的一次国际经度会议（又称国际子午线会议）上，规定将全球划分为24个时区（东、西各12个时区）。</p><p>每个时区横跨经度15度，时间正好是1小时。</p><p>例如，中国东8区的时间总比泰国东7区的时间早1小时，而比日本东9区的时间晚1小时。因此，出国旅行的人，必须随时调整自己的手表，才能和当地时间相一致。凡向西走，<strong>每过一个时区，就要把表拨慢1小时（比如2点拨到1点）；凡向东走，每过一个时区，就要把表拨快1小时（比如1点拨到2点）。</strong>并且规定英国（格林尼治天文台旧址）为本初子午线，即零度经线。</p><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/eaf81a4c510fd9f98f128c0f2f2dd42a2834a44b.jpg" alt="eaf81a4c510fd9f98f128c0f2f2dd42a2834a44b"></p><h3 id="Clojure"><a href="#Clojure" class="headerlink" title="Clojure"></a>Clojure</h3><p>Clojure是一种运行在Java平台上的 Lisp 方言，Lisp是一种以表达性和功能强大著称的编程语言，但人们通常认为它不太适合应用于一般情况，而Clojure的出现彻底改变了这一现状。如今，在任何具备 Java 虚拟机的地方，您都可以利用 Lisp 的强大功能。</p><h3 id="结构化编程"><a href="#结构化编程" class="headerlink" title="结构化编程"></a>结构化编程</h3><p><strong>结构化程式设计</strong>（英语：Structured programming），一种编程典范。它采用子程序、程式码区块（英语：block structures）、for循环以及while循环等结构，来取代传统的 goto。希望借此来改善计算机程序的明晰性、品质以及开发时间，并且避免写出面条式代码。</p><h3 id="函数式编程"><a href="#函数式编程" class="headerlink" title="函数式编程"></a>函数式编程</h3><p>函数式编程是种编程方式，它将电脑运算视为函数的计算。函数编程语言最重要的基础是λ演算（lambda calculus），而且λ演算的函数可以接受函数当作输入（参数）和输出（返回值）。</p><p>和指令式编程相比，函数式编程强调函数的计算比指令的执行重要。</p><p>和过程化编程相比，函数式编程里函数的计算可随时调用。</p><h3 id="指令式编程"><a href="#指令式编程" class="headerlink" title="指令式编程"></a>指令式编程</h3><p><strong>命令式编程</strong>（英语：Imperative programming），是一种描述计算机所需作出的行为的编程典范。几乎所有计算机的硬件工作都是命令式的；几乎所有计算机的硬件都是设计来运行机器码，使用命令式的风格来写的。较高阶的命令式编程语言使用变量和更复杂的语句，但仍依从相同的典范。虽非计算机程序，但与命令式编程有相似的风格：每步都是指令，有形的世界控制情况。因为命令式编程的基础观念，不但概念上比较熟悉，而且较容易具体表现于硬件，所以大部分的编程语言都是命令式的。</p><h3 id="过程化程序设计语言"><a href="#过程化程序设计语言" class="headerlink" title="过程化程序设计语言"></a>过程化程序设计语言</h3><p>过程化程序设计语言：即第三代程序设计语言，指需要由编写程序的人员一步一步地安排好程序的执行过程的程序设计语言。SQL是高级的非过程化编程语言，允许用户在高层数据结构上工作。它不要求用户指定对数据的存放方法，也不需要用户了解具体的数据存放方式，所以具有完全不同底层结构的不同数据库系统可以使用相同的SQL语言作为数据输入与管理的接口。它以记录集合作为操作对象，所有SQL语句接受集合作为输入，返回集合作为输出的语句</p><h3 id="字节码"><a href="#字节码" class="headerlink" title="字节码"></a>字节码</h3><p>字节码（Bytecode）是一种包含执行程序、由一序列 op 代码&#x2F;数据对 组成的<strong>二进制文件</strong>。<strong>字节码是一种中间码</strong>，它比机器码更抽象，需要直译器转译后才能成为机器码的中间代码。</p><p>通常情况下它是已经经过编译，但与特定机器码无关。字节码通常不像源码一样可以让人阅读，而是编码后的数值常量、引用、指令等构成的序列。</p><p>字节码主要为了实现特定软件运行和软件环境、与硬件环境无关。字节码的实现方式是通过编译器和虚拟机器。编译器将源码编译成字节码，特定平台上的虚拟机器将字节码转译为可以直接执行的指令。字节码的典型应用为Java bytecode。</p><p>字节码在运行时通过JVM（JAVA虚拟机）做一次转换生成机器指令，因此能够更好的跨平台运行。</p><blockquote><p><strong>总结：</strong>字节码是一种中间状态（中间码）的二进制代码（文件）。需要直译器转译后才能成为机器码。</p></blockquote><h3 id="Cocktail-party-effect"><a href="#Cocktail-party-effect" class="headerlink" title="Cocktail party effect"></a>Cocktail party effect</h3><p>The <strong>cocktail party effect</strong> is the phenomenon of the brain’s ability to focus one’s auditory attention(an effect of selective attention in the brain) on a particular stimulus while filtering out a range of other stimuli, as when a partygoer can focus on a single conversation in a noisy room. Listeners have the ability to both segregate different stimuli into different streams, and subsequently decide which streams are most pertinent to them. Thus, it has been proposed that one’s sensory memory subconsciously parses all stimuli and identifies discrete pieces of information by classifying them by salience. This effect is what allows most people to “tune into” a single voice and “tune out” all others. It may also describe a similar phenomenon that occurs when one may immediately detect words of importance originating from unattended stimuli, for instance hearing one’s name among a wide range of auditory input.</p><h3 id="人工智能"><a href="#人工智能" class="headerlink" title="人工智能"></a>人工智能</h3><h4 id="人工智能-1"><a href="#人工智能-1" class="headerlink" title="人工智能"></a>人工智能</h4><p><strong>人工智能</strong>指<strong>由人类制造出的机器表现出的智能。</strong>这是一个非常大的范围，长远目标是让机器实现类人智能。 不过目前我们还在非常非常初级的阶段，甚至都不能称为智能。</p><h4 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h4><p><strong>机器学习</strong>是指通过数据训练出能完成一定功能的模型，<strong>是实现人工智能的手段之一，也是目前最主流的人工智能实现方法</strong>。</p><h4 id="深度学习"><a href="#深度学习" class="headerlink" title="深度学习"></a>深度学习</h4><p>大数据造就了深度学习，通过大量的数据训练，我们能够轻易的发现数据的规律，从而实现基于监督学习的数据预测。</p><p>这里要强调的是基于监督学习。</p><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BA%94%E7%94%A8.jpg" alt="深度学习应用"></p><p><strong>深度学习则是机器学习的分支。深度即层数</strong>，超过 8 层的神经网络模型就叫深度学习——目前在语音、图像等领域取得了很好的效果。</p><h4 id="迁移学习（举一反三）"><a href="#迁移学习（举一反三）" class="headerlink" title="迁移学习（举一反三）"></a>迁移学习（举一反三）</h4><p>迁移学习解决的问题是 如何将学习到知识 从一个场景迁移到另一个场景？</p><p>拿图像识别来说，从白天到晚上，从 Bottom View 到 Top View，从冬天到夏天，从识别中国人到 识别外国人……</p><p>这是一个普遍存在的问题，问题源自于你所关注的场景缺少足够的数据来完成训练，在这种情况下你需要 通过迁移学习来实现 模型本身的泛化能力。</p><p>借用一张示意图（From：A Survey on Transfer Learning）来进行说明： </p><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/20180723205115749.jpg" alt="20180723205115749"></p><p>实际上，你可能在不知不觉中使用到了 迁移学习，比如所用到的预训练模型，在此基础所做的 Fine-Turning，再比如你做 Tracking 所用的 online learning。</p><p>迁移学习的必要性和价值体现在：</p><p>1、复用现有知识域数据，已有的大量工作不至于完全丢弃；<br>2、不需要再去花费巨大代价去重新采集和标定庞大的新数据集，也有可能数据根本无法获取；<br>3、对于快速出现的新领域，能够快速迁移和应用，体现时效性优势；</p><p>关于迁移学习算法 有许多不同的思路，我们总结为：</p><p>1、通过 原有数据 和 少量新领域数据混淆训练；<br>2、 将原训练模型进行分割，保留基础模型（数据）部分作为新领域的迁移基础；<br>3、通过三维仿真来得到新的场景图像（OpenAI的Universe平台借助赛车游戏来训练）；<br>4、借助对抗网络 GAN 进行迁移学习 的方法； </p><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/20180723205002115.jpg" alt="20180723205002115"></p><h4 id="强化学习（反馈与修正）"><a href="#强化学习（反馈与修正）" class="headerlink" title="强化学习（反馈与修正）"></a>强化学习（反馈与修正）</h4><p>强化学习全称是 Deep Reinforcement Learning（DRL），其所带来的推理能力 是智能的一个关键特征衡量，真正的让机器有了自我学习、自我思考的能力，毫无疑问Google DeepMind 是该领域的执牛耳者，其发表的 DQN 堪称是该领域的破冰之作。 </p><p>目前强化学习主要用在游戏 AI 领域（有我们老生常谈的 AlphaGo）和 机器人领域，除此之外，Google宣称通过 强化学习 将数据中心的冷却费用降低了 40%，虽无法考证真伪，但我愿意相信他的价值。</p><p>强化学习 是个复杂的命题，Deepmind 大神 David Silver 将其理解为这样一种交叉学科： </p><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/20180723205257161.jpg" alt="20180723205257161"></p><p>实际上，强化学习是一种探索式的学习方法，通过不断 “试错” 来得到改进，不同于监督学习的地方是 强化学习本身没有 Label，每一步的 Action 之后它无法得到明确的反馈（在这一点上，监督学习每一步都能进行 Label 比对，得到 True or False）。</p><p>强化学习是通过以下几个元素来进行组合描述的：</p><p>对象（Agent）</p><p>也就是我们的智能主题，比如 AlphaGo。</p><p>环境（Environment）</p><p>Agent 所处的场景－比如下围棋的棋盘，以及其所对应的状态（State）－比如当前所对应的棋局。</p><p>Agent 需要从 Environment 感知来获取反馈（当前局势对我是否更有利）。</p><p>动作 (Actions)</p><p>在每个State下，可以采取什么行动，针对每一个 Action 分析其影响。</p><p>奖励 (Rewards)</p><p>执行 Action 之后，得到的奖励或惩罚，Reward 是通过对 环境的观察得到。</p><p>通过强化学习，我们得到的输出就是：Next Action？下一步该怎么走，这就是 AlphaGo 的棋局，你能够想到，对应围棋的 Action 数量吗？</p><p>关于强化学习的具体算法，大多从 马尔可夫链 讲起。</p><h4 id="联系"><a href="#联系" class="headerlink" title="联系"></a>联系</h4><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/v2-cdbef7f0385b59656eaa9df2a75d890e_720w.jpg" alt="img"></p><p><img src="https://garymk-1258635034.cos.ap-beijing.myqcloud.com/typora/v2-25cb113551541a79efdb7bd0b38d4d90_720w.jpg" alt="img"></p><h2 id="英语总结"><a href="#英语总结" class="headerlink" title="英语总结"></a>英语总结</h2><p>with respect to：关于，至于</p><p>It turns out that：原来是；翻译；人们发现</p><p>make sense：讲得通有意义有道理言之有理</p><p>terms：术语</p><p>And equally important or more important </p><p>than…：而等同或更重要的是…</p><p>end up one of：最终成为</p><p>the stuff：这玩意</p><p>Industry Icons： 传奇超模</p><p>like-minded：志趣相投的</p><p>Off-topic：离题</p><p>non-native English speakers：非英语母语者</p><p>abbreviations or slang：缩写或俚语</p><p>as…… as possible：尽可能…</p><p>the size of different houses in square feet：不同房子的面积，单位一平方英尺</p><p>given this data：根据这些数据</p><p>let’s say：假设说</p><p>fit a straight line to the data：使直线拟合数据</p><p>Based on that：在此基础上</p><p>a quadratic function：一个二次函数</p><p>a second-order polynomial：二阶多项式</p><p>closer to：更相近</p><p>refers to：指的是；参考；涉及；适用于</p><p>rounded-off：四舍五入</p><p>a real number：一个实数</p><p>a scalar value：一个标量值</p><p> a continuous value：一个连续的数值</p><p>malignant or benign：恶性或良性</p><p> a breast tumor：乳房肿瘤</p><p>shown down here：显示在这里</p><p>instead of drawing crosses：取代×号</p><p>mapped it down to：把它映射到</p><p>Just a quick wrap up question.：简单总结一下</p><p>Back then：当时，那时候</p><p>get rid of：摆脱，除去</p><p>clean up：清理；大捞一笔；收割（游戏术语）</p><p>a ton of：大量的</p><p>come up with：提出；想出；赶上</p><p>a learning setting：一个学习机制</p><p>as opposed to：与…截然相反；对照</p><p>gonna：（美）将要（等于going to）</p><p>As such：同样地；本身；就其本身而论</p><p>put into place：发挥实际作用</p><p>put in place：到位；落实到位；正在实施</p><p>volunteered time ：志愿时间</p><p>probability theory：概率论</p><p>linear algebra：线性代数</p><p>come up to：达到；等于</p><p>rapid vectorized calculations：快速矢量化计算</p><p>ML algorithms under the hood：ML算法的底层</p><p>decimal point rounding method：小数点舍入</p><p>best addressed：最好的解决</p><p>side effects：副作用</p><p>the odds of：……的发生的几率</p>]]></content>
      
      
      <categories>
          
          <category> 随记 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>项目管理文档简介</title>
      <link href="/2020/10/13/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E6%96%87%E6%A1%A3%E7%AE%80%E4%BB%8B/"/>
      <url>/2020/10/13/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E6%96%87%E6%A1%A3%E7%AE%80%E4%BB%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="项目管理文档简介"><a href="#项目管理文档简介" class="headerlink" title="项目管理文档简介"></a>项目管理文档简介</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><h3 id="为什么需要项目管理工具"><a href="#为什么需要项目管理工具" class="headerlink" title="为什么需要项目管理工具"></a>为什么需要项目管理工具</h3><ol><li>在重要的节点上，来检查自己是否遗漏了重要的环境</li><li>增强对工作进度的把控力度</li><li>专门的项目管理软件学习成本高，且工作文件可能需要相应软件打开</li></ol><h3 id="项目管理文档简介-1"><a href="#项目管理文档简介-1" class="headerlink" title="项目管理文档简介"></a>项目管理文档简介</h3><h4 id="项目计划表"><a href="#项目计划表" class="headerlink" title="项目计划表"></a>项目计划表</h4><p>用于记录项目各个任务模块，以及对应的负责人，开始时间，项目周期这些数据。</p><h4 id="甘特图"><a href="#甘特图" class="headerlink" title="甘特图"></a>甘特图</h4><p>甘特图是以提出者甘特先生的名字命名的。横轴表示时间，纵轴表示项目里各个任务。通过条状图来显示项目里各个任务随着时间进展的完成情况。</p><p>通过甘特图可以清晰的看到各个任务的完成进度。</p><h4 id="项目分析"><a href="#项目分析" class="headerlink" title="项目分析"></a>项目分析</h4><p>项目图表分析部分是根据项目计划数据自动生成的，并不需要人为额外更新，最大程度上减少了人员工作量。</p><p>这部分主要是为了方便全局看到项目信息和人员任务安排信息，帮助最大化利用人员时间和效率，降低资源浪费。</p><p>每周你可以把项目进度文档发给各个相关的人员，每个人可以看到整体项目的进度，和各自当前的工作任务。跟CEO汇报也一目了然。</p><p>整个文档做起来难度并不是很大，做完之后能够多次重复使用，大大的提升了使用的愉悦度和效率。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_jpg/axvPqcjkDkJdBcPhBqH8zxibHicWeJfzYUNMBH5JIg109rxrStpiaWFNLj9CDHxM5lU5EMnTjQ25uyXwFvxyOQoaQ/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="img"></p><h2 id="项目管理文档制作"><a href="#项目管理文档制作" class="headerlink" title="项目管理文档制作"></a>项目管理文档制作</h2><h3 id="项目计划表的制作"><a href="#项目计划表的制作" class="headerlink" title="项目计划表的制作"></a>项目计划表的制作</h3><p><img src="https://mmbiz.qpic.cn/mmbiz_jpg/axvPqcjkDkJdBcPhBqH8zxibHicWeJfzYUJw2hVPIbu81zjlMFTxbEQRbJ4X2VcapP7OGPtuIk7WrT5icKcgtpbNg/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="img"></p><blockquote><p>辅助列截止时间里的值等于开始时间加上需要天数；<br>已完成天数里的today()函数为当天日期，里面当天日期和开始日期计算出已完成天数；<br>未完成天数等于需要天数减去已完成天数</p></blockquote><h3 id="甘特图的制作"><a href="#甘特图的制作" class="headerlink" title="甘特图的制作"></a>甘特图的制作</h3><p><img src="https://mmbiz.qpic.cn/mmbiz_jpg/axvPqcjkDkJdBcPhBqH8zxibHicWeJfzYUichowlibnYPyVIEj7f9tovHrPdA7mAl3KkYIP0aqxh3ibUuicsBZJmMdibg/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="img"></p><p>第1步，按住ctrl键选中项目分解，已完成天数，未完成天数这几列</p><p>第2步，选择插入菜单栏下的堆积条形图，就得到了下面图片中的甘特图</p><p><img src="https://mmbiz.qpic.cn/mmbiz_jpg/axvPqcjkDkJdBcPhBqH8zxibHicWeJfzYUG4ZegjWdDakFNvdPqtTibJ4FiclbcYWF9xNAJJ8M2keCc9adCtaDriaWw/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="img"></p><p>第3步，选中图表，点击鼠标右键，选择“选择数据”按钮</p><p>第4步，在弹出的对话框中选择添加，出现下面图片中的对话框</p><p><img src="https://mmbiz.qpic.cn/mmbiz_jpg/axvPqcjkDkJdBcPhBqH8zxibHicWeJfzYUXdIc7iajkrRwtmqvOKH3icibPTCE2wdOuHHYvwJxg9mz0BXLiaGDxBrljA/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="img"></p><p>第5步，在系列名称中选择计划表中的开始时间列名。在系列值中选择开始时间这一列的数据。就把开始时间作为横轴加到甘特图里了。</p><p>第6步，我们把开始时间移动到最前面，就可以看到我们图表中的绿色条形就是开始时间。</p><p>下面我们继续优化图表。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_jpg/axvPqcjkDkJdBcPhBqH8zxibHicWeJfzYU79ibu8YVtDewV0emAuM2J4QFYqqE6PXM855NHQWOQoSEEqAWxmvFGCg/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="img"></p><p>第7步，我们设置坐标轴。</p><p>选择纵轴，鼠标右键选择“设置坐标轴格式”，在弹出的对话框中选择“逆序类别”，我们看到纵轴安装任务顺序排列好了，横轴开始时间也移动到了最上方。</p><p>我们看到横轴时间比较乱，下面图片我们继续设置横轴时间。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_jpg/axvPqcjkDkJdBcPhBqH8zxibHicWeJfzYUqBjb6uowxLfBzQzOqWcC42bEkQm2EjKO85GltljoUgThzF828VhPXw/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="img"></p><p>选中横轴，鼠标右键选择“设置坐标轴格式”，在弹出的对话框里最小值设置为计划表开始时间的最小日期，输入日期后按回车键。最大值设置为计划表截止日期里的最大日期。</p><p>设置好后我们就看到了下图的效果。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_jpg/axvPqcjkDkJdBcPhBqH8zxibHicWeJfzYUpCZpULYeVck3RIoZjMSYNgg57yhlacibFh3Wib87G8JZianms6iaGq6nAw/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="img"></p><p>我们将绿色条形的地方选中，选择无填充，让它隐去，就得到了甘特图。然后再做一些图表的细节优化处理，就可以让甘特图更好看了。</p><h3 id="项目分析的制作"><a href="#项目分析的制作" class="headerlink" title="项目分析的制作"></a>项目分析的制作</h3><p>预计总天数，已完成天数，未完成天数，对之前的计划表列做加法就可以得到。</p><p>然后插入饼状图就可以得到项目完成进度。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_jpg/axvPqcjkDkJdBcPhBqH8zxibHicWeJfzYUibjK3HR5lGoWpYOcsdECSjkwXWDOgamFOpVKWe1QzgCAiaatBiaftiazEA/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="img"></p><p>对计划表做数据透视表，就可以得到项目人员工作量的柱状图。</p>]]></content>
      
      
      <categories>
          
          <category> 开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 项目管理 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
